\input{head}



\title{Современное программирование \\ 
Конспект по алгебре, 2019-2020}
\date{}


\begin{document}

\tableofcontents

\chapter{Введение}




\section{Уравнения и числа}

Современные задачи алгебры очень разнообразны, однако корни всех алгебраических задач стоит искать в исследовании различных уравнений.


Попробуем проиллюстрировать этот тезис на примере простейшего уравнения в целых числах $a=bx$.

\dfn[Делимость] Пусть $a$ и $b$ -- два целых числа. Будем говорить, что $a$ делится на $b$, если уравнение $a=bx$ разрешимо в целых числах. Будем обозначать это как $a\di b$ 
\edfn

Как узнать, делится ли одно число на другое? Для этого стоит поделить с остатком.

\thrm[О делении с остатком] Пусть $a$ и $b$ --- два целых числа, причём $b\neq 0$. Тогда существуют единственные целые
числа $q$ и $r$, такие что
$$a=bq+r \text{ и } 0\leq r< |b|.$$
\ethrm
\proof Докажем существование. Будем считать, что $a\geq 0$. Индукция по $a$. Если $a<|b|$  то возьмём $q=0$, $r=a$. Шаг. Вычтем из $a$ модуль $b$. Обозначим разность $a'=a-|b|$. По предположению $a'=bq'+r$. Тогда $a=b(q'\pm 1)+r$, где $\pm$ ставится в зависимости от знака $b$. 

Для отрицательных $a$. $|a|=bq+r$. Если $r=0$, то $a=b(-q)$.  Иначе $a=b(-q)+(-r)=b(-q\pm 1)+(|b|-r)$.

Докажем единственность. Пусть $a=bq+r=bq'+r'$. Тогда $0=b(q-q')+(r-r')$. Заметим, что $|r-r'|<|b|$. Тогда равенство нулю возможно только если $q-q'=0$. Но тогда $r-r'=0$.
\endproof




\dfn[Общий делитель и наибольший общий делитель] Пусть $a$ и $b$ -- два целых числа. Тогда число $d$ называется общим делителем $a$ и $b$, если $a\di  d $ и $b \di d$.
Общий делитель $d$ называется наибольшим общим делителем, если $d\geq 0$  и для любого другого делителя $d'$ верно, что $d \di d'$
\edfn

\rm Если два натуральных числа делятся друг на друга, то это значит, что они равны. Из этого следует, что если наибольший общий делитель есть, то он единственен.
\erm

\lm Пусть $a$ и $b$ -- два целых числа. Тогда существует такое натуральное число $d$, что множество чисел вида $ax+by$ совпадает с множеством чисел, кратных $d$ (будем обозначать последнее как $d\mb Z$). Более того, $d$ является наибольшим общим делителем чисел $a$ и $b$.
\elm 
\proof  Пусть $a$ и $b$ отличны от нуля. Рассмотрим множество $(a,b)=\{z\in \mb Z\,|\, \exists\, x,y \in \mb Z, \text{ что } z=ax+by\}$ элементов вида $ax+by$. Или менее формально $(a,b)=\{ax+by\,|\, x,y \in \mb Z\}$. Для всякого $d$ так же определим множество $(d)=d\mb Z=\{dx\,|\,x\in \mb Z\}$ -- множество элементов, кратных $d$. Мы хотим найти такой $d$, что $(d)=(a,b)$. 

В случае $a=0=b$ подходит $d=0$ и ничего другого. Иначе, рассмотрим наименьший положительный $d$ (такой теперь есть), который лежит в $A$. Покажем, что тогда все элементы $A$ делятся на $d$. Действительно, пусть $ax+by=c\in A$. Поделим $c$ на $d$ с остатком
$$c=dq+r.$$
Заметим, что тогда элемент $r$ так же лежит в $A$, но его модуль меньше $d$. Так как $d$ наименьший положительный элемент $A$ это значит, что $r$ равен нулю. Что и требовалось. 


Обратно, любой элемент, делящийся на $d=ax+by$ сам имеет такой вид.
Осталось показать, что $d$ наибольший общий делитель. Для этого заметим, что элементы $a$ и $b$ сами лежат в $A$ и, следовательно, делятся на $d$. С другой стороны, так как $d=ax+by$, то любой общий делитель  $a$  и $b$ есть делитель $d$. 
\endproof

\crl Для любых двух целых чисел $a,b$ существует $\Nod(a,b)$. $\Nod(a,b)$ единственен и является наименьшим положительным элементом в множестве $(a,b)$ и, таким образом, однозначно этим множеством определяется. Поэтому мы будем вместо $\Nod(a,b)$ писать просто $(a,b)$, если это не вызовет путаницы.
\ecrl



\crl[Линейное разложение НОД-а] Пусть $a$ и $b$ --- два целых числа. Пусть $d$ --- наибольший общий делитель $a$ и $b$. Тогда существуют такие целые числа $x$ и $y$, что
$d=ax+by$.
\ecrl

Думаю, что вам всем хорошо известно следующее определение:

\dfn Два числа $n,m$ называются взаимно простыми, если $(n,m)=1$.
\edfn

Покажем полезное для нас свойство взаимно простых чисел.

\lm Пусть $n$ -- некоторое целое число, $a$ и $b$ -- взаимно простые целые числа. Тогда если $na \di b$, то $n\di b$.
\elm
\proof Наибольший общий делитель $a$  и $b$ равен $1$. Рассмотрим его линейное разложение 
$$1=ax+by.$$
Домножим это разложение на $n$. Получим $$n=nax+nby.$$
Заметим, что оба слагаемых делятся на $b$ -- первое по предположению теоремы, второе -- просто содержит $b$. Значит $n \di b$, что и требовалось.
\endproof

Разберёмся подробнее с решением уравнения $ax+by=c$. Первое: как искать какое-то решение? Второе: как выглядят все остальные решения?\\
1) Очевидно, что если $(d)=(a,b)$, то для того, чтобы было решение необходимо и достаточно $c\di d$. А именно если есть разложение $d=ax+by$. Тогда есть решение $c= \frac{c}{d}(ax+by)$. Опишем, как выглядят все остальные решения.\\
2) Пусть есть два решения уравнения $ax+by=c$ и $ax'+by'=c$. Возьмём разность $a(x-x')+b(y-y')=0$, то есть 
$$\tfrac{a}{d}(x-x')=-\tfrac{b}{d}(y-y').$$
Тогда по привычному нам свойству $(x-x')\di \frac{b}{d}$. Пусть $(x-x')=t\frac{b}{d}$. Тогда $(y-y')=-t\frac{a}{d}$. Таким образом, пододвинуть первую координату мы можем только на кратное $\frac{b}{d}$ и это определяет однозначно вторую координату. Понятно, что новые $x',y'$ обязательно решения.\\






Единственный не рассмотренный подробно вопрос, касающийся решения  линейного диофантового уравнения $ax+by=c$ состоит в том, как вычислить наибольший общий делитель двух чисел и его линейное разложение.

Рассмотрим пару чисел $a,b\in \mb Z$. Поделим $a$ на $b$ с остатком $a=bq_1+r_1$. Тогда $$(d)=(a,b)=(a-bq,b)=(b,r_1).$$
продолжая так далее имеем соотношение
$$r_{i-1}=r_iq_{i+1}+r_{i+1}  \text{ и $(a,b)=(r_i,r_{i+1})$}.$$
Так как начиная со второго номера все $r_i$ положительные и всегда убывают по модулю, то в конце концов получаем, что $r_{k+1}=0$.
В этот момент  $\Nod(a,b)=\Nod(r_k,r_{k+1})=r_k$. Как вычислить линейное разложение? В самом начале имеем $a=1\cdot a+0\cdot b$ и $b=0\cdot a+ 1\cdot b$. По индукции пусть есть разложение для $r_{i-1}=ax+by$ и $r_i=ax'+by'$. Тогда $$r_{i+1}=r_{i-1}-q_ir_{i}=a(x-q_ix')+b(y-q_iy').$$
Это называется расширенным алгоритмом Евклида.

Сколько делений с остатком может потребоваться для того, чтобы вычислить наибольший общий делитель?
Понятно, что чем больше неполные частные в делениях с остатком, тем меньше делений с остатком понадобится. Кандидатом на наихудшее число операций в алгоритме Евклида, таким образом, являются числа Фибоначчи:
$$f_{n+1}=f_n+f_{n-1}, \text{ и $f_0=0$, $f_1=1$}.$$

\lm Пусть для пары целых чисел $a>b>0$ в алгоритме Евклида происходит $k$ делений с остатком. Тогда $a\geq f_{k+2}$, а $b\geq f_{k+1}$? 
\elm
\proof Пусть $r_{i-2}=q_ir_{i-1}+r_i$, $a=r_{-1}$, $b=r_0$ и $r_k=0$. Покажем, что $f_{i+1}\leq r_{k-i}$. По индукции. $i=1,2$ верно. Далее
$$r_{k-i}=q_{k-i+2}r_{k-i+1}+r_{k-i+2}\geq r_{k-i+1}+r_{k-i+2}\geq f_i+f_{i-1}=f_{i+1}.$$
\endproof

Оценим рост чисел Фибоначчи:
\lm При $n>1$ имеет место неравенство $f_n\geq \varphi^{n-2}$, где $\varphi=\frac{1+\sqrt{5}}{2}$ является корнем уравнения $x^2-x-1=0$. 
\elm
\proof При $n=1,2$ --- верно. Для $n+1$ имеем неравенство
 $$f_{n+1}=f_n+f_{n-1}\geq \varphi^{n-2}+\varphi^{n-3}=\ffi^{n-3}(\ffi+1)=\ffi^{n-1}.$$
\endproof

\thrm Пусть $b<a\leq N$ --- натуральные числа. Тогда число делений с остатком в алгоритме Евклида при нахождении $\Nod(a,b)$  не превосходит $\left\lfloor \log_{\ffi} N\right\rfloor$. 
\ethrm
\proof Пусть, как и раньше, $k$ -- это количество делений с остатком для пары $a,b$. Тогда
$$N\geq a=r_{-1}\geq f_{k+2} \geq \ffi^k.$$ 
Получаем $k\leq \left\lfloor \log_{\ffi} N\right\rfloor.$ 
\endproof

\rm Можно улучшить алгоритм допуская отрицательные остатки.
\erm

\fct Битовая сложность умножения двух чисел такая же как и у операции деления с остатком (естественно, с точностью до мультипликативной константы).
\efct

\rm В этом случае, битовая сложность алгоритма Евклида для чисел длины $n$ бит можно оценить как $ C n^3$, если использовать обычный алгоритм умножения и $C n^2\log n \log \log n$ при использовании алгоритма умножения Шёнхаге-Штрассена. Если присмотреться, то можно увидеть, что это не оптимальная оценка, так как в случае маленьких неполных частных деление с остатком стоит не так много. Это приводит к оценке $C n (\log n)^2\log\log n$.
\erm




\section{Сравнения по модулю и их свойства} 

Рассмотрим уравнение $x^2+251x+1203$. Имеет ли оно решение в целых числах? Если действовать в лоб, то надо потратить много усилий. Однако, можно заметить, что если $x$ чётное, то результат его подстановки будет числом нечётным и, следовательно, не может быть равным нулю. Аналогично, если $x$ -- нечётное число. Таким образом, получаем, что целочисленных решений это уравнение не имеет. 

Смотреть на чётность -- это всё равно что смотреть на остаток от деления на $2$. Наша задача для произвольного числа $n$ извлечь информацию про целочисленное уравнение посмотрев на  остатки его коэффициентов по модулю $n$.

\dfn Пусть $a,b,n$ -- целые числа . Будем говорить, что число числа $a$ и $b$ сравнимы по модулю $n$, если $a-b \di n$. Будем записывать это как
$$a\equiv b \mod n \text{ или для краткости } a\equiv b \,\,(n)$$  
\edfn

Сформулируем основные свойства сравнений. Пусть $n, a,b,c, d$ --  некоторые целые числа. Тогда:\\
0) $a\equiv a \mod n$, если $a\equiv b \mod n$, то $b \equiv a \mod n$\\
1) $a\equiv b \mod n$ $b\equiv c \mod n$ тогда $a\equiv c$.\\
2) Если $a\equiv b \mod n$, и $c\equiv d \mod n$, то $a+c \equiv b+d \mod n$ и $ac\equiv bd \mod n$.\\
3) В частности, если $a\equiv b \mod  n$, то $ac\equiv bc \mod n$.\\
4) $a\equiv b \mod n$ тогда и только тогда, когда их остатки от деления на $n$ одинаковы.\\
5) Если $a\equiv b \mod n$, то $a\equiv b \mod (-n)$. Таким образом, всегда можно считать, что $n$ -- неотрицательное число. Более того, при $n=0,1$ понятие сравнения становится очень простым. При $n=0$ два числа сравнимы тогда и только тогда, когда они равны, а при $n=1$ любые два целых числа сравнимы.\\


На языке сравнений удобно формулировать разные ограничительные условия для целых чисел. Например, линейным сравнением относительно $x$ называется условие вида 
$$ax\equiv b \mod n .$$
Здесь $a,b,n$ -- целые числа. Решить такое сравнение означает найти все целые $x$ ему удовлетворяющие. Посмотрим как это можно сделать. Для этого распишем условие $ax\equiv b \mod n$. Такое сравнение выполнено, если существует $y$, что $ax=b+ny$, то есть если $ax-ny=b$. Таким образом, число $x$ должно быть первой компонентой решения линейного диофантового уравнения. 

Отсюда сразу сделаем вывод: решение линейного сравнения $ax\equiv b \mod n$ существует тогда и только тогда, когда $b \di (a,n)$. В частности, оно всегда разрешимо, если $a,n$ -- взаимно простые числа. 

Далее, если $x_0$ -- некоторое решение сравнения, то все его решения имеют вид $x=x_0+t\frac{n}{d}$. Осталось заметить, что само это условие удобно записывается на языке сравнений
$$x\equiv x_0 \mod \frac{n}{d}.$$ 
Мы будем говорить, что решение линейного сравнения единственно по модулю $\frac{n}{d}$. В частности, это означает, что у сравнения есть единственное решение в промежутке от $0$ до $\frac{n}{d}-1$.



\section{Немного теории множеств}

Нам понадобилось понятие отображения. Для этого нам необходимо понятие декартового произведения множеств.

\dfn Пусть $A$ и $B$ -- два множества. Тогда их декартовым произведением $A\times B$ называется множество всех пар $(a,b)$, где первая координата из $A$, а вторая из $B$. Это можно записать так:
$$ A \times B = \{ (a,b) \, | \, a \in A \text{ и } b \in B \}.$$
\edfn

Что такое отображение между множествами $A$  и $B$? Это некоторое правило соответствия по элементу $A$ дающее элемент $B$. Но как это выразить на самом языке теории множеств? Для этого заметим, что отображение $f\colon A \to B$ должно кодироваться его графиком, то есть множеством пар вида $(x,f(x))$ $x\in A$ и $f(x)\in B$, то есть подмножеством декартового произведения. Это приводит нас к формальному определению.


\dfn Отображение $f \colon A \to B$ из множества $A$ в множество $B$ это тройка данных $(A,B,\Gamma_f)$, где $\Gamma_f \subseteq A \times B$ обладает свойством, что для всех $a \in A$ существует единственное $b \in B$, что $(a,b) \in \Gamma_f$ (в дальнейшем будем просто писать $b=f(a)$). 
\edfn

Конечно для задания отображений мы будем использовать формулы, а не графики. Например, $f(x)=x^2$ задаст нам отображение $\mb R \to \mb R$. Однако, отдельное задание множеств $A$ и $B$ -- области определения и прибытия, очень важно. Одна и та же формула $f(x)=x^2$ может задавать совершенно разные отображения. Например, из $\mb N$ в $\mb N$, или из $\mb Z \to \mb R$.

Вот примеры интересных нам свойств, которые очень чувствительны к тому, какие $A$ и $B$ выбраны:

\dfn Отображение $f \colon A \to B$ называется инъективным, если $\forall x_1,x_2 \in A$ таких, что $f(x_1)=f(x_2)$ верно, что $x_1=x_2$.
\edfn

Отображение $f(x)=x^2$ инъективно, если посмотреть на него, как на отображение $\mb N \to \mb N$, но не инъективно как отображение $\mb Z \to \mb R$.

\dfn Отображение $f \colon A \to B$ называется сюръективным, если $\forall y\in B$ существует $x \in A$, что $f(x)=y$. Такой элемент $x\in B$ называется прообразом элемента $y$.
\edfn

Отображение $f(x)=x^2$ -- сюръективно как отображение $\mb R \to \mb R_{\geq 0}$, но не сюръективно как отображение $\mb R \to \mb R$.

\dfn Отображение $f \colon A \to B$ называется биективным, если оно инъективно и сюръективно.
\edfn



Из любого множества в себя есть биективное отображение -- тождественное.



\dfn Пусть $A$ множество. Определим отображение $id_A \colon A \to A$ по правилу $id_A(x)=x$. Такое отображение называется тождественным.
\edfn

Ещё пример биективного отображения: $f \colon \mb R \to \mb R$ вида $f(x)=2x$, ну или $f(x)=x^3$.


В дальнейшем нам понадобится определения обратного отображения и, следовательно, определение композиции отображений.

\dfn Пусть есть три множества $A,B,C$ и два отображения между ними -- $f\colon A \to B$ и $g\colon B \to C$. Определим отображение $g \circ f \colon A \to C$, по правилу $g\circ f(x)= g(f(x))$ для всех $x \in A$. 
\edfn

\dfn Пусть $f \colon A \to B$. Тогда обратным отображением к $f$ называется такое $f^{-1}\colon B \to A$, что $f \circ f^{-1}= id_B$ и $f^{-1}\circ f= id_A$. 
\edfn



\thrm Отображение $f \colon A \to B$ биективно тогда и только тогда, когда оно обратимо. Если обратное отображение есть, то оно единственно.
\ethrm

\crl Если $f \colon A \to B$ биекция, то $f^{-1}\colon B \to A$ тоже биекция.
\ecrl

\thrm[Принцип Дирихле] Пусть $X$ и $Y$ -- два конечных множества с одинаковым числом элементов. Тогда отображение  $f\colon X \to Y$ инъективно тогда и только тогда, когда оно сюръективно.
\ethrm




\section{Бинарные отношения}

Часто встречается такая ситуация, когда некоторое свойство $R(x,y)$ зависит от $x,y$ -- элементов одинакового типа (одного множества $X$). В такой ситуации принято говорить, что на $X$ задано бинарное отношение $R$. Если свойство $R$ истинно на паре $x,y$, то пишут $x R y$. Но что же такое это свойство $R$ с точки зрения теории множеств? Вот формальный ответ:

\dfn Бинарное отношение на множестве $X$ это подмножество $R \subseteq X\times X$.
\edfn
Действительно, если взять пару $x,y$, то $x R y$ истинно, если $(x,y)\in R$. Понятно, что таким образом кодируется абсолютно любое свойство $R$.

\exm \\
1) Отношение сравнимости $a\equiv b \mod n$ на $\mb Z$ по фиксированному модулю $n$.\\
2) Отношение дружить друг с другом на множестве всех людей.\\
3) Отношение делимости на множестве натуральных чисел.\\


Посмотрим на другое определение:

\dfn Ориентированным графом (возможно с петлями) $G$ называется пара множеств $V$, $E$, где $E \subseteq V \times V$. Множество $V$ называется множеством вершин, а множество $E$ -- множеством рёбер.
\edfn



Видно, что оба эти определения идентичны, точнее задать отношение на множестве $X$ это тоже самое, что задать ориентированный граф с множеством вершин $X$. Это замечание позволяет связать с каждым отношением $R$ на $X$ картинку -- элементы множества $X$ обозначаются точками, и две точки $x$ и $y$ соединяются стрелкой $x \to y$, если $x R y$.



\dfn Пусть  $R$ -- отношение на $X$. Тогда\\
1) Если $\forall a \in X$ верно $a R a$, то $R$ называется рефлексивным. Рефлексивность означает, что на картинке у каждой вершины будет нарисована петелька. Следовательно для заведомо рефлексивных отношений петельки можно не рисовать.\\
2) Если $\forall a,b \in X$ верно, что если $a R b$, то $b R a$, то отношение $R$ называется симметричным. На картинке это означает, что все стрелочки двусторонние. В этом случае вместо стрелок рисуют просто отрезки.\\
3) Если $\forall a,b,c \in X$ верно, что в случае $aR b $ и $b R c$ выполнено, что $a R c$, то отношение $R$ называется транзитивным.\\
4) Если $\forall a,b \in X$, где $a\neq b$, верно, что если $a R b$, то $b \notin R a$, то отношение $R$ называется антисимметричным. На картинке это означает, что все стрелочки направлены в одну сторону.\\
\edfn

Это довольно Теперь сформулируем два наиболее осмысленных типа отношений, которые будут встречаться нам в дальнейшем. Первое из них отвечает интуитивному пониманию, что значит упорядочить элементы множества



\dfn Пусть $X$ --- множество, $\leq$ --- бинарное отношение на нём. Будем говорить, что $\leq$ --- отношение порядка, если выполнены свойства\\
1)  $\forall a \in X$ верно $a \leq a$. Это свойство называется рефлексивностью.\\
2)  $\forall a,b,c \in X$ верно, что в случае $a \leq b $ и $b \leq c$ выполнено, что $a \leq c$. Это свойство называется транзитивностью.\\
3)  $\forall a,b \in X$, если одновременно $a\leq b$ и $a \leq b$, то $a=b$. Это свойство называется антисимметричностью.\\
Множество $X$ вместе с таким отношением $\leq$ называется частично упорядоченным множеством.
\edfn

\exm \\
1) Множества $\mb Z$, $\mb Q$, $\mb R$ относительно обычного порядка.\\
2) Множество натуральных чисел, относительно делимости $a | b$.\\
3) Множество яблок, относительно такого порядка: яблоко $x$ меньше или равно яблока $y$, если площадь поверхности яблока $x$ занятая красным цветом, $redarea(x)$ строго меньше $redarea(y)$ или, если  $x=y$. Нельзя поставить здесь вместе $<$ отношение $\leq$, так как тогда нарушится симметричность. Но тогда для рефлексивности надо добавить условие про равенство.\\
4) Если $X$ -- частично упорядоченное множество, а $A \subseteq X$, то на $A$ можно ограничить порядок, говоря, что $a\leq b$, если это отношение было выполнено для них, как для элементов $X$.\\
5) Множество $2^X=\{A\,|\, A \subseteq X\}$ всех подмножеств множества $X$ относительно включения $\subseteq$.\\
6) Множество $\mb N \times \mb N$ относительно порядка $(a,b) \leq (c,d)$, если $a\leq c$ и $b\leq d$.\\
7) Множество $\mb N \times \mb N$ относительно порядка $(a,b) \leq_{lex} (c,d)$, если $a<c$ или $a=c$ и при этом $b\leq d$\\



Вот пример полезного определения (которого не было на лекции) определяемого через отношение порядка.


\dfn[Наибольший и наименьший элемент] Пусть $X$ -- частично упорядоченное множество. Элемент $x\in X$ называется наименьшим, если $\forall y \in X$  выполнено, что $x\leq y$. Аналогично определяется наибольший  элемент.
\edfn









Часто бывают ситуации, когда с объектами обладающими одним и тем же свойством хочется работать как с одним. Например, если некоторая конструкция применима для всех зданий с одинаковой высотой, то стоит объявить такие здания эквивалентными, если речь идёт об этой конструкции. Аксиоматизируем, что бы мы хотели от такого отношения:

\dfn Пусть $X$ --- множество, $\sim$ --- бинарное отношение на нём. Будем говорить, что $\sim$ --- отношение эквивалентности, если\\
1) $\forall a \in X$ верно $a \sim a$.\\
2) $\forall a,b \in X$, если $a\sim b$ то и $b \sim a$. Это свойство отношения называется симметричностью.
3)  $\forall a,b,c \in X$ верно, что в случае $a \sim b $ и $b \sim c$ выполнено, что $a \sim c$.
\edfn




\exm \\
1) Отношение сравнимости по модулю $n$, то есть $a\equiv b \mod n $, является отношением эквивалентности на $\mb Z$.\\
2) Множество пар вещественных чисел $\mb R \times \mb R$ обладает, например, таким отношением эквивалентности $(x,y)\sim (u,v)$, если $x-y=u-v$.\\
3) Множество прямых на плоскости и отношение быть параллельным.\\
4) Пусть $G=(V,E)$ -- ориентированный граф с петлями. Тогда можно задать отношение эквивалентности на множестве вершин -- быть соединённым путём из неориентированных рёбер $G$. По-другому это называют "лежать в одной компоненте связности". Так же на это определение можно посмотреть так: мы научились по каждому бинарному отношению строить отношение эквивалентности. Более того -- это наименьшее отношение эквивалентности, которое содержит исходное.\\
5) Множество домов и отношение быть одинаковой высоты.\\
6) А вот отношение "Дружить" не является отношением эквивалентности. Если на симметричность ещё можно надеяться, то с транзитивностью часто бывают проблемы. \\





\dfn Пусть $\sim $ отношение эквивалентности на $X$. Тогда классом эквивалентности элемента $x\in X$ называется множество $\ovl{x}=\{y \in X\,|y\sim x\}$. 
\edfn

\rm Все элементы в классе $\ovl{x}$ эквивалентны друг другу.
\erm 

\fct Всякий элемент $x\in X$ лежит в каком-то классе эквивалентности.  Иными словами, объединение всех классов эквивалентности есть всё множество $X$.  Два класса эквивалентности либо не пересекаются либо совпадают. В такой ситуации будем говорить, что множество $X$ раскладывается в дизъюнктное объединение, в данном случае, классов эквивалентности.
\efct
\proof Первое утверждение тривиально -- всякий элемент лежит в своём классе эквивалентности. Покажем, что если два класс $\ovl{x}$  и $\ovl{y}$ пересекаются, то они совпадают. Для этого покажем, например, включение $\ovl{x}\subseteq \ovl{y}$. Пусть $z\in \ovl{x}\cap \ovl{y}$. Тогда $z\sim x$ и $z\sim y$. Если теперь $x' \sim x$, то $x'\sim x\sim z\sim y$, откуда по транзитивности получаем, что $x'\sim y$, что  и требовалось.
\endproof

\dfn Обозначим за $X/\!\sim$ множество всех классов эквивалентности по отношению $\sim$. Это множество называется фактормножеством $X$ по отношению $\sim$. Есть естественное сюръективное отображение $X\to X/\!\sim$. Класс элемента $x\in X$ я буду обозначать как $\ovl{x}$ или просто как $x$, если из контекста ясно, что нужно взять именно элемент фактормножества.
\edfn

\exm\\
1) Для отношения сравнимости по модулю $n$ классы эквивалентности выглядят как $\{a+kn\,|\, n \in \mb Z\}$. Количество различных классов эквивалентности равно $n$. Они однозначно соответствуют числам от $0$ до $n-1$ -- различным остаткам от деления.\\
2) Если $G$ -- ориентированный граф возможно с петлями, то фактор множества вершин по отношению быть соединённым путём по неориентированным рёбрам в $G$ есть множество компонент связности.\\
3) Множество классов эквивалентности для отношения параллельности для прямых континуально. Каждому такому классу однозначно соответствует угол $0\leq \ffi<\pi $ между каждой прямой и 


Введём специальное обозначение для нашего главного героя.

\dfn Пусть $n\in \mb N$. Тогда отношение фактор множества $\mb Z$ по отношению сравнимости по модулю $n$ обозначается как $\mb Z/n\mb Z$ или просто $\mb Z/n$ и называется множеством классов вычетов по модулю $n$.
\edfn

Даже если в определении некоторого понятия участвует понятие фактормножества, при конкретных вычислениях никто не представляет классы эквивалентности. Вместо этого часто для каждого класса выбирают какого-то его канонического представителя и вместо класса целиком проводят все определения и действия с этими самыми представителями. 

\dfn Пусть $X$ -- множество, $\sim$ -- отношение эквивалентности. Тогда $T\subseteq X$ называется полной системой представителей или трансверсалью для отношения $\sim$, если для каждого $x \in X$ существует единственный $c\in T$, что $x\sim c$. Иными словами, в каждом классе эквивалентности лежит ровно один элемент из $T$.
\edfn

Например, при вычислении в кольце остатков по модулю $n$ думают не про классы эквивалентности, а про числа от $0$ до $n-1$ ровно по той причине, что в каждом классе эквивалентности есть ровно одно число от $0$ до $n-1$.

Выбор представителя в классе эквивалентности --- дело вкуса и удобства, однако есть несколько советов, как можно сделать этот выбор. Например, если множество $X$ было упорядочено. Тогда в классе эквивалентности можно выбрать в качестве представителя наименьший элемент (если он, конечно есть) или наименьший с каким-нибудь свойством. Так для отношения сравнимости по модулю $n$ на целых числах канонические представители выбираются как наименьшие неотрицательные числа в классе эквивалентности.


Однако в теоретических вопросах работать с классами эквивалентности довольно удобно. Покажем это на примере $\mb Z/n$. А именно, введём на этом множестве аналогичные сложению и умножению операции. Однако прежде всего дадим определение.

\dfn Бинарной операцией на множестве $X$ называется отображение $f \colon X \times X \to X$.
\edfn

Введём на множестве $\mb Z/n$ две бинарные операции $+$ и $\cdot$ по следующему правилу:\\
$$ \ovl{a}+\ovl{b}=\ovl{a+b} \text{ и } \ovl{a}\cdot \ovl{b}= \ovl{a\cdot b}.$$
Здесь есть небольшая проблема. Представим себе, что мы хотим посчитать эти операции два двух классов $A$ и $B$. Заметим, что в качестве представителей этих классов по определению можно взять  разные элементы $a\in A$ и $b\in B$. Сумма $a+b$ и произведение $ab$ зависят от этого выбора, так что априори и классы $\ovl{a+b}$  и $\ovl{ab}$ могут от такого выбора зависеть. Наша задача показать, что это определение корректно, то есть, что результат не зависит от выбора представителей.

Действительно, пусть $c,d$ -- другие представители классов $\ovl{a}$ и $\ovl{b}$, то есть $a\equiv c$ и $b\equiv d$. Тогда как мы знаем $a+b\equiv c+d \mod n$ и $ab\equiv cd \mod n$. Но это и означает, что мы получили элементы из тех же классов эквивалентности. 

Какие свойства наследуют эти операции от операций над целыми числами? Практически все базовые свойства <<раскрытия скобочек>>:\\
1) Ассоциативность: для всех $a,b,c \in \mb Z/n$ верно $(a+b)+c=a+(b+c)$.\\
2) Существование нейтрального: существует $0\in \mb Z/n$, такой что $\forall a \in \mb Z/n$ верно $a+0=0+a=a$. Таким свойством обладает класс нуля  $\ovl{0}$.\\
3) Существование обратного: $\forall a \in \mb Z/n$ существует $-a \in \mb Z/n$, что $a+(-a)=(-a)+a=0$.\\
4) Коммутативность сложения: $\forall a,b \in \mb Z/n$ верно $a+b=b+a$.\\
5) Дистрибутивность: $a(b+c)=ab+ac$ и $(b+c)a=ba+ca$.\\
6) Ассоциативность умножения: $(ab)c=a(bc)$\\
7) Существование нейтрального относительно умножения: $\exists 1 \in \mb Z/n$, что $\forall a \in \mb Z/n$ выполнено $1\cdot a= a\cdot 1=a$.\\
8) Коммутативность умножения: $ab=ba$.\\

\rm Если бы мы вводили операции не на классах, а на их представителях -- числах от $0$ до $n-1$, то сложение определялось бы так 
$$a+_n b = \begin{cases}a+b, \text{ если } a+b<n\\
a+b-n, \text{ если } a+b\geq n
\end{cases}$$
Попробуйте проверить ассоциативность сложения по такому определению!
\erm

Для каждого числа $n$ мы получили множество с двумя бинарными операциями. Это вынуждает нас ввести общее определение для того, чтобы мы могли исследовать все эти множества и другие аналогичные объекты одновременно, не разбираясь с каждым по отдельности.






\chapter{Базовые алгебраические структуры}

Из всех свойств операций для остатков и целых чисел только свойство дистрибутивности задействует две операции сразу, все остальные свойства относятся только к одной операции. 
\rm Если операция обозначается как $\cdot$ или похожим образом, то её обычно называют умножением. Обозначение операции $\cdot$ часто опускают и вместо $a\cdot b$ пишут просто $ab$. Если же операция обозначается похожим на $+$ способом, то она называется сложением. По умолчанию используется обозначение умножения $\cdot$.
\erm
Пусть $\cdot\colon X \times X \to X$ -- бинарная операция.
Тогда:\\
{\bf\noindent 1)} Такая операция  называется ассоциативной, если $\forall a,b,c\in X$ выполнено $(a\cdot b) \cdot c=a\cdot (b \cdot c)$.
\rm
Благодаря ассоциативности операции в произведении нескольких элементов можно не расставлять скобки.
\erm
{\bf\noindent 2)} Операция умножения коммутативна, если $\forall a,b \in X$ выполнено $a\cdot b= b\cdot a$

{\bf\noindent 3)} Относительно умножения существует нейтральный, если $\exists e \in X$ такой, что $\forall a\in G$ верно $a\cdot e= e\cdot a= a$.
\rm Если нейтральный элемент существует, то он единственен. Действительно, пусть есть два нейтральных элемента $e_1$ и $e_2$. Тогда имеем $e_1=e_1\cdot e_2=e_2$. Для получения левого равенства мы воспользовались нейтральностью $e_2$, а для получения правого -- нейтральностью $e_1$.
\erm
{\bf\noindent 4)} Если относительно операции умножения на $X$ есть нейтральный элемент $e$, то будем говорить, что элемент $x\in X$ называется обратимым относительно этой операции, если $\exists x^{-1} \in X$, такой что $x\cdot x^{-1}=x^{-1}\cdot x=e$. Такой элемент $x^{-1}$ называется обратным. 

\rm Если обратный элемент относительно операции умножения есть, то он единственен. Действительно, пусть   есть два элемента $y_1$ и $y_2$ из $X$, являющиеся обратными к $x\in X$. Тогда
$$y_1= y_1\cdot 1=y_1(xy_2)=(y_1x)y_2=y_2.$$
\erm

\rm Если есть два обратимых элемента, то их произведение тоже обратимо. Действительно, покажем, что $(xy)^{-1}= y^{-1}x^{-1}$. 
В самом деле 
$$xyy^{-1}x^{-1}= x\cdot 1\cdot x^{-1}=e.$$
Аналогично для произведения с другой стороны.
\erm



\section{Группы}

\dfn[Группа] Пусть $G$ множество на котором задана бинарная операция $\cdot \colon G \times G \to G$. Тогда $G$ вместе с этой операцией называется группой если \\
1) $\cdot$ ассоциативна.\\
2) Существует нейтральный относительно $\cdot$.\\
3) Любой элемент $x\in G$ обратим.
\edfn

Часто говорят, что $G$ -- группа, опуская информацию об операции, если это не приводит к коллизии. Коллизия может произойти, когда на одном и том же множестве заданы две разные операции, относительно которых это множество является группой. Но  такое бывает крайне редко.

\dfn[Абелевы группы] Пусть $G$ -- группа. $G$ называется абелевой группой если \\
4) Для всех $a,b \in G$ выполнено $ab=ba$. То есть операция коммутативна.
\edfn

Операция в абелевых группах часто называется суммой и обозначается как $+$ вместо $\cdot$. В свою очередь нейтральный элемент обозначается как $0$ (вместо $1$ или $e$), а обратный к $a$ как $-a$ (вместо $a^{-1}$).

\exm\\
а) На одноэлементном множестве $G=\{e\}$ можно единственным образом ввести операцию и она-таки удовлетворяет всем свойствам. Это тривиальный пример\\
б) Группа целых чисел $\mb Z$, рациональных $\mb Q$ и вещественных $\mb R$ относительно сложения.\\
в) Пусть $X$ -- множество. Рассмотрим множество $S_X=\{f\colon X\to X\,|\, f \text{ биекция }\}$. Заметим, что композиция биекций -- снова биекция. Действительно $(f\circ g)^{-1}=g^{-1}\circ f^{-1}$. Таким образом, на $S_X$ определена операция $(f,g)\to f \circ g$. Заметим, что  композиция отображений ассоциативна. Нейтральным элементом является тождественное отображение, а обратным относительно композиции -- обратное отображение. Таким образом, $S_X$ образует группу относительно композиции.



Основной лазейкой, при помощи которой группы попадают в этот мир является понятие подгруппы.

\dfn[Подгруппа] Пусть $G$ -- группа, а $H$ -- её подмножество. Тогда $H$ называется подгруппой если\\
1) $\forall a,b \in H$ выполнено, что $ab \in H$. Это свойство называется замкнутостью относительно операции.\\
2) Нейтральный элемент группы $G$ лежит в $H$.\\
3) $\forall a \in H$ выполнено, что $a^{-1} \in H$.
\edfn

\rm Первое свойство позволяет ограничить умножение с $G$ на $H$. Два других свойства гарантируют существование нейтрального и обратного. Ассоциативность наследуется автоматически.
\erm

\noindent г) Рассмотрим множество изометрий плоскости $Isom_{\mb R^2}=\{f\colon \mb R^2\to \mb R^2\,|\, f \text{ изометрия (движение) } \}$. Последнее означает, что $f$ -- биекция и $\forall x,y \in \mb R^2$ верно, что $\dist(x,y)=\dist(f(x),f(y))$, где $\dist$ -- обычное расстояние между точками плоскости. Это подгруппа в $S_{\mb R^2}$. Прежде всего легко заметить, что композиция таких отображений тоже сохраняет расстояние и тождественное отображение сохраняет расстояние. Дальше заметим, что обратное отображение сохраняет расстояние. Действительно $$\dist(f^{-1}(x),f^{-1}(y))=\dist(f(f^{-1}(x)),f(f^{-1}(y)))=\dist(x,y).$$
\noindent д) Рассмотрим множество изометрий сохраняющих фиксированную точку $x_0$ на плоскости. Это подгруппа в $Isom_{\mb R^2}$.

\dfn[Произведение групп] Пусть $G$ и $H$ две группы. Тогда введём на  их декартовом произведении $G\times H$ структуру группы определив умножение покомпонентно 
$$(g_1,h_1)\cdot(g_2,h_2)=(g_1g_2, h_1h_2).$$
\edfn


\rm Единицей этой группы будет элемент $(e,e)$. Обратным к элементу $(g,h)$ будет $(g^{-1},h^{-1})$.
\erm



\dfn Пусть $x \in G$ -- элемент группы, а $n\in \mb Z$. Тогда определим $$x^n=\begin{cases}
x\cdot \dots \cdot x, \text{ $n$ раз } n>0\\
e, n=0\\
(x^{-1})^{|n|}, n<0
\end{cases}$$
\edfn

\upr Проверьте, что $x^{n+m}=x^nx^m$. Покажите, что при гомоморфизме $f(x^n)=f(x)^n$ для всех целых $n$.
\eupr






\section{Кольца}

Нашей текущей задачей будет введение понятия кольца, 

\dfn[Кольцо] Кольцом называется множество $R$ вместе со введёнными на нём операциями сложения $+\colon R\times R \to R$ и умножения $\cdot \colon R \times R \to R$ со свойствами:\\
1) $(R,+)$ – абелева группа.\\
2) $\forall a,b,c \in R$ верно, что $(a+b)\cdot c= a\cdot c+ b\cdot c$ и  $c\cdot (a+b)= c\cdot a+ c\cdot b$. Это свойство дистрибутивности.
\edfn

Редко кто рассматривает теорию для произвольных колец.

\dfn[Коммутативное ассоциативное кольцо с единицей] Пусть $R$ --- кольцо. Мы будем обращать внимание на следующие свойства:\\
а) Существование нейтрального (единицы) относительно умножения. Кольцо с таким элементом называется кольцом с единицей.\\
б) Ассоциативность умножения. Кольцо в котором умножение ассоциативно называется ассоциативным. \\
в) Коммутативность умножения. Кольцо с таким свойством называется коммутативным.\\
Если выполнены все три свойства, то кольцо $R$ называется ассоциативным коммутативным кольцом с единицей.
\edfn





\lm[Общие свойства] Пусть $R$ — кольцо. Тогда \\
1) $\forall b \in R$  $0\cdot b = b\cdot 0 = 0$;\\
2) $\forall a,b \in R$  $a\cdot(-b) = (-a)\cdot b = -ab$.\\
3) Если $R$ -- кольцо с единицей то $\forall a \in R$  $(-1)\cdot a = a\cdot (-1) = -a$.
\elm





\exm \\
Примерами колец являются:\\
а) целые числа $\mb Z$;\\
б) рациональные $\mb Q$;\\
в) вещественные $\mb R$;\\
г) Пусть $X$ – некоторое множество, $R$ – кольцо. Рассмотрим множество всех функций $R^X=\{f\colon X \to R\}$. Это кольцо относительно поточечных операций сложения и умножения. Точнее определим 
$$(f+g)(x)=f(x)+g(x) \text{ и } f\cdot g(x)=f(x)g(x).$$
е) Кольца остатков $\mb Z/n$.\\
ё) Рассмотрим пример некоммутативного кольца. Пусть $R$ -- кольцо. Рассмотрим множество троек $R\times R\times R$ и определим на нём структуру кольца по следующему правилу:
$$(a,b,c) + (a',b',c')=(a+a',b+b',c+c') \text{ и } (a,b,c) \cdot (a',b',c')=(a\cdot a',ab'+bc',c\cdot c').$$
Заметим, что произведение элементов $(1,0,0)$ и $(0,1,1)$ разное в зависимости от порядка.\\
ж) Определим произведение колец
\dfn Пусть $R_1, R_2$ -- два кольца. Тогда введём на  их декартовом произведении $R_1\times R_2$ структуру кольца определив операции покомпонентно 
$$(r,u)+(s,v)=(r+s,u+v) \text{ и } (r,u)\cdot(s,v)=(rs, uv).$$
\edfn

\rm
Если $R_1,R_2$ -- 1) ассоциативные, 2) коммутативные, 3) с единицей, то и $R_1\times R_2$  тоже 1) ассоциативное, 2) коммутативное, 3) с единицей, соответственно.
\erm

\dfn[Подкольцо] Пусть $R$ - кольцо. Подкольцом в $R$ называется подмножество $R'$, на которое можно
ограничить операции. Тонкость состоит в том, что если $R$ было кольцом с единицей, то от $R'$ так же требуют, чтобы оно содержало ту же единицу. Морально стоит считать, что взятие единицы так же является операцией (только от нуля аргументов).
Формально это означает, что\\
а) $R'$ -- подгруппа $R$ по сложению\\
б) $\forall a,b\in R'$ должно быть верно $a\cdot b \in R'$ \\
В случае колец с единицей отдельно требуют\\
в) $1\in R'$.
\edfn



\rm Например, множество вещественных чисел вида 
$$\mb Z[\sqrt{2}]=\{a+b\sqrt{2}\,|\, a,b \in \mb Z\} $$
является подкольцом (с единицей) в $\mb R$. Это обозначение читают так: << $\mb Z$ от корня из двух >> или << $\mb Z$ с добавленным корнем из двух>>. 
\erm




Приведём ещё два примера колец, которые понадобятся нам в дальнейшем, а именно кольцо многочленов и кольцо
формальных степенных рядов.



\dfn[Кольцо многочленов] Пусть $R$ – некоторое кольцо. Определим кольцо многочленов $R[x]$ от
одной переменной как кольцо состоящее из выражений вида
$$a_0+a_1x+a_2x^2+\dots+a_nx^n,$$
где все коэффициенты $a_i\in R$. Сложение двух таких выражений происходит покоэффициентно, а умножение однозначно определяется правилом раскрытия скобок и равенством $x^n\cdot x^m=x^{n+m}.$ Точнее для двух многочленов $f(x)=a_0+\dots+a_nx^n$ и $g(x)=b_0+\dots+b_mx^m$ выполнено
$$f(x)g(x)= (a_0b_0)+ \dots+\sum_{i+j=k}a_ib_j x^k+\dots+a_nb_mx^{n+m}$$
\edfn

\dfn[Кольцо формальных степенных рядов] Аналогично определим кольцо формальных степенных рядов как кольцо выражений
$$a_0+a_1x+a_2x^2+\dots+a_nx^n+\dots,$$
где операции определены тем же способом, что и в кольце многочленов.
\edfn

Однако, в таком определении чувствуется нестрогость. Поэтому дадим формальные определения, выписав явно формулу для коэффициентов суммы и произведения двух таких выражений.

\dfn[Кольцо формальных степенных рядов и кольцо многочленов, дубль два] Пусть $R$ -- кольцо. Кольцом формальных степенных рядов над $R$ назовём множество последовательностей $\{(a_0,\dots,a_n, \dots)\,|\, a_i\in R\}$ вместе с операциями:
$$ (a+b)_n=a_n+b_n, \, \text{ и } \, (a\cdot b)_n=\sum_{i+j=n}a_ib_j.$$
Кольцо формальных степенных рядов обозначается $R[[x]]$. Кольцом многочленов над $R$ назовём подкольцо в $R[[x]]$,
состоящее из элементов $a=(a_0,\dots,a_n,\dots)$ таких, что все кроме конечного числа $a_i$ равны $0$.
\edfn

Дав формальное определение я должен бы был проверить, что выполнены все требуемые аксиомы (свойства сложения, дистрибутивность) и то, что $R[x]$ -- подкольцо. Это упражнение на раскрытие скобок, которое я предпочитаю опустить для того, чтобы сохранить ясность происходящего. Так же

\rm Если $R$ -- 1) ассоциативное, 2) коммутативное, 3) с единицей, то $R[x]$ и $R[[x]]$ тоже 1) ассоциативное, 2) коммутативное, 3) с единицей, соответственно.
Единицей в $R[x]$ и $R[[x]]$ будет элемент вида $1(x)=1=1+0\cdot x+0\cdot x^2+\dots$.
\erm


\section{Гомоморфизмы}

Если мы хотим сравнить два множества между собой, то мы строим отображение между ними. Что делать, если у нас не просто множества а группы?

\dfn[Гомоморфизм] Пусть $G$ и $H$ -- группы. Отображение $f\colon G\to H$ называется гомоморфизмом групп, если $f(ab)=f(a)f(b)$. 
\edfn

\lm[Свойства] Пусть $f\colon G \to H$ -- гомоморфизм групп. Тогда\\
1) $f(e)=e$\\
2) $f(x^{-1})=(f(x))^{-1}$\\
3) $f(x^n)=f(x)^n$ для всех натуральных $n$.
\proof $f(e)=f(e\cdot e)=f(e)f(e)$. Осталось домножить на $f(e)^{-1}$.
Далее $e=f(e)=f(xx^{-1})=f(x)f(x^{-1})$. Аналогично про произведение $f(x^{-1})f(x)$. Третье очевидно
\endproof
\elm

\dfn[Изоморфизм] Гомоморфизм $G\to H$ называется 1) мономорфизмом 2) эпиморфизмом 3) изоморфизмом, если он 1) инъективен, 2) сюръективен, 3) биективен соответственно.
\edfn

\rm Обратное отображение к изоморфизму -- тоже изоморфизм.
\erm

\exm\\
а) Отображение $\mb Z \to\mb Z/n$, заданное правилом $x\to \ovl x$ является эпиморфизмом.\\
б) Отображение $\mb Z/nm \to \mb Z/n$, заданное правилом $\ovl{x} \to \ovl{x}$ корректно и является эпиморфизмом.\\
в) Отображение $\mb Z/n \to \mb Z/nm$, заданное правилом $\ovl{x}\to \ovl{mx}$ корректно и является мономорфизмом.\\
г)  Отображение $\mb Z \to \mb Z$, заданное правилом $x \to ax$ является гомоморфизмом при любом $a\in \mb Z$, мономорфизмом при $a\neq 0$ и изоморфизмом при $a=\pm 1$.\\
д)  Отображение $\mb R \to \mb R$, заданное правилом $x \to ax$ является гомоморфизмом при любом $a\in \mb R$,  и изоморфизмом при $a\neq 0$.\\
е) Отображение $\mb Z/nm \to\mb Z/n\times \mb Z/m$ заданное правилом $\ovl{x}\to (\ovl{x},\ovl{x})$ является изоморфизмом групп если $(n,m)=1$ по китайской теореме об остатках.\\



Мы обсудили, что некоторые группы могут иметь альтернативное, более простое описание. Оформлено это замечание было в виде понятия изоморфизма групп. Чуть позже к нему добавилось понятие гомоморфизма, как способ просто связать, а не «приравнять» две структуры. Аналогичное определение есть и для колец.

\dfn[Гомоморфизм колец] Пусть $R$ и $S$ --- два кольца. Гомоморфизмом из $R$ в $S$ называется отображение $f\colon R \to S$, что
$\forall a,b \in R$ выполнено 
$$f(a+b)=f(a)+f(b)\text{  и  }f(a\cdot b)=f(a) \cdot f(b).$$
Если кольца $R$ и $S$ с единицей, то естественно дополнительно потребовать $f(1) = 1$. Сюръективные, инъективные, биективные гомоморфизмы называются эпи-, моно- и изоморфизмами соответственно.
\edfn

Отметим сразу два базовых свойства гомоморфизмов колец:

\lm Пусть $f\colon R \to S$  и $g\colon S \to T$ --- гомоморфизмы колец. Тогда $g\circ f\colon R \to T$ так же гомоморфизм
колец. Если $f$ — изоморфизм, то отображение $f^{-1}$ --- гомоморфизм (и, следовательно, изоморфизм). Тождественное отображение всегда гомоморфизм колец.
\elm
\proof Докажем про гомоморфность обратного. Пусть есть $a,b \in S$. Тогда $f(f^{-1}(a)\cdot f^{-1}(b))=f(f^{-1}(a))\cdot f(f^{-1}(b))=a\cdot b$. Тогда элемент $f^{-1}(a)\cdot f^{-1}(b)$ есть прообраз $a\cdot b$. Сумма --- аналогично.
\endproof



\section{Группа обратимых элементов}

\dfn[Обратимый элемент] Пусть $R$ — ассоциативное кольцо с единицей. Элемент $a\in R$ называется обратимым, если он обратим относительно умножения.
\edfn

\lm[Группа обратимых элементов] Пусть $R$ --- ассоциативное кольцо с единицей. Множество всех обратимых элементов $R^*$ образует группу относительно умножения.
\elm
\proof Ассоциативность наследуется из ассоциативности умножения на всём кольце, единица есть, т.к. обратна себе. Обратный есть, так как обратный есть в $R$ и лежит в $R^*$ (так как ${x^{-1}}^{-1}=x$).
\endproof

\dfn[Поле] Пусть $R$ -- ассоциативное коммутативное кольцо с единицей и $R\neq \{0\}$. $R$ называется полем, если   любой элемент $ a\in R\setminus\{0\}$ обратим. По другому это означает что множество $R\setminus\{0\}$ есть группа относительно умножения.
\edfn





\noindent Понятие гомоморфизма удобно при описании групп обратимых элементов колец. Дело в том, что умножение в кольцах часто устроено сложнее, чем сложение. Поэтому особенно ценны те ситуации, когда умножение удаётся описать проще. Посмотрим на такие альтернативные описания:\\
а) $\mb Z^* = \{\pm 1\}\cong \mb Z/2$.\\
б) $\mb Q$ -- поле, то $\mb Q^* = \mb Q\setminus\{0\}$. Из этого множества есть гомоморфизм в группу $\Z/2 \times \prod_{p \text{ -- простое }} \Z $. Группа $\mb Q^*$, таким образом, изоморфна подгруппе, состоящей из кортежей, где все, кроме конечного числа, элементы равны нулю.\\
в) Пусть $K=\mb R$. Все вещественные числа не равные нулю либо положительны, либо отрицательны. Кроме того, любое положительное число есть экспонента от единственного вещественного числа. Тогда вещественному не нулевому числу $y$ можно сопоставить пару $(\eps(y), \ln|y|)$. Здесь $\eps(y)=\ovl{0}$, если $y>0$ и $\eps(y)=\ovl{1}$, если $y<0$. Получился изоморфизм групп $$\mb R^*\to \mb Z/2 \times \mb R.$$
Обратный к нему -- это гомоморфизм
$$(\eps,x) \to (-1)^{\eps}\, e^x.$$
\noindent г) C кольцом формальных степенных рядов тоже можно разобраться. 
\lm Пусть $R$ -- ассоциативное коммутативное кольцо с 1. Ряд $f(x) \in R[[x]]$ обратим тогда и только тогда, когда его свободный член обратим.
\elm
\proof Пусть дан ряд $f(x)=a_0+a_1x+\dots$. Для того, чтобы ряд был обратим необходимо, чтобы $a_0$ было обратимо. Действительно, условие $fg=1$, где $g=b_0+b_1x+\dots$, для нулевого коэффициента даёт равенство $1=a_0b_0$.  Теперь покажем в обратную сторону, что если $a_0$ обратим, то и весь ряд обратим. Условие $fg=1$ даёт уравнения на коэффициенты $g$. Первое из них мы уже рассмотрели. Пойдём дальше 
$$0=a_0b_n+a_1b_{n-1}+\dots+a_nb_0.$$
Видно, что если определены $b_0, \dots, b_{n-1}$, то однозначно определено и $b_n=\frac{-1}{a_0}(a_1b_{n-1}+\dots+a_nb_0)$.
\endproof
\noindent д) Элементы $\mb Z/n^*$ однозначно соответствуют остаткам, взаимно простым с $n$. Таким образом, в $\mb Z/n^*$ элементов столько же, сколько в  $\{0 < x< n\,|\, (x,n) = 1\}$. Детальное описание будет позже.\\




\section{Комплексные числа}

\dfn Пусть $L$ -- поле, а $K\subseteq L$ -- подкольцо в $L$, являющееся полем относительно ограничения операций с $L$. Тогда $K$ называется подполем $L$, а $L$ расширением $K$.
\edfn



Покажем, что у многочлена $x^2+1$ есть корни в некотором расширении $\mb R$. Представим себе на секунду, что в некотором расширении вещественных чисел $L$ есть корень $i\in L$ у многочлена $x^2+1$. Тогда в поле $L$ должны лежать и все элементы вида $a+bi$, где $a,b\in \mb R$. Более того, если мы захотим перемножить два числа такого вида, то обязаны получить $$(a+bi)(c+di)=ac+bdi^2+(ad+bc)i=(ac-bd)+(ad+bc)i.$$
Это приводит нас к следующей конструкции:

\dfn[Комплексные числа] Множество $\mb R \times \mb R$ вместе с двумя операциями $$(a,b)+(c,d)=(a+c,b+d)\,\,(a,b)\cdot(c,d)=(ac-bd,ad+bc)$$
называется полем комплексных чисел. Будем обозначать это  поле как $\mb C$.
\edfn

\upr Поле комплексных чисел действительно поле.
\eupr

Исходя из мотивации нашей конструкции обозначим за $i$ пару $(0,1)$. Вещественное число $a\in \mb R$ отождествляется с парой $(a,0)$. Элемент $i$ по самому определению $\mb C$ удовлетворяет соотношению $i^2=-1$. Любой элемент $z$ в $\mb C$ однозначно записывается в виде суммы $z=a+bi$, где $a,b\in \mb R$.  Такая форма записи для комплексного числа будет для нас стандартной. Число $a$ называется вещественной частью числа $z$ и обозначается $a=\re z$, число $b$ --- мнимой частью и обозначается $\im z$.

Единственное, что нам понадобится разобрать из упражнения -- это формула для обратного  к комплексному числу. Для удобства введём понятие модуля комплексного числа и понятие сопряжённого к комплексному числу.

\dfn[Модуль комплексного числа] Рассмотрим комплексное число $z=a+bi\in \mb C$. Тогда модулем комплексного числа $z$ назовём выражение
$$|z|=\sqrt{a^2+b^2}.$$
\edfn

\dfn[Комплексное сопряжение] Пусть $z=a+bi\in \mb C$. Тогда сопряжённым к $z$ числом называется $a-bi=\ovl{z}$.
\edfn

\lm[Формула для обратного] Пусть $z\in \mb C$, $z\neq 0$. Тогда
$$ z^{-1} =\frac{\ovl{z}}{|z|^2}= \frac{a}{a^2+b^2}-i\frac{b}{a^2+b^2}.$$
\elm

Оказывается, что отображение комплексного сопряжения обладает замечательными свойствами.


\dfn[Гомоморфизм колец] Пусть $R$ и $S$ --- два кольца. Гомоморфизмом из $R$ в $S$ называется отображение $f\colon R \to S$, что
$\forall a,b \in R$ выполнено 
$$f(a+b)=f(a)+f(b)\text{  и  }f(a\cdot b)=f(a) \cdot f(b).$$
Если кольца $R$ и $S$ с единицей, то естественно дополнительно потребовать $f(1) = 1$. Биективные гомоморфизмы называются  изоморфизмами.
\edfn


\utv Комплексное сопряжение является автоморфизмом $\mb C$. Более того это единственный нетривиальный автоморфизм, который оставляет на месте $\mb R$.
\eutv
\proof То, что это автоморфизм проверяется непосредственно. Покажем единственность. Для начала докажем простую, но показательную лемму.
\lm[Решение переходит в решение]  Пусть имеются два кольца $R$ и $S$ и гомоморфизм колец $\psi\colon R \to S$. Пусть $a_0+a_1x+\dots+a_nx^n=g(x)\in R[x]$ и $\psi(g(x))=\psi(a_0)+\psi(a_1)x+\dots+\psi(a_n)x^n \in S[x]$.  Если $\lambda$ корень $g(x)$, то $\psi(\lambda)$ -- корень $\psi(g(x))$. 
\elm
\proof Имеем $0=f(\lambda)=a_0+a_1\lambda+\dots+a_n\lambda^n$. Подействуем $\psi$ и раскроем скобки. 
$$0=\psi(0)=\psi(f(\lambda))=\psi(a_0)+\psi(a_1)\psi(\lambda)+\dots+\psi(a_n)\psi(\lambda)^n.$$
\endproof

Пусть теперь дан гомоморфизм $\ffi\colon \mb C \to \mb C$, такой что $\ffi(a)=a$ для всех $a\in \mb R$. Тогда $\ffi(a+bi)=a+b\ffi(i)$. Всё определяется образом $\ffi(i)$ и нас интересует какие бывают варианты. Заметим, что $i$ -- это корень многочлена $x^2+1$. Тогда $\ffi(i)$ должен быть корнем $\ffi(x^2+1)=x^2+1$, то есть того же многочлена.  Но $\mb C$ -- поле и у этого многочлена уже есть два корня -- $\pm i$. Других быть не может. Если мы $i$ отображаем в $i$, то получаем тождественное отображение. Иначе $i\to -i$ и элемент $a+bi$ переходит в $a-bi$. То есть, в случае нетождественного отображения, мы обязаны получить комплексное сопряжение.
\endproof


\rm Модуль комплексного числа может быть выражен через комплексное сопряжение: $|z|=\sqrt{z\ovl{z}}$.
\erm

Такое представление удобно. Например, докажем при его помощи мультипликативность модуля комплексного числа

\utv Пусть $z_1, z_2\in \mb C$. Тогда $|z_1z_2| = |z_1||z_2|$.
\eutv
\proof Правая и левая часть вещественные положительные числа. Достаточно доказать равенство их квадратов. Имеем
$$|z_1z_2|^2=z_1z_2\ovl{z_1z_2}= z_1\ovl{z_1}z_2\ovl{z_2}=|z_1|^2|z_2|^2.$$
\endproof


Комплексное число не определяется своим модулем. Геометрически ясно, что недостающим параметром является угол (ориентированный) между данным комплексным числом и лучом $OX$. Это приводит к новой форме записи комплексного числа.

\dfn[Тригонометрическая форма записи] Рассмотрим ненулевое комплексное число $z= a+bi\in\mb C$. Поделим число $z$ на его модуль. Число
$\frac{z}{|z|}$ лежит на окружности $|z| = 1$. Точки такой окружности имеют вид $\cos\varphi +i\sin\varphi$ для единственного $0 \leq \varphi < 2\pi$. Обозначим выражение $\cos\varphi+i\sin\varphi$ за $e^{i\varphi}$. Тогда $z=re^{i\varphi}$, где $0<r=|z|$.
Такая запись единственна и называется тригонометрической записью комплексного числа. Угол $\varphi$ обозначают $\arg z$ и называют аргументом комплексного числа. На самом деле, нам будет удобно считать, что аргумент комплексного числа определён с точностью до $2\pi$. Иными словами, что это элемент группы $\mb R/2\pi\mb Z$. Аргумент нуля не определён.
\edfn


Почему $e^{i\varphi}$ естественно определить как $\cos\varphi+i\sin \varphi$ ? Основная мотивация для этого есть тождество для рядов  (это эвристическое рассуждение, но его можно сделать строгим).
$$\exp(ix) = \sum_{n=0}^{\infty} \frac{(ix)^n}{n!}=\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n}}{2n!} + i\sum_{n=0}^{\infty} \frac{(-1)^n x^{2n+1}}{(2n+1)!}= \cos(x) + i\sin(x).$$
Возможность подставлять в ряды различные значения вместо формальной переменной вы будете долго обсуждать в рамках курса математического анализа. В частности, во все указанные ряды можно будет подставить любое комплексное число. Так же, если для рядов было выполнено некоторое тождество, то оно будет верно и для функций, которые они задают.
Нас на текущий момент гораздо больше  интересует то обстоятельство, что экспонента сумму переводит в произведение. Так как никаких особенных средств матанализа у нас в распоряжении нет, то постараемся показать это свойство в нашем конкретном случае руками, а заодно посмотреть геометрически, что же происходит.


Вопрос: что происходит с аргументом при домножении на другое комплексное число, в частности на число вида $\cos \varphi + i \sin \varphi$? 

\thrm Пусть $z_1$ и $z_2$ -- два комплексных числа, отличных от нуля. Тогда $\arg z_1z_2= \arg z_1+ \arg z_2$.
\ethrm
Дадим два доказательства этой теоремы \proof[Первое доказательство.] Можно считать, что $|z_1|=|z_2|=1$. Тогда $z_1=\cos \alpha+i\sin \alpha$, а $z_2=\cos \beta + i\sin \beta$. Перемножив получаем:
$$z_1z_2=\cos \alpha \cos\beta - \sin\alpha \sin \beta+ i(\cos \alpha \sin\beta + \sin\alpha \cos \beta)= \cos (\alpha+\beta)+i\sin(\alpha+\beta).$$
Что и требовалось.
\endproof

Второе доказательство хорошо тем, что не использует тригонометрических формул, а лишь использует понятие движения (изометрии) и некоторые базовые свойства.


\dfn[Расстояние] Расстоянием между комплексными числами $z_1$ и $z_2$ положим равным $|z_1-z_2|$. Это просто обычное расстояние на плоскости.
\edfn

Отображение плоскости, сохраняющее расстояние называется движением или изометрией плоскости. Множество всех изометрий плоскости образует группу относительно композиции. Верен следующий:
\begin{fact} Поворот вокруг точки на некоторый угол есть изометрия плоскости. Изометрия плоскости, имеющая ровно
одну неподвижную точку является поворотом вокруг этой точки.
\end{fact}

Докажем лемму:

\lm[Геометрическая интерпретация] Пусть $z\in \mb C$ число по модулю равное единице. Тогда отображение $\mb C \to \mb C$  заданное правилом $ x\to zx$   является поворотом вокруг точки 0 на угол $\arg z$.
\elm
\proof Пусть $z\neq 1$ (случай $z=1$ соответствует тождественному отображению). Проверим, что домножение на $z$ имеет ровно одну неподвижную точку 0. Действительно, пусть $zz_1=z_1$. Тогда, если $z\neq 1$, то обязательно $z_1= 0$. Очевидно, домножение на $z$ сохраняет расстояние
$$|zz_1-zz_2|=|z(z_1-z_2)|=|z||(z_1-z_2)|=|(z_1-z_2)|.$$
Получается, что домножение на $|z|$ есть поворот. Как узнать угол? Для этого достаточно посмотреть, куда переходит какая-нибудь точка. Например 1. Единица переходит в $z$, то есть точку под углом $\arg z$ к исходной. Значит это поворот на $\arg z$.
\endproof

\proof[Второе доказательство теоремы]
Пусть как и раньше $|z_1|=|z_2|=1$. Тогда по лемме $z_1z_2$ есть $z_2$ повёрнутое на $\arg z_1$, то есть имеет аргумент $\arg z_2+ \arg z_1$.
\endproof

\crl
Домножение на число вида $re^{i\ffi}$, это растяжение в $r$ раз и поворот на угол $\ffi$.
\ecrl

\crl В тригонометрической записи тождество для аргумента смотрится очень естественно 
$$r_1e^{i\ffi_1}r_2e^{i\ffi_2}=r_1r_2e^{i(\ffi_1+\ffi_2)}.$$
\ecrl

\crl[Формула Муавра] Пусть $z\in \mb C$ имеет тригонометрическую запись $z=re^{i\varphi}$. Тогда
$$z^{n}=r^{n}(\cos \varphi +i\sin \varphi )^{n}=r^{n}(\cos n\varphi +i\sin n\varphi ).$$
Эту формулу можно воспринимать, как выражение для косинусов и синусов кратного угла.
\ecrl

То, что тригонометрическая запись числа существует и ведёт себя предсказуемым образом при произведении, позволяет нам более или менее явно построить решения для уравнений некоторого специального вида.

\thrm[Извлечение корней] Пусть $z\in \mb C$, $z=re^{i\varphi}$, $r>0$ . Тогда у уравнения $x^n=z$ есть ровно $n$ различных
решений в $\mb C$, которые задаются формулой
$$ x_k =\sqrt[n]{r} e^{i\frac{\varphi + 2\pi k}{n}} ,\,\, k\in \ovl{0,n-1}.$$
\ethrm
\proof
Прямой проверкой можно установить, что указанные $x_k$ являются корнями уравнения. Необходимо доказать, что они различные. Рассмотрим частное $x_k$ и $x_l$. Это $e^{i\frac{ 2\pi k- 2\pi l}{n}}$. Так как $\frac{k-l}{n}$ не есть целое число, то аргумент $x_k/x_l$ не равен нулю и, значит, это отношение не единица.
\endproof

\dfn Пусть $R$ -- кольцо. Тогда элемент $x\in R$, такой что $x^n=1$ называется корнем степени $n$ из единицы.
\edfn

\rm Числа вида $e^{i\frac{2\pi k}{n}}$ являются корнями степени $n$ из единицы в $\mb C$.
\erm

\dfn Пусть $K$ -- поле. Тогда $\xi\in K$ -- корень степени $n$ из единицы  называется первообразным корнем степени $n$ если его порядок в $ K^*$ ровно $n$. (Для колец более сложное определение).
\edfn

\rm Элементы $e^{i\frac{2\pi k}{n}}$, где $(k,n)=1$ являются первообразными корнями из единицы в $\mb C$.
\erm


При решении задачи очень часто бывает, что сам факт существования того, о чём идёт речь вообще говоря является не очевидным. Например, далеко не каждая функция имеет на отрезке минимум и следовательно задача поиска минимального значения функции может быть просто не корректна. Поэтому важно заранее знать, что предмет исследования есть.  В связи с этим можно спросить, а бывает ли так, что есть поле, такое что каждый многочлен с коэффициентами из этого поля имеет корень в нём?

Ответ — да, такое поле есть. Первый и основной такой пример --- это как раз поле комплексных чисел.
\dfn[Алгебраическая замкнутость] Поле $K$ называется алгебраически замкнутым, если у любого многочлена  $f(x)\in K[x]$, отличного от константы, в $K$ найдётся его корень.
\edfn

\thrm[Основная теорема алгебры] Поле $\mb C$ алгебраически замкнуто.
\ethrm

Не совсем понятно, насколько это основная теорема. На такое звание она тянула в начале девятнадцатого века. На самом деле не совсем понятно, насколько это теорема алгебры, потому что в любом её доказательстве используются методы математического анализа. Мы не будем сейчас доказывать эту теорему. Для интересующихся, самое простое доказательство приведено ниже. 





Комплексная экспонента определяется через вещественные тригонометрические функции. На самом деле, во многих вопросах комплексная экспонента удобнее своих вещественных предков. Это определяет популярность экспоненты и намекает на то, что экспонента фундаментальнее, чем её тригонометрические братья.

Приведём пример, как комплексные числа могут помочь в упрощении различных тригонометрических выражений
Рассмотрим сумму $1+ \cos x + \cos 2x + \dots + \cos nx$, где $x > 1$. Вопрос состоит в том, чему она равна в зависимости от $n$. Основной трюк здесь --- заменить непонятные вещественные числа, на их улучшенную комплексную версию. Например, $$\cos x = \frac{e^{ix}+e^{-ix}}{2}, \sin x = \frac{e^{ix}-e^{-ix}}{2i}.$$
В данном случае, проще заметить, что $\cos x=\re e^{ix}$. Тогда
$$1 + \cos x+ \dots + \cos nx = \re(1+ e^{ix} + \dots + e^{inx}) = \re \frac{e^{i(n+1)x}-1}{e^{ix}-1}$$
Теперь необходимо привести выражение к виду, не содержащему комплексных чисел.
$$\re \frac{e^{i(n+1)x}-1}{e^{ix}-1} = \re e^{i\tfrac{n+1}{2}x}\cdot e^{-i\tfrac{x}{2}}\frac{\sin \tfrac{n+1}{2}x}{\sin\tfrac{x}{2}}=\frac{ \sin \tfrac{n+1}{2}x}{\sin\tfrac{x}{2}} \re e^{\tfrac{inx}{2}}=
\frac{\cos \tfrac{nx}{2} \sin \tfrac{n+1}{2}x}{\sin\tfrac{x}{2}}$$







\subsection*{Дополнение: доказательство основной теоремы алгебры}

\begin{thmm}[Основная теорема алгебры] Поле $\mb C$ алгебраически замкнуто.
\proof Пусть $f$ — многочлен степени $n\geq 1$ в $\mb C[x]$. Будем считать, что старший коэффициент $f$ равен единице. Пусть у этого многочлена нет корней. Рассмотрим функцию $|f|\colon \mb C \to \mb R$. Эта функция непрерывна и не принимает значения 0. Так как $f$ --- многочлен степени $n$, то на бесконечности $|f|$ растёт. Разберёмся точнее. Пусть
$c = |f(z_0)| > 0$ в некоторой точке $z_0$. Я утверждаю, что вне некоторого круга радиуса $R$ с центом в 0 функция
$|f|$ принимает значения строго больше чем $c$. Действительно возьмём $R= M \max(2,c)$, где $M$ --- сумма модулей всех коэффициентов многочлена $f$. Двойка здесь играет роль числа строго большего единицы.
Тогда для поиска инфимума $|f|$ достаточно ограничиться кругом радиуса $R$. Но круг радиуса $R$ --- компактное множество и непрерывная функция $|f|$ достигает на нём минимальное значение в точке $x_0$. Пусть $a_0 =f(x_0)$. Разложим
$f$ по степеням $(x-x_0)$. Тогда имеем
$$f(x) = a_0 + a_k (x-x_0)^k + \dots + a_n(x -x_0 )^n.$$
Здесь $a_k$ --- первый ненулевой коэффициент после $a_0$. Такой есть потому что иначе $f$ --- это константа. Теперь наша
задача понять, что мы можем немного сдвинуться от точки $x_0$ , так, чтобы значение $|f|$ уменьшилось. В районе точки
$x_0$ самое большое слагаемое в разложении $f$ это $a_0 + a_k (x-x_0)^k$ и оно практически полностью определяет поведение $f$.
У этого многочлена есть корень. Обозначим его за $y_0$. Будем двигаться из $x_0$ в направлении $y_0$ и смотреть, что происходит.
Рассмотрим $x_{\eps} = x_0 + \eps(y_0 -x_0 ), \,\eps < 1$. Тогда $x_{\eps} -x_0 = \eps(y_0 -x_0 )$. Тогда
$$|f(x_{\eps})| = |(1 - \eps^k)a_0 + \eps^{k+1} a_{k+1} (y_0 -x_0)^{k+1} + \dots+ \eps^n(y_0-x_0 )^n | \leq (1- \eps^k )|f(x_0)| + \eps^{k+1}N,$$
где $N$ — это некоторая константа не зависящая от $\eps$. Например, можно взять $N = \sum_{i=k+1}^n |a_i||y_0 -x_0 |^i$. Для достаточно
маленьких $\eps$ выражение $ -\eps^k |f(x_0)| + \eps^{k+1}N$ отрицательно. Тогда для всех достаточно маленьких $\eps>0$ выполнено неравенство $|f(x_{\eps})| < |f(x_0)|$.
Противоречие с минимальностью $|f(x_0)|$. \endproof
\end{thmm}





\chapter{Теория делимости}

\section{Области целостности}

\rm Вероятно, все кольца в этом курсе будут ассоциативными с единицей, а большая часть --- коммутативными. Поэтому теперь будем считать, что все кольца коммутативные ассоциативные и с единицей до тех пор, пока не оговорено противное.
\erm

Попробуем обобщить теорию делимости с кольца целых чисел на более широкий класс колец.

Когда мы говорим про делимость целых чисел, мы знаем, что если $a\di b$, то множитель $c$, такой что $a=bc$ определён однозначно, за исключением случая, когда $b=0$. Наверное мы бы хотели такое свойство при построении теории. 

Единственность второго множителя равносильна тому, что из условия $ax=ay$ следует, что $x=y$. Это условие сократимости.

Если $a=0$, то, понятно, что его не стоит ждать. Однако, даже если $a\neq 0$, то, вообще говоря, не для произвольного кольца  следует, что $x=y$. поподробнее.

\dfn[Делитель нуля, нильпотент] Пусть $R$ --- кольцо.\\
1) Элемент $a\in R$ называется делителем нуля, если существует $b\in R$, $b\neq 0$, такой что $ab=0$. Будем говорить, что
$a=0$ --- это тривиальный делитель нуля.\\
2) Элемент $a\in R$ называется нильпотентом, если существует $n\in \mb N$, что $a^n= 0$. $a= 0$ --- тривиальный случай.
\edfn

\dfn[Область целостности] Кольцо $R$ называется областью целостности, если для любых $a,b\in R$,
если $ab=0$, то либо $a = 0$, либо $b= 0$.
\edfn

\lm Кольцо $R$ является областью целостности тогда и только тогда, когда для него выполнена сократимость.
\proof Покажем, что из целостности следует сократимость. Пусть $a\neq 0$ и $ab=ac$. Тогда $a(b-c)=0$. Тогда $b-c=0$. Что и требовалось.
\endproof
\elm


\noindent {\bf Примеры:}
\enm
\item Рассмотрим кольцо $\mb Z/n$.
Пусть так случилось, что $n\in \mb N$ -- составное. Опишем все нетривиальные делители 0 в $\mb Z/n$. Пусть $k \in \mb Z$ такое, что $d=\Nod(k,n)\neq 1$, но и $k \ndi n$.\\
Тогда и $k=ld$ и $\frac{n}{d}$ не равны нулю, как элементы $\mb Z/n$. С другой стороны 
$$k\frac{n}{d}= ld\frac{n}{d}= ln=0 \text{ в $\mb Z/n$}.$$
Например, $n=6$, а $k=4$. Тогда $d=2$, $\frac{n}{d} = 3$. Получаем $4\cdot 3=12=0$ в $\mb Z/6$.
Так как остальные $k$ либо дают ноль по модулю $n$ либо обратимы, то это полное описание.
\item Пусть $n=m^k$ , $m> 1$. Тогда $m$ --- нетривиальный нильпотент в $\mb Z/n$. Например, $3$ в $\mb Z/9$.
\item Поле всегда область целостности.
\item Рассмотрим кольцо функций $R^X$, где $X$ -- некоторое множество, а $R$ -- кольцо. Тогда $R^X$ -- область целостности тогда и только тогда, когда $R$ -- область целостности и $X$ состоит из одного элемента. Прежде всего, если $ab=0$, но $0\neq a,b \in R$ и в $X$ есть хотя бы один элемент $x_0\in X$, то
$$f(x)=\begin{cases} a,\, x=x_0\\
0, \text{ иначе }
\end{cases} 
\text{ и } 
g(x)=\begin{cases} b,\, x=x_0\\
0, \text{ иначе }
\end{cases} 
$$
это нетривиальные делители 0 в $R^X$. Если же $R$ область целостности, но в $X$ есть хотя бы две точки $x_0$ и $y_0$, то
$$f(x)=\begin{cases} 1,\, x=x_0\\
0, \, x=y_0\\
0, \text{ иначе }
\end{cases} 
\text{ и } g(x)=\begin{cases} 0,\, x=x_0\\
1,\, x=y_0\\
0, \text{ иначе }
\end{cases} 
,$$
так же дают нетривиальные делители 0.
\eenm



\subsection{Характеристика кольца}



\dfn Пусть $f\colon R \to S $  -- гомоморфизм колец. Определим ядро гомоморфизма  как $\Ker f=\{ a \in R\,|\, f(a)=0\}$.
\edfn


Рассмотрим различные примеры гомоморфизмов: прежде всего на  глаза бросается пример гомоморфизма $\mb Z\to \mb Z/n$ переводящего элемент $n$ в его класс в $\mb Z/n$. Мы уже отмечали, что это гомоморфизм групп. Осталось заметить, что он так же переводит умножение в умножение. Оказывается, что мы можем легко описать все гомоморфизмы из $\mb Z$ в любое кольцо.


\thrm Пусть $R$ --- кольцо. Тогда существует единственный гомоморфизм из $\mb Z \to R$.
\ethrm

\proof Докажем единственность. Пусть $f\colon \mb Z \to  R$. Тогда $f(1)=1$, но тогда. $f(2)=f(1+1)=f(1)+f(1)$ и других вариантов нет. Аналогично для $n\in \mb N$ верно $f(n)=1+\dots+1$ $n$-раз. Так как $f(-n)=-f(n)$ то для отрицательных чисел тоже никакого выбора.

Из части про единственность мы уже поняли как выглядит гомоморфизм. Положим $$f(n)=\begin{cases}
1+\dots+1 \text{ $n$ раз }, n>0\\
-(1+\dots+1) \text{ взяв $-n$ раз }, n<0\\
0, n=0
\end{cases}.$$

Надо проверить, что это гомоморфизм. Проверим для произведения. Пусть $n,m\in \mb N$ тогда 
$$f(nm)=\sum_{i=1}^{nm} 1= \sum_{j=1}^n 1\cdot f(m)=\Big(\sum_{j=1}^n 1\Big)\cdot f(m)=f(n)\cdot f(m).$$
Остальные случаи следуют из этого. Сумма разбирается аналогично.
\endproof





Такое утверждение позволяет нам определить очень важный инвариант кольца:
\dfn Пусть $R$ --- кольцо. Рассмотрим тот самый единственный гомоморфизм $f\colon \mb Z \to R$. Тогда $\Ker f$
--- это подгруппа в $\mb Z$, то есть имеет вид $n\mb Z$ для некоторого натурального $n$. Это число $n$ называется характеристикой кольца $R$ и обозначается $n=\chr R$. Попросту говоря, характеристика --- это наименьшее число единичек, сложив которые можно получить $0$ (или число $0$, если это невозможно).
\edfn

Очевидно, что характеристика кольца $\mb Z/n$ есть $n$. Характеристика $\mb Z, \mb Q,\mb  R$  равна $0$. Характеристика $R[x]$ и $R[[x]]$ равна $\chr R$.

\rm Характеристика поля обязательно простое число или ноль.
\proof  Пусть теперь $\chr K=n\neq 0$, а $f$ --- единственный гомоморфизм $f\colon \mb Z \to K$. Если $n=mk$, где $1<m,k< n$, то $f(m)\neq 0$ и $f(k)\neq 0$, но $f(m)\cdot f(k)=f(n)=0$, что и даёт нетривиальные делители нуля в $K$.
\endproof
\erm



Для того, чтобы покомфортнее чувствовать себя при работе с понятием гомоморфизма выясним, как описать все
гомоморфизмы из кольца многочленов $R[x]$ в произвольное кольцо $S$. Прежде всего отметим, что если $\Psi \colon R[x]\to S$ гомоморфизм, то ограничение $\psi= \Psi|_{R}$ --- на постоянные многочлены, есть гомоморфизм $\psi \colon R \to S$.

\thrm Пусть $R$ и $S$ --- два кольца. Пусть $\psi \colon R \to S$ гомоморфизм, а $\lambda$ --- некоторый элемент из $S$. Тогда
существует единственный гомоморфизм $\Psi \colon R[x]\to S$, такой, что ограничение $\Psi|_{R}=\psi$ и $\Psi(x)=\lambda$.
\ethrm
\proof Опять же в таких случаях сначала докажем единственность, заодно поняв, как вообще может быть устроен указанный гомоморфизм.
Действительно, нам задано как $\Psi$ действует на константах из $R$. Так же мы знаем выражение для $\Psi(t^n)= \lambda^n$. Но тогда 
$$\Psi(a_0+ a_1 t+\dots+a_nt^n)=\psi(a_0)+\psi(a_1)\lambda+\dots+\psi(a_n)\lambda^n$$
по аддитивности и мультипликативности. Заметим, что $\Psi$ обязано быть отображением подстановки точки $\lambda$ в многочлен. Таким образом, единственность есть.

Видно, что выбора для определения $\Psi$ нет. Осталось проверить, что формула $$\Psi(a_0+\dots+a_nt^n)=\psi(a_0)+\dots+\psi(a_n)\lambda^n$$
даёт гомоморфизм. Аддитивность опустим и проверим более сложную мультипликативность. Пусть $g(x)=b_0+\dots+b_mx^m\in R[x]$. 
Тогда 
$$\Psi(fg)=\sum_{k=0}^{n+m}\psi\left(\sum_{i+j=k} a_ib_j \right)\lambda^k=\sum_{k=0}^{n+m}\sum_{i+j=k} \psi(a_i)\psi(b_j) \lambda^{i+j}$$
С другой стороны 
$$\Psi(f)\Psi(g)=\left(\psi(a_0)+\dots+\psi(a_n)\lambda^n\right)\left(\psi(b_0)+\dots+\psi(b_m)\lambda^m\right)$$
Осталось раскрыть скобки по дистрибутивности
$$\Psi(f)\Psi(g)=\sum_{i=0}^{n}\sum_{j=1}^m \psi(a_i)\psi(b_j) \lambda^{i+j}$$
и перегруппировать слагаемые.
\endproof












Это соображение можно использовать для того, чтобы доказать что у целочисленного уравнения нет решений. Например, мы знаем, что отображение $\mb Z \to \mb Z/n$ -- это гомоморфизм колец. Значит целочисленное решение уравнения $f(x)=0$, где $f(x)\in \mb Z[x]$ переходит в решение того, же уравнения но с коэффициентами, взятыми по модулю $n$. Но тогда, если по модулю $n$ не было  решений, то не было и целочисленных решений. 





\section{Основные определения теории делимости}

\dfn[Делимость в кольцах] Будем говорить, что элемент $a\in R$ делится на $b \in R$, если существует
$c \in R$, что $a=bc$. Обозначать это будем как $a\di b$ (или $b|a$).
\edfn

\dfn[Ассоциированные элементы] Будем говорить, что элементы $a,b\in R$ ассоциированы, если $b\di a$ и $a \di b$.
\edfn

\lm[Переформулировки условия ассоциированности] Следующие условия эквивалентны:\\
1) $a$ и $b$ ассоциированы.\\
2) $a = \eps b$, где $\eps \in R^*$.\\
3) $(a) = (b)$.
\elm
\proof Очевидно, что 1) равносильно 3). 

Теперь заметим, что если $a = \eps b$, где $\eps \in R^*$, то $a\di b$ и $b=\eps^{-1}a \di a$. 

Пусть теперь $a\di b$ и $b\di a$. Тогда $a=bc_1$, $b=ac_2$. Подставляя одно в другое получаем $a=ac_1c_2$. Если $a=0$, то и $b=0$ и доказывать нечего. Если же $a\neq 0$ то сокращая получаем, что $1=c_1c_2$. Отсюда $c_1$ обратим, что и требовалось.
\endproof

\dfn[НОД] Рассмотрим элементы $a,b\in R$. Будем говорить, что $d$ является наибольшим общим делителем $a$ и $b$, если $a\di d$, $b\di d$ (то есть является общим делителем) и для любого другого общего делителя $d'$ $d\di d'$.
\edfn

\lm[Единственность НОД-а] Пусть $R$ --- область целостности $a,b \in R$. Тогда если у пары $a,b$ есть НОД,
то он единственен с точностью до ассоциированности.
\elm
\proof
Пусть $d$ и $d'$ два наибольших общих делителя. В частности, они общие делители для $a$ и $b$. Тогда $d \di d'$ так как $d$ наибольший и $d' \di d$ симметрично.
\endproof

\dfn[Неприводимый элемент] Элемент $p\neq 0$, $p\notin R^*$ называется неприводимым, если он не раскладывается на множители нетривиальным образом. То есть для любых $a,b \in R$, если $ab=p$, то либо $a$ обратим, либо $b$ обратим.
\edfn

\dfn[Простой элемент] Элемент $p\neq 0$ называется простым, если  для любых $a,b\in R$, если $ab\di p$, то или $a\di p$ или $b\di p$ и при этом $p\notin R^*$.
\edfn

\utv Простой ненулевой элемент в области целостности обязательно неприводим.
\proof Действительно, если $p=ab$, то либо $a\di p$, либо $b \di p$. Пусть $a$. Тогда $p$ и $a$ ассоциированы. Но тогда $p=\eps a=ab$, $\eps \in R^*$. Но тогда $\eps=b$. Что и требовалось.
\endproof
\eutv

\rm[Дополнительно] Рассмотрим подкольцо в $\mb R$ вида  $\mb Z[\sqrt{5}]=\{a+\sqrt{5}b\,|\, a,b\in \mb Z\}$. В нём есть элемент $3+\sqrt{5}$. Если умножить $(3+\sqrt{5})(3-\sqrt{5})=9-5=4 =2\cdot 2$, то увидим, что у числа $4$ есть два разложения. Заметим, что $2$ не делит ни $3+\sqrt{5}$ ни $3-\sqrt{5}$. Если мы покажем, что элемент $2$ неприводим, то получится пример неприводимого, но не простого элемента в кольце.

Пусть есть разложение $(a+b\sqrt{5})(c+d\sqrt{5})=2$. Тогда $(a-b\sqrt{5})(c-d\sqrt{5})=2$ так же. Значит
$2\cdot 2= (a+b\sqrt{5})(c+d\sqrt{5})(a-b\sqrt{5})(c-d\sqrt{5})=(a^2-5b^2)(c^2-5d^2)$. Это соотношение между целыми числами. Покажем, что оно не может быть выполнено, если в исходном разложении не было обратимых элементов.

Если $a^2-5b^2=\pm 1$, то $a+b\sqrt{5}$ обратим. Если $a^2-5b^2=\pm 4$, то $c^2-5d^2=\pm 1$, что приводит к желаемому результату. Значит остался случай $a^2-5b^2=\pm 2$. Посмотрим на это уравнение по модулю $5$. Оно принимает вид $a^2\equiv 2 \mod 5$. 

Легко проверить, что оно не имеет решений. Значит и исходное уравнение не имеет целочисленных решений.  Отсюда получаем, что $2$ не раскладывается нетривиальным образом на множители. Значит $2$ неприводим в $\mb Z[\sqrt{5}]$, но не прост.

Теперь несложно заметить, что у элементов $(3+\sqrt{5})^2=2(7-3\sqrt{5})$ и $4$ нет наибольшего общего делителя в $\mb Z[\sqrt{5}]$, так как оба они делятся на $2$ и на $3+\sqrt{5}$, но нет общего делителя, который бы на каждый из них делился.
\erm






\section{Идеалы}

Рассмотрим конечный набор элементов $a_1, \dots, a_n \in R$ и рассмотрим уравнение первой степени
$$a_1 x_1 + \dots +a_n x_n =y.$$
Вопрос — для каких $y$ это уравнение разрешимо? Естественно получить удовлетворительный ответ в общем случае нельзя, но можно заметить какие-то свойства. А именно, сумма $y_1+y_2$ таких элементов тоже является решением уравнения и $ry$ -- тоже решение уравнения. Разовьём тему.

\dfn[Идеал] Пусть $R$ -- кольцо. Тогда подмножество $I\subseteq R$ называется идеалом, если:
\enm
\item $I$ -- подгруппа $R$ относительно сложения
\item $\forall r \in R$ и $a\in I$ выполнено, что $ra \in I$.
\eenm
\edfn

\exm\\
0) $0,R$ -- всегда идеалы в кольце $R$.\\
1) $n\mb Z \leq \mb Z$\\
2) Если заданы элементы  $a_1, \dots, a_n \in R$, то идеал $(a_1,\dots,a_n)=\{a_1 x_1 + \dots +a_n x_n\, |\, x_i\in R\}$ называется идеалом, порождённым $a_1,\dots,a_n$.\\
3) Идеал $(f)$ ещё обозначается как $fR$ называется главным идеалом.\\
4) Рассмотрим кольцо непрерывных функций $C([0,1])$. Пусть $Y$ некоторое подмножество в $[0,1]$. Тогда множество функций $I_Y=\{ f\in C([0,1])\,|\, f(y)=0, \text{ для всех } y\in Y\}$ есть идеал в $C([0,1])$.\\
5) Ядро гомоморфизма колец это идеал. Действительно, если $f(a)=f(b)=0$, то $f(a+b)=f(a)+f(b)=0$. Аналогично, $f(ra)=f(r)f(a)=0$, если $a\in \Ker f$.\\
6) Опишем все идеалы в кольце целых чисел:


\utv Любой идеал в кольце $\Z$ главный.
\eutv






\section{Основная теорема арифметики для областей главных идеалов}

Кроме условия сократимости для целых чисел важнейшим для нас фактом, было то, что в кольце целых чисел любой идеал является главным. Это давало нам возможность построить $\Nod$ и его линейное разложение. Оказывается, что это условие, достаточно для построения хорошей теории.

\dfn[Область главных идеалов] Область целостности $R$ называется областью главных идеалов, если любой идеал $I\leq R$ является главным.
\edfn

\exm\\
1) Целые числа.\\
2) Формальные степенные ряды над полем.
\lm Пусть $K$ --- поле, тогда все нетривиальные идеалы в кольце $K[[x]]$ имеют вид $(x^n)$. \elm
\proof
Пусть $I$ --- идеал. Рассмотрим элемент $a(x)\in I$ начинающийся с наименьшей возможной степени $x$, скажем $x^k$. Тогда любой элемент начинается хотя бы с $x^k$ и, следовательно, делится на $x^k$. Значит $I\subset (x^k)$. По выбору $a(x)$ имеет вид $a(x)=x^k g(x)$, где $g(x)$ имеет ненулевой свободный член. Тогда $g(x)$ обратим. Тогда $g^{-1}(x)a(x)=x^k\in I$. Значит $(x^k)\subset I$.
\endproof

Обсудим основные свойства областей главных идеалов, аналогичные целым числам.

\lm[Существует НОД]  Пусть $R$ --- область главных идеалов. Тогда для любых $a,b \in R$ существует $d$ -- наибольший общий делитель $a$ и $b$. Более того $(a,b)=(d)$.
\elm
\proof Пусть $d$ -- такое, что $(a,b)=(d)$. Тогда $a\di d$ и $b\di d$, то есть $d$ -- общий делитель. Далее пусть $d'$ другой общий делитель. Посмотрим на разложение $d=ax+by$. Заметим, что каждое из слагаемых делится на $d'$. Тогда и $d\di d'$. 
\endproof

\lm[Простой=неприводимый в ОГИ] Пусть $R$ --- область главных идеалов. Тогда любой неприводимый элемент прост. 
\begin{proof} Пусть элемент $p$ --- неприводим. Допустим $ab\di p$. Рассмотрим $(a,p)=(d)$. Так как $p$ --- неприводим, то $d$ или ассоциирован с $p$ и тогда $p|d|a$ и это нам подходит, или $d $ -- обратим. Если $d$ обратим, то $(a,p)=(d)=(1)$. Тогда рассмотрим разложение $1 = ax  + py$. Домножив на $b$ получаем $b = bax+bpy$. Так как оба слагаемых делятся на $p$, то и $b$ делится на $p$.
\end{proof}
\elm


Верны и остальные аналоги утверждений про делимость целых чисел. Перейдём к основной цели.



\thrm[Существование и единственность разложения] Пусть $R$ --- область главных идеалов. Тогда для любого $a\in R$, $a\neq 0$ существует представление $a$ в виде 
$$ a=\eps p_1\dots p_n,$$
где $p_i$ --- простые, а $\eps \in R^*$. Причём такое разложение единственно с точностью до ассоциированности и перестановки сомножителей. То есть для любого другого разложения $a=\eps' q_1\dots q_m$ верно, что $n=m$ и существует перестановка $\sigma \in S_n$ $q_i\sim p_{\sigma(i)}$.
\ethrm Для того, чтобы доказать, что разложение существует нам понадобится лемма.
\lm Пусть $R$ --- область главных идеалов. Рассмотрим некоторую возрастающую последовательность идеалов
$$I_1\subseteq I_2\subseteq \dots \subseteq I_n\subseteq \dots.$$
Тогда существует $N\in \mb N$, что для любого $i\in \mb N$, выполнено, что $I_{N}=I_{N+i}$.
\elm
\proof[Доказательство леммы] Рассмотрим объединение $J=\cup_{n\in \mb N} I_n$. Тогда $J$ идеал. Тогда $J=(d)$. Тогда $d\in I_N$ для некоторого $N$. Тогда $J=I_N$. Понятно, что $J=I_N\subseteq I_{N+i}\subseteq J$, что означает, что все они равны между собой.
\endproof

\proof[Существование] Пусть $a\neq 0$. Предположим, что у $a$ нет разложения на простые множители. В частности $a$ --- не простой. Значит у $a$ нетривиальным образом раскладывается на множители $a=bc$. Если у нас есть разложение для $b$ и $c$, то есть и для $a$. Значит его нет скажем для $b$. Тогда $b$ не прост и у него есть нетривиальный делитель $b_1$ у которого тоже нет разложения. Для $b_1$ есть делитель $b_2$ и т.д. Таким образом, у нас есть бесконечная цепочка делителей $a \di b \di b_1 \di b_2 \di \dots$. Тогда есть цепочка идеалов $(a)<(b)<(b_1)<(b_2)<\dots$. Все включения строгие так как $b_{i+1}$ нетривиальный делитель $b_i$ (то есть они не ассоциированы). Противоречие с леммой.

\proof[Единственность] Рассмотрим два разложения $a=\eps p_1\dots p_n=\eps' q_1\dots q_m$. Рассмотрим элемент $p_1$. Он делит $q_1\dots q_m$. Так как $p_1$ --- простой, то он делит какой-то сомножитель $q_{k_1}$. Тогда $p_1\sim q_{k_1}$ так как $q_{k_1}$ неприводим. Сократим на $p_1$ обе части равенства и продолжим по индукции.
\endproof

\lm В области главных идеалов $R$ элемент $a=\eps p_1^{\alpha_1}\dots p_k^{\alpha_k}$ делится на $b=\eps' p_1^{\beta_1}\dots p_k^{\beta_k}$ тогда и только тогда, когда $\alpha_i\geq \beta_i$. Здесь предполагается, что $p_i$ и $p_j$ не ассоциированы, если $i\neq j$  и их набор одинаков для обоих разложений. Зато $\alpha_i$ и $\beta_j$ могут быть равны нулю.
\proof Очевидно, что если условие выполнено, то $a\di b$. Обратно. Пусть $a\di b$, то есть $a=cb$ для некоторого $c=up_1^{\gamma_1}\dots p_k^{\gamma_k}$. Тогда для $a$ имеется два разложения
$$a=\eps p_1^{\alpha_1}\dots p_k^{\alpha_k}=u\eps'p_1^{\beta_1+\gamma_1}\dots p_k^{\beta_k+\gamma_k}.$$
Так как $p_i$ и $p_j$ не ассоциированы, то $\alpha_i=\beta_i+\gamma_i$. Так как $\gamma_i$ неотрицательно получаем нужное неравенство.
\endproof
\elm



\lm В области главных идеалов для любых двух элементов существует $\Nod$. Более того, если $a=\eps p_1^{\alpha_1}\dots p_k^{\alpha_k}$, а $b=\eps' p_1^{\beta_1}\dots p_k^{\beta_k}$, то $$\Nod(a,b)=d=p_1^{\min(\alpha_1,\beta_1)}\dots p_k^{\min(\alpha_k,\beta_k)}.$$
\proof
Очевидно, что $d$ есть общий делитель для $a$ и $b$. Рассмотрим другой общий делитель $d'=p_1^{\gamma_1}\dots p_k^{\gamma_k}$. Тогда $\gamma_i\leq \alpha_i$ и $\gamma_i\leq \beta_i$. Что и требовалось.
\endproof
\elm







Как понять, что ваше кольцо это область главных идеалов? Проще всего придумать аналог для деления с остатком -- процедуру, которая в некотором смысле уменьшает один элемент при помощи прибавления другого. Точнее:

\dfn[Евклидово кольцо] Пусть $R$ --- область целостности. Будем говорить, что $R$ --- евклидово, если существует функция $\nu \colon R\setminus \{0 \}\to \mb Z_{\geq 0}$ , что для любых $a,b \in R\setminus \{0\}$ существуют $q,r\in R$, что
$$a=bq+r \text{ и либо $\nu(r)<\nu(b)$, либо } r=0.$$
\edfn



\thrm[Все идеалы евклидова кольца главные] Пусть $I\leq R$ --- идеал в евклидовом кольце. Тогда $I$ --- главный.
\ethrm

\proof Повторим стандартное доказательство для $\mb Z$. Пусть $I\leq R$ --- идеал. Рассмотрим $a$ --- наименьший по евклидовой норме элемент $I$. Покажем, что $I=\lan a\ran$. Действительно, пусть $b\in I$ и $b\ndi a$. Тогда $b=aq+r$, причём $\nu(r)<\nu(a)$. Но $r$ тоже лежит в $I$. Противоречие с минимальностью нормы для $a$.
\endproof


Из примеров евклидовых колец у нас пока есть только целые числа, но мы будем над этим работать.






\section{Китайская теорема об остатках}

\thrm[Китайская теорема об остатках] Пусть $R$ -- область главных идеалов. Рассмотрим попарно взаимно простые элементы $r_1,\dots,r_n$. Тогда для любых $a_1,\dots,a_n\in R$ система сравнений
$$ \begin{cases}
x\equiv a_1 (\mod r_1)\\
\quad \vdots \\
x\equiv a_n (\mod r_n)
\end{cases}$$
имеет единственное решение по модулю $r_1\cdots r_n$.
\ethrm
\proof Доказательство идёт индукцией по $n$. База при $n=2$. Пусть элементы $r_1$ и $r_2$ взаимно просты. Прежде всего покажем единственность. Пусть $x$ и $y$ -- два решения. Тогда $x-y \equiv 0 \mod r_1$. То есть $x-y \di r_i$. Так как $r_i$ попарно взаимно просты, то это означает, что $x-y \di r_1 r_2 $. То есть $x\equiv y \mod r_1 r_2$.
Осталось показать существование решения. Если $r_1$ и $r_2$ взаимно простые, то значит единица представляется в виде $1=sr_1+tr_2$.

Давайте посмотрим на элемент $tr_2$. Он даёт 1 по модулю $r_1$ и 0 по модулю $r_2$, то есть соответствует паре $(1,0)$. Симметрично для  $sr_1$. Если же мы хотим получить пару $(a_1,a_2)$, то подойдёт элемент $x=a_1tr_2+a_2sr_1$.

Шаг. Пусть даны элементы $r_1,\dots, r_n$. Заметим, что $r_1$ и $r_2\cdots r_n$ -- пара взаимно простых элементов. По индукционному предположению система 
$$ \begin{cases}
x\equiv a_2 (\mod r_2)\\
\quad \vdots \\
x\equiv a_n (\mod r_n)
\end{cases}$$
равносильна одному сравнению $x\equiv x_0 \mod r_2\dots r_n$ для некоторого $x_0\in R$. Но тогда мы имеет систему из двух сравнений по взаимно простым модулям $r_1$ и $r_2\dots r_n$, которая, по доказанному в базе индукции имеет единственное решение по модулю $r_1\dots r_n$.
\endproof









\section{Первые применения}

\subsection{Теорема Лагранжа}


Из предыдущего раздела осталось несколько вопросов: откуда же взять изначальное условие $g^n=e$ для нахождения порядка элемента $g$? Почему в теореме про подгруппы циклической группы мы ограничились только теми подгруппами, порядок которых делит размер объемлющей группы? Оказывается это всё проявление некоторого общего принципа свойственного всем группам.


\dfn Пусть $H$ --- подгруппа $G$. Определим отношение эквивалентности $\sim_H$ на $G$ следующим образом: $g_1\sim_H g_2$ если $\exists h \in H$, что $g_1=g_2 h$.
\edfn

\utv Это отношение эквивалентности.
\eutv
\proof Действительно. Для того, чтобы показать, что $g\sim_H g$ возьмём $h=e$. 

Cимметричность: если $g_1 \sim_H g_2$, то $g_1=g_2h$ для некоторого $h\in H$. Тогда $g_2=g_1h^{-1}$. Осталось заметить, что $h^{-1}\in H$.

Покажем рефлексивность. Пусть $g_1\sim_H g_2 \sim_H g_3$.  То есть $g_1=g_2h_1$, $g_2=g_3h_2$. Но тогда подставив в первое равенство второе получим $g_1=g_3h_2h_1$. Значит, $g_1\sim_H g_3$. Что и требовалось. 
\endproof

Посмотрим как выглядят классы эквивалентности относительно $\sim_H$.

\dfn Пусть $G$ -- группа, $H$ -- подгруппа и задан некоторый элемент $g\in G$. Тогда множество $gH=\{ gh\,|\, h \in H\}$ является классом эквивалентности относительно $\sim_H$. Будем называть $gH$ левым смежным  классом элемента $g$ по подгруппе $H$. 
\edfn

\dfn Множество всех левых смежных классов будем обозначать $G/H$. Количество элементов в $G/H$ называется индексом $H$ в $G$  и обозначается $[G:H]$. 
\edfn

Благодаря тому, что отношение $\sim_H$ -- это отношение эквивалентности получаем, что:


\crl Группа $G$ разбивается в дизъюнктное объединение левых смежных классов $$G=\coprod_{ gH \in G/H} gH.$$
\ecrl




\rm Аналогично определяется правый смежный класс $Hg$ для элемента $g$. Группа $G$ так же разбивается в диъюнктное объединение правых смежных классов. Множество правых смежных классов обозначается как $H\setminus G$.
\erm 

Это не всё, что нам нужно от смежных классов:

\utv Пусть $H$ -- подгруппа $G$ и $g\in G$ -- некоторый элемент. Тогда отображение $H \to gH$, заданное по правилу $h \to gh$, является биекцией.
\eutv
\proof Построим обратное отображение. Оно берёт элемент $x=gh\in gH$ и отправляет его в $g^{-1}x=h \in H $. Несложно проверить, что это взаимно обратные отображения.
\endproof

\dfn Пусть $G$ -- группа. Тогда число элементов в $G$ называют порядком $G$.
\edfn

\thrm[Лагранжа]  Пусть $G$ -- группа, $H$ -- подгруппа. Пусть порядок  $H$ конечен и индекс $[G:H]$ конечен. Тогда $G$ -- конечная группа и 
 $$|G|=|H|[G:H].$$
\ethrm
\proof По следствию из того, что $\sim_H$ -- отношение эквивалентности, получаем, что группа $G$ разбивается в дизъюнктное объединение левых смежных классов $$G=\coprod_{gH \in G/H} gH.$$
Таких смежных классов по определению $[G:H]$ штук. В каждом смежном классе $gH$ элементов столько же, сколько в $H$, то есть $|H|$. Но тогда число элементов в $G$ конечно и равно $|H|[G:H]$.
\endproof

\crl Пусть $G$ -- конечная группа, а $H$ -- её подгруппа. Тогда $|G| \di |H|$.
\ecrl
\proof В теореме Лагранжа даже сказано откуда берётся дополнительный множитель.
\endproof

\dfn[Циклическая подгруппа]
\edfn

\dfn[Порядок элемента]
\edfn

\lm[Порядок циклической подгруппы]
\elm

\crl Пусть $G$ -- конечная группа. Тогда порядок элемента $g\in G$ делит $|G|$.
\ecrl
\proof Порядок $\ord g$ равен $|\lan g\ran|$. Но $\lan g\ran$ -- это подгруппа в $G$. Применим предыдущее следствие.
\endproof

\crl Пусть $G$ -- конечная группа порядка $n$, а $g$ -- её элемент. Тогда $g^n=e$.
\ecrl  
\proof По предыдущему следствию $n= \ord g \cdot m$, для $m\in \mb N$. Тогда $g^n=(g^{\ord g})^m=e^m=e$. 
\endproof

\subsection{Функция Эйлера}

\dfn Пусть $n$ -- натуральное число. Тогда определим функцию Эйлера $\ffi(n)$ как $\ffi(n)=|\mb Z/n^*|$. 
\edfn 

Попробуем посчитать функцию Эйлера. Рассмотрим случай, когда $n=p$ -- простое число. Тогда все числа от $1$ до $p-1$ взаимно просты с $p$. Значит $\ffi(p)=p-1$.
\rm В частности, $\mb Z/p$ -- поле, если $p$ --  простое
\erm
Если число $n=p^k$ есть степень простого числа $p$, то $$\ffi(p^k)=(p-1)p^{k-1}.$$
Для доказательства заметим, что число $x$ не взаимно просто с $p^k$ тогда и только тогда, когда оно делится на $p$. Любое число $x<p^k$ делящееся на $p$ имеет вид $pl$, где $l<p^{k-1}$. Таких чисел $p^{k-1}$ штук. Итого взаимно простых чисел $p^k-p^{k-1}$. \\
Далее заметим, что если  $n$ и $m$ взаимно простые, то 
$$\ffi(nm)=\ffi(n)\ffi(m).$$ 
Действительно, по Китайской теореме об остатках паре остатков -- $a_1$ по модулю $n$ и $a_2$ по модулю $m$ соответствует единственный остаток $x_0$ по модулю $nm$. Осталось заметить, $a_1$ взаимно прост с $n$  и $a_2$ взаимно просто с $m$ тогда и только тогда, когда $x_0$ взаимно прост с $nm$. Сформулируем теорему

\thrm
Пусть $n=p_1^{\alpha_1}\dots p_k^{\alpha_k}$ натуральное число, а $p_i$ -- различные простые. Тогда
$$\ffi(p_1^{\alpha_1}\dots p_k^{\alpha_k})=(p_1-1)p_1^{\alpha_1-1}\cdots (p_k-1)p_k^{\alpha_k-1}=n\left(1-\frac{1}{p_1}\right)\dots\left(1-\frac{1}{p_k}\right).$$
\ethrm
\proof Применим предыдущее замечание несколько раз воспользовавшись тем, что $p_i^{\alpha_i}$  и $p_j^{\alpha_j}$ взаимно просты при $i\neq j$. 
\endproof

\crl[Остатки как поля] Кольцо $\mb Z/n$ является полем тогда и только тогда, когда число $n$ --- простое.
\ecrl

\thrm[Эйлера] Пусть $n$ -- натуральное число и $a\in \mb Z/n^*$. Тогда $a^{\ffi(n)}=1$.
\ethrm
\proof
Рассмотрим все обратимые классы вычетов $x_1,\dots,x_{\ffi(n)}$. Заметим, что отображение $\mb Z/n^* \to \mb Z/n^*$ заданное правилом $x\to ax$ корректно и обратимо. Действительно, так как $a$ и $x$ обратимы, то $ax$ -- тоже обратим. Для построения обратного отображения возьмём $b=a^{-1}$. Тогда аналогичное отображение, заданное правилом $x\to b x$ -- обратное для исходного. Таким образом, $ax_1,\dots,ax_{\ffi(n)}$ это все возможные обратимые классы вычетов.

Значит совпадают произведения
$$ x_1\cdots x_{\ffi(n)} = a x_1 \cdots ax_{\ffi(n)} = a^{\ffi(n)} x_1 \cdots x_{\ffi(n)} $$ 
Заметим, что общий множитель из правой и левой частей $x=x_1 \cdots x_{\ffi(n)}$ обратим, как произведение обратимых элементов. Домножив на $x^{-1}$ получаем требуемое.

\endproof


\crl[Малая теорема Ферма] Пусть $p$ простое число, и $a\in \mb Z/p$. Тогда $a^{p} = a$.
\ecrl
\proof Если $a\neq 0$, то $a$ обратим и применима предыдущая теорема. Получаем, что $a^{p-1}=1$. Домножим на $a$ и получим требуемое. Если же $a=0$, то справа и слева стоит 0. 
\endproof






\subsection{Криптографическая система RSA}
Понятие сравнения и понятие кольца вычетов были мотивированы критериями неразрешимости уравнений в целых числах. Однако и существование решений в кольце вычетов может быть полезным. В качестве примера рассмотрим задачу про извлечение корня по модулю $n$.

\lm Рассмотрим уравнение  $x^k=a$ в $\mb Z/n$. Пусть $a\in \mb Z/n^*$ и $(k,\varphi(n))=1$.
Рассмотрим $s$ ---  решение уравнения $ks+\varphi(n)t=1$. В таком случае $x^k=a (\mod n)$ тогда и только тогда, когда $x=a^s(\mod n)$.
\proof
Пусть $x^k=a$. Заметим, что элемент $x$ -- обратим. Действительно, $x^{-1}=x^{k-1}a^{-1}$. Тогда возведём обе части равенства в степень $s$. Получим 
$$a^s=x^{ks}=x^{1-\ffi(n)t}=x.$$
Обратно, если взять $x=a^s$, то
$$x^k=a^{sk}=a^{1-\ffi(n)t}=a.$$
\endproof
\elm

Обсудим, как результат этой леммы может быть применён в криптографии.

Основную задачу криптографии можно сформулировать так: передать сообщение от одного адресата другому, так, чтобы в случае доступа к каналу связи третьего человека, он не смог получить текст исходного сообщения. 

Точнее третье лицо может получить только зашифрованное сообщение, по которому, по идее, не должно иметь возможность за разумное время восстановить исходное сообщение. С другой стороны, необходимо, чтобы получатель сообщения смог бы расшифровать полученное (не умерев от нетерпения).




В 1978 в работе \href{http://people.csail.mit.edu/rivest/Rsapaper.pdf}{ R.L. Rivest, A. Shamir, L. Adleman, A Method for Obtaining Digital Signatures and Public-Key Cryptosystems } было опубликовано описание алгоритма шифрования со следующим свойством: злоумышленник, перехвативший сообщение мог его дешифровать, но за недостижимое на практике время. В свою очередь получатель сообщения мог его быстро расшифровать используя секретный ключ. Таким образом, достигалась секретность переданного сообщения.



Основная идея этой системы шифрования состоит в том, что разложение  чисел на множители является гораздо более трудоёмкой операцией, чем  умножение. Таким образом, любые параметры, которые легко посчитать, зная разложение числа на множители и сложно найти, если такого разложения не знать, могут быть использованы для передачи сообщений.

Перейдём к описанию алгоритма. Пусть есть два человека, скажем Алиса и Боб. И Боб хочет написать Алисе. Для этого Алиса должна подготовить два ключа --  секретный, который знает только она и использует для расшифровки присланных сообщений и открытый -- с помощью которого любой может зашифровать сообщение для Алисы. В нашей ситуации, открытым ключом будет пара $n,e$, а секретным ключом будет набор чисел $p,q,d$. Здесь $p,q$ --- два простых числа, $n=pq$  и  $e<n$ --- некоторое число, взаимно простое с $\ffi(n)$. Число $d<n$ удовлетворяет сравнению $de\equiv 1\mod \ffi(n)$. Заметим, что зная $p,q$ нам известно $\ffi(n)=(p-1)(q-1)$ и зная $e$ легко найти число $d$

Множество возможных сообщений это $\mb Z/n^*$. На практике в качестве сообщения выступает произвольное число от $1$ до $n-1$. Вероятность попасть в число не взаимно простое с $n$ крайне мала.  Допустим Боб хочет послать Алисе сообщение $t$. Для этого ему необходимо вычислить 
$$s=t^e\mod n.$$
Алисе же для того чтобы расшифровать сообщение необходимо найти
$$t=s^d \mod n.$$



\subsection{Тесты на простоту}
В системе RSA ключевым является выбор простых чисел $p,q$. Это должны быть большие простые числа для того, чтобы разложение числа $n=pq$ на множители заняло много времени у злоумышленника. Кроме того, это должны быть достаточно случайные числа -- если брать простые из заранее известного маленького множества, то злоумышленник может просто проверить число $n$ на делимость на все элементы этого множества. Так же никакие специальные алгоритмы разложения на множители не должны быстро работать для $n=pq$. Мы обсудим некоторые подходы к созданию таких простых чисел.

Приведём здесь простейший пример того, как проверить, что некоторое число $n$ -- простое, если известно разложение на множители числа $n-1$. Простейшие методы генерации простых чисел основаны на тесте Люка:
\thrm[Тест Люка] Пусть $n=p_1^{\alpha_1}\dots p_k^{\alpha_k}+1$. Тогда, если существует такое  $a\in \mb Z/n$, что $a^{\frac{n-1}{p_i}}\neq 1 $, но $a^{n-1} = 1$, то тогда число $n$ --- простое.
\ethrm  
Для доказательства нам понадобится некоторое общее для всех групп свойство.
\lm Пусть $G$ -- группа, $a\in G$. Пусть $a^n=1$ и $a^m=1$. Тогда $a^{(n,m)}=1$. 
\elm
\proof Напишем линейное разложение $d$ наибольшего общего делителя чисел $n$  и $m$. Имеем $d=nu+mv$. Тогда
$$a^d= a^{nu+mv}=(a^n)^u (a^m)^v=1.$$
\endproof

\proof[Доказательство теоремы]
Пусть $n$ -- не простое. Тогда $\ffi(n)<n-1$. Заметим, что $a\in \mb Z/n^*$ так как $a^{n-1} = 1$. Таким образом, по условию теоремы $a^{n-1}= 1$  и $a^{\ffi(n)}=1$  одновременно. Но тогда $a^d=1$, где $d=(n,\ffi(n))$. Заметим, что $d<n-1$  и $d|n-1$. Тогда существует простое $p_i$ из разложения $n-1$, что $n-1=p_idl$, для некоторого $l\in \mb Z$. Но тогда $a^{\frac{n-1}{p_i}}=a^{dl}=1$ в $\mb Z/n$, что противоречит одному из условий.
\endproof

Это даёт возможность строить простые числа следующим образом -- взять набор не очень больших простых чисел $p_1,\dots,p_k$, выбрать случайно степени $\alpha_1,\dots,\alpha_k$ и построить число $n=p_1^{\alpha_1}\dots p_k^{\alpha_k}+1$. Для него стоит перебрать все маленькие $a \leq \log n$ или сгенерировать несколько $a$ случайно и проверить для них  условия теста Люка. 

\fct[Докажем в следующем семестре] Если $n$ простое, то такие $a$ существуют. Более того их должно быть $\ffi(n-1)$ штук. 
\efct

Однако, для  простых чисел,  сгенерированных таким образом, есть специальный алгоритм, раскладывающий на множители их произведение. Действительно, пусть $n=pq$, где $p,q$ -- простые, такие что $p-1$ и $q-1$ раскладываются на простые множители порядка $\log n$. Прежде всего заметим, что для того чтобы посчитать $a^k 
\mod n$ достаточно знать $a^s \mod p$  и $a^s \mod q$. Заметим, что если последовательно брать $s$ вида $s=\lcm(1,\dots,k)$ или $s=k!$, то довольно скоро (для $k$ порядка $\log n$)  $a^s\equiv 1 \mod p$ и $a^s \equiv 1 \mod q$ так как $\ffi(p)=p-1$ довольно скоро будет делить $s$ и аналогично для $q$. 

Однако с большой вероятностью наименьшее такое $k$, что $a^{k!}\equiv 1 \mod p$ не будет совпадать с аналогичным $k$ для сравнения по модулю $q$. Но тогда $(a^{k!}-1,n)$ будет нетривиальным делителем $n$ для некоторого $k$ порядка $\log n$.

Поэтому на практике оказалось, что удобнее брать случайные числа из заданного большого промежутка и проверять их на простоту вероятностым способом. При такой проверке мы, вообще говоря, не сможем доказать, что прошедшие проверку числа будут простыми, но у нас будет очень большая уверенность в этом. Кроме того,  злоумышленник с большой вероятностью не сможет проверить, что мы ошиблись и взяли не простые числа.

Рассмотрим простейший пример вероятностного теста: пусть $p$ -- простое число. Тогда по малой теореме Ферма известно, что для всех $(a,p)=1$ выполнено, что $a^{p-1}\equiv 1(\mod p)$. Итого получаем, что если найти такое $a$, что $(a,n)=1$ и $a^{n-1}\nequiv 1(\mod n)$, то $n$ точно не простое. Следовательно, получаем  тест:\\
\noindent{\bf Тест Ферма}\\
1) Дано некоторое число $n$. Берём случайное число $1<a<n$.\\
2) Вычисляем $b=a^{n-1} \mod n$. Если $b\neq 1$, то выдаем, что число $n$ не простое. Иначе ничего не говорим.

\dfn Если указанный тест  проходит для простого числа $a$, то есть $a^{n-1}\equiv 1(\mod n)$, то будем говорить, что $a$ является свидетелем простоты для теста Ферма числа $n$ и $n$ -- псевдопростое по основанию $a$.
\edfn

Почему этот тест удобен? прежде всего из-за его простоты. А именно, проверка $a^{n-1}\equiv 1 \mod n$ занимает $O(\log(n))$ операций умножения в $\mb Z/n$. 

Однако есть другой вопрос: а сможем ли мы с какой-то попытки при помощи такого теста отличить простое число от непростого? С одной стороны да, потому что перебирая все числа $a$ в случае непростого числа мы в какой-то момент наткнёмся на нетривиальный делитель. С другой стороны понятно, что делителей числа $n$ мало. Поэтому немного поменяем вопрос: верно ли, что для всякого непростого числа $n$ существует $(a,n)=1$, что $a$ не свидетель простоты $n$? Оказывается, что это не всегда так.

\utv Любое число, взаимно простое с числом 561 является свидетелем простоты числа 561. При этом число $561$ раскладывается на множители $561=3\cdot 11\cdot 17$.
\eutv

\dfn Составное число $n$ называется числом Кармайкла или псевдопростым числом, если $\forall a$, что $(a,n)=1$ выполнено $a^{n-1}\equiv 1(\mod n)$.
\edfn



\fct Чисел Кармайкла бесконечно много. \href{http://www.dms.umontreal.ca/~andrew/PDF/carmichael.pdf}{W.R. Alford, Andrew Granwill, Carl Pomerance, There are infinitely many Carmichael numbers}
\efct

Можно немного усовершенствовать этот тест: заметим, что во время быстрого возведения в степень мы сначала считаем $a^{\frac{n-1}{2}} $ в кольце $\mb Z/n$, а потом возводим это число в квадрат. Можем ли мы что-то конкретное сказать про $x=a^{\frac{n-1}{2}}$ когда $n$ -- простое. Да, сможем. А именно, для всякого $0\neq a \in \mb Z/n$ $x^2=a^{n-1}\equiv 1 \mod n$.
\lm Если $n$ -- простое число, то единственными решениями $x^2=1$ в кольце $\mb Z/p$ являются $x=\pm 1$.
\elm
\proof Распишем на языке сравнений. Сравнение $x^2\equiv 1 \mod p $ равносильно условию $x^2-1=(x-1)(x+1)\di p$. Но тогда либо $x+1\di p$, то есть $x\equiv -1 \mod p$, либо $x\equiv 1 \mod p$.
\endproof

Это приводит нас к следующему тесту на простоту для целых чисел:

\noindent{\bf Тест Эйлера}\\
1) Дано некоторое число $n$. Берём случайное число $1<a<n$.\\
2) Вычисляем $b=a^{(n-1)/2} \mod n$. Если $b\neq \pm 1$, то выдаем, что число $n$ не простое. Иначе ничего не говорим.




Тест Эйлера так же вычислительно прост. Однако он обладает и тем же недостатком. А именно, имеются псевдопростые для данного теста числа. Например, любое число, взаимно простое с  $1729=7\cdot 13\cdot 19$ подтверждает, что $1729$ простое.\\



Однако, можно пойти дальше. Представим число  $n-1$ в виде $n-1=m2^s$, где $m$ -- нечётное. в процессе вычисления $a^{n-1}$ при быстром возведении в степень мы вычисляем сначала $a^m \mod n$, а потом и числа $a^{2^r m}\mod n$ где $r<s$. Посмотрим, что мы можем  сказать про эти числа.

\thrm
Пусть $n$~--- простое число, обозначим $n-1=2^s\cdot m$, где $m$ нечётно. Тогда для любого $a\in\mb Z/n^*$ выполнено хотя бы одно из двух условий
\begin{itemize}
\item 
$a^m=1$;
\item
существует $0\leqslant r<s$ такое, что $a^{2^rm}=-1$.
\end{itemize}
\ethrm
\proof Пусть $l \geq 0$ -- наименьшее такое, что $a^{m2^l}= 1$. Такое $l$ есть, потому что $a^{m2^s}=a^{n-1}=1$. В частности $l\leq s$ Если $l=0$, то $a^m=1$, что подходит для нас. Иначе рассмотрим $x=a^{m2^{l-1}}$. Как и раньше имеем $x^2=1$. Но тогда по лемме $x=- 1$ ($x=1$ не подходит благодаря выбору $l$). Осталось взять $r=l-1$.
\endproof



\noindent{\bf Тест Миллера-Рабина} \\
1) Представим $n-1=2^sm$, где $m$ нечётно.\\
2) Берём случайное число $1<a<n$. Вычисляем $a^m \mod n$. Если $a^{m}\equiv \pm 1\mod n$, то $n$ вероятно простое. Иначе переходим к следующему шагу.\\
3) Для всех $1\leq r<s$ смотрим, верно ли что $a^{m2^r}\equiv -1 \mod n$. Если это так, то $n$ вероятно простое. Если такого $r$ -- нет, то $n$ -- составное.\\

\dfn Будем называть число $a\in\mb Z/n$ {\it свидетелем простоты} числа $n$, если число $n$ проходит описанный тест по основанию $a$. Число $n$ в этом случае называется сильно псевдопростым по основанию $a$.
\edfn

Тест Миллера-Рабина был придуман \href{https://www.cs.cmu.edu/~glmiller/Publications/Papers/Mi76.pdf}{Гэри Миллером}, как детерминированный тест на простоту. Предполагалось, что с помощью этого теста надо проверить первые $O(n^{1/7})$ чисел $a$. Если все эти $a$ были свидетелями простоты $n$, то по теореме, доказанной Миллером $n$ должно быть простым.

Так же Миллер получил следующий результат: в предположении обобщённой гипотезы Римана, если все числа $a\leq C \log^2 n $ являются свидетелями простоты числа $n$ для указанного теста, то $n$ простое. Позднее было показано, что в качестве константы $C$ можно взять 2. Большинство математиков верят, что обобщённая гипотеза Римана верна.

В свою очередь, Михаэль Рабин в статье \href{https://ac.els-cdn.com/0022314X80900840/1-s2.0-0022314X80900840-main.pdf?_tid=e8201658-e83e-11e7-9793-00000aab0f26&acdnat=1514074434_a1f0bbeeacc3f326abc83943e330aa13}{Probabilistic algorithm for testing primality} рассмотрел вероятностную версию этого алгоритма показав её эффективность с помощью следующей теоремы:


\thrm(Рабин) 
Для любого $n$ -- нечётного составного, $n>9$, существует не более $\frac{\ffi(n)}{4}$ свидетелей его простоты.
\ethrm

Таким образом, вероятность, что случайно выбранное число $a\in\mb Z/n$ является свидетелем простоты числа $n$ меньше $\frac14$. Если же  выбрать случайное число $a$ $k$ раз подряд, и каждый раз оно будет  свидетелем простоты числа $n$, то вероятность того, что $n$~--- составное, меньше $\frac{1}{4^k}$.









\chapter{Многочлены}



\section{Кольцо многочленов от одной переменной}


Теперь настало время разобрать второй по важности, после целых чисел пример евклидового кольца, а следовательно, и области главных идеалов --- кольцо многочленов над полем. Для начала разберём немного ситуацию не только над полем.

\dfn[Степень многочлена] Пусть $R$ -- кольцо, а $f=a_0+a_1x+\dots+a_nx^n$ ненулевой многочлен в $R[x]$. Положим степень $\deg f = \max_{a_n\neq 0} n$ -- номеру наибольшего ненулевого коэффициента. Будем говорить, что $a_{\deg f}$ --- старший коэффициент многочлена $f$. Если $f=0$ положим $\deg f= -\infty$.
\edfn

\rm В дальнейшем будем подразумевать, что $-\infty+m=-\infty$ для всех $ m \in \mb Z$.
\erm

\lm[Коэффициент при старшей степени] Пусть $R$ --- область целостности, а $f$ и $g$ два  многочлена из $R[x]$ степени $n$ и $m$. Тогда степень $\deg fg = \deg f +\deg g$. Более того, если $f$ и $g$ ненулевые и их старшие коэффициенты это $a_n$ и $b_m$, то старший коэффициент $fg$ равен $a_nb_m$.
\elm
\proof Случай когда один из многочленов нулевой тривиален. Пусть оба они ненулевые. Рассмотрим коэффициент $c_k$ при степени $k>n+m$ в произведении $fg$. Тогда $c_k=\sum_{i+j=k}a_ib_j$. Но каждое слагаемое есть 0, так как содержит нулевой сомножитель. Тогда $c_k=0$. С другой стороны в коэффициенте $c_{n+m}$ есть ровно одно ненулевое слагаемое $a_nb_m$. Тогда $c_{n+m}=a_nb_m\neq 0$. Следовательно степень $fg$  есть $n+m$.
\endproof

\crl[Кольцо многочленов --- область целостности] Пусть $R$ --- область целостности. Тогда $R[x]$ --- область целостности.
\proof Если $f$ и $g$ не равны 0, то $\deg fg =\deg f+ \deg g\neq - \infty$, то есть произведение не 0.
\endproof
\ecrl



\lm Пусть $R$ -- область целостности. Тогда $R[x]^*=R^*$.
\elm 
\proof  Пусть так случилось, что $fg=1$. Тогда степень $\deg f+\deg g=\deg 1=0$. Отсюда $\deg f=\deg g=0$. То есть оба они константы из $R$. Тогда указанное равенство $fg=1$ верно в $R$, то есть $f$ обратим в $R$.
\endproof

\rm Если в $R$ есть нильпотенты, то это вообще говоря не так. Вот пример: $R=\mb Z/p^2$, где $p$ -- простое. Тогда многочлены $1+px$ и $1-px$ обратны друг другу.
\erm

\rm Заметим, что, хотя для степени суммы равенства нет,  тем не менее можно написать неравенство
$$\deg (f+g) \leq \max(\deg f, \deg g).$$
\erm

\thrm[Деление с остатком в кольце многочленов] Пусть $R$ --- кольцо. Рассмотрим два многочлена $f,g \in R[x]$, причём старший коэффициент $g$ обратим. Тогда существуют единственные $q,r \in R[x]$ такие, что:\\
$$f=qg+r \text{ и } \deg r < \deg g.$$
\ethrm
\proof Сначала докажем единственность. Пусть $f=q_1g+r_1=q_2g+r_2$, $\deg r_1 < \deg g$ и  $\deg b_1 < \deg g$. Тогда $(r_2-r_1)=(q_1-q_2)g$. Если $q_1\neq q_2$, то  $(q_1-q_2)g$ большей степени, чем $r_2-r_1$, что противоречит равенству Значит $q_1=q_2$. Но тогда $r_1=r_2$.

Для доказательства существования приведём индукционный алгоритм построения. Индукция по степени $f$. Если $\deg f<\deg g$, то $r=f$, $q=0$. Пусть $f=a_nx^n+\dots+a_0$, а $g=b_mx^m+\dots + b_0$, $m\leq n$. Рассмотрим разность $$f_1=f-\tfrac{a_n}{b_m}x^{n-m}g.$$
Это многочлен степени меньшей $\deg f$. Тогда $f_1=q_1g+r_1$. Возьмём $q=q_1+\tfrac{a_n}{b_m}x^{n-m}$ и $r=r_1$.
\endproof






Напомню, что главной целью этого параграфа было введение нового важного примера евклидового кольца.

\thrm
Пусть $K$ -- поле. Тогда кольцо многочленов $K[x]$ является евклидовым кольцом с нормой -- $f \to \deg f$.
\proof Если $K$ поле, то старший коэффициент любого ненулевого многочлена обратим. Осталось воспользоваться теоремой о делении с остатком.
\endproof
\ethrm

А что вообще значат вопросы делимости в кольце многочленов?

\lm \label{remainder} Пусть $R$ -- кольцо, $a\in R$, $f\in R[x]$. Тогда $f\di (x-a)$ тогда и только тогда, когда $a$ корень
многочлена $f$.
\elm
\proof Поделим многочлен $f$ на $(x-a)$ с остатком $f=(x-a)q+r$. Многочлен $r$ --- какая-то константа из $R$. Тогда $f(a)=0+r=r$. C одной стороны, $r=0$ тогда и только тогда, когда $f \di (x-a)$, с другой стороны, тогда и только тогда когда $f(a)=0$.
\endproof

Самым, пожалуй, важным фактом, следующим из однозначности разложения в кольце многочленов, является оценка на число его корней.

\thrm Пусть $R$ -- область целостности, $0\neq f\in R[x]$. Тогда у $f(x)$ не более $\deg f$ корней. 
\ethrm
\proof Пусть $\lambda_1,\dots,\lambda_k \in R$ -- набор всех корней многочлена $f(x)$. Тогда $f(x)=(x-\lambda_1)g(x)$. Заметим, что $g(x)$ имеет $\lambda_2,\dots,\lambda_n$ своими корнями. Действительно $0=f(\lambda_i)=(\lambda_i-\lambda_1)g(\lambda_i)$. Если $i\geq 2$, то $\lambda_i-\lambda_1 \neq 0$ и тогда $g(\lambda_i)=0$. Продолжая так далее получим разложение $f(x)=(x-\lambda_1)\dots(x-\lambda_k)h(x)$. Сравнивая степени имеем $\deg f = k + \deg h$. Отсюда $\deg f \geq k$, что и требовалось.
\endproof


\dfn[Кратность корня] Пусть $R$ -- область целостности. Будем говорить, что многочлен $f\in R[x]$ имеет $a\in R$ корнем кратности $k$, если
$$f\di(x-a)^k \text{ и } f\ndi(x-a)^{k+1}.$$
\edfn



\dfn Пусть $R$ -- область целостности, $f\in R[x]$. Пусть $\lambda_1, \dots, \lambda_k$ -- все корни $f$ в $R$, причём их кратности равны $r_1,\dots,r_k$. Тогда число корней с учётом кратностей это $r_1+\dots+r_k$. 
\edfn

\rm Если $K$ -- поле, то многочлены $x-a$ и $x-b$ неприводимы в $K[x]$ и взаимно просты.
\erm

\thrm У многочлена $f\neq 0$ в поле не более чем $\deg f$ различных корней с учётом кратности.
\ethrm 
\proof Разложим $f(x)$ на неприводимые множители
$$f(x)=(x-\lambda_1)^{r_1}\dots (x-\lambda_k)^{r_k}\prod_{\deg p_i\geq 2} p_i^{\alpha_i}.$$
Сравнивая степени справа и слева получаем $\deg f=r_1+\dots+r_k+h$, где $h\geq 0$. Осталось заметить, что $r_1+\dots+r_k$ и есть число корней с учётом кратности.
\endproof

\lm Пусть $f,g \in K[x]$ многочлены степени меньше или равной $n$. Если есть $n+1$ точка $x_0,\dots,x_n$, что $f(x_i)=g(x_i)$, то $f(x)=g(x)$. 
\elm
\proof Рассмотрим разность $f-g$. Это многочлен степени не более $n$, но у него $n+1$ корень. Такое бывает только если $f-g=0$, то есть если $f=g$.
\endproof

\thrm[О формальном и функциональном равенстве многочленов] Пусть $K$ --- бесконечное поле. Тогда два многочлена равны в том и только том случае, когда их значения для всякой точки из $K$ равны.
\ethrm
\proof Пусть $f,g\in K[x]$  и $n$ -- это максимум из их степеней. Тогда рассмотрим $n+1$ точку $\lambda_0,\dots,\lambda_n \in K$. Тогда по условию они равны в этих точках и, следовательно, равны по лемме
\endproof


Приведём пример использования однозначности разложения на множители в кольце многочленов.

\utv Пусть $f\in K[x]$  многочлен степени $n$, и у него есть ровно $n$ различных корней $x_1,\dots,x_n$. Тогда 
$$f(x)=c \prod_{i=1}^n (x-x_i),$$
где $c$ -- это старший коэффициент $f(x)$.
\eutv
\proof Если $x_i$ -- различные корни $f(x)$, то как мы отмечали,  $f(x) \di \prod_{i=1}^n(x-x_i)$. То есть $f(x) = g(x)\prod_{i=1}^n(x-x_i)$. Но тогда дополнительный множитель $g(x)$ -- это константа. Осталось сравнить старшие коэффициенты слева и справа.
\endproof

\thrm[Теорема Вильсона] Натуральное число $p$ простое тогда и только тогда, когда $(p-1)! \equiv -1(\mod p)$.
\ethrm
\proof Если $p$ не простое, то есть $a<p$ --- нетривиальный делитель $p$ и следовательно делитель $0$ в $\mb Z/p$. Тогда произведение $(p-1)!$ тоже делитель 0.
Если $p$ простое, то два многочлена $x^{p-1}-1$  и $(x-1)\dots(x-(p-1))$ имеют $p-1$ общих корней в $\mb Z/p$ (по малой теореме Ферма) и одинаковый старший коэффициент. Но тогда они равны. Следовательно, равны и их свободные члены. С одной стороны это $(-1)$ с другой -- это $(p-1)!$.
\endproof




\dfn[Кольцо многочленов от нескольких переменных] Пусть $R$ — кольцо. Кольцом многочленов от $n$ переменных $x_1, \dots, x_n $ определяется индуктивно как $R[x_1,\dots,x_{n-1},x_n]=R[x_1,\dots,x_{n-1}][x_n]$.
\edfn



У нас тут возникли многочлены от нескольких переменных и настала пора разобраться с их записью.
\dfn Набор $\alpha=(\alpha_1,\dots,\alpha_n) \in (\mb N\cup\{0\})^{\times n}$ называется мультииндексом.
\edfn

\dfn Пусть $\alpha=(\alpha_1,\dots,\alpha_n)$ -- мультииндекс. Обозначим многочлен $x_1^{\alpha_1}\dots x_n^{\alpha_n}$ за $x^{\alpha}$.
\edfn

\rm Пусть $f(x_1,\dots,x_n) \in R[x_1,\dots,x_n]$. Тогда существуют единственный набор коэффициентов $a_{\alpha}\in R$, что $f(x_1,\dots,x_n)=\sum_{\alpha} a_{\alpha}x^{\alpha}$. Более того, такой набор коэффициентов должен обладать свойством, что все $a_{\alpha}$ кроме конечного числа равны 0. Обратно, если есть такой набор коэффициентов, то он задаёт многочлен $f(x_1,\dots,x_n)=\sum_{\alpha} a_{\alpha}x^{\alpha}$. Элементы $a_{\alpha}$ называются коэффициентами $f$. Многочлены вида $ax^{\alpha}$ называются мономами.
 \erm




 

Обсудим алгоритмический аспект вычисления значения многочлена в точке. А именно, с наскока может показаться, что для вычисления выражения $f(x)=a_0+a_1x+\dots+a_nx^n$ при подстановки $x=\lambda$ может понадобится $O(n^2)$ умножений. Однако, сразу видно, что можно сэкономить --- а именно возводя $\lambda$ в степень последовательно можно запоминать результаты вычислений и не считать их второй раз. Это даёт $2n-2$ умножение и $n$ сложений. Тем не менее для реализации указанного способа необходимо хранить некоторую информацию в памяти. Ещё более совершенный способ даёт схема Горнера. 

Представим выражение $a_n\lambda^n+\dots+a_1\lambda+a_0$ в виде $(\dots((a_n\lambda+a_{n-1})\lambda+a_{n-2})\dots)\lambda+a_0$. Определим элементы $b_i$ по правилу $b_i=b_{i+1}\lambda+a_i$, начиная с $b_n=a_n$. Тогда $b_0=f(\lambda)$. Видно, что при таком подходе используется только $n$ умножений и $n$ сложений. Однако, это ещё не всё:

\lm Числа $b_i$ в схеме Горнера являются коэффициентами неполного частного при делении $f(x)$ на $x-\lambda$. 
\elm
\proof
Пусть $f=(x-\lambda)q+f(\lambda)$, где $q(x)=c_nx^{n-1} +\dots +c_1$. Вначале заметим, что старший коэффициент неполного частного $c_n$ обязан быть равен $b_n=a_n$. Сравним теперь коэффициенты при степени $i$ справа и слева. Получаем $a_{i}=c_{i}-\lambda c_{i+1}$, то есть $c_i=c_{i+1}\lambda +a_{i}$ удовлетворяет той же рекуррентной формуле, что и $b_i$
\endproof

Оптимальность схемы Горнера и ещё много чего было доказано в 1966 году Виктором Паном в работе <<\href{http://www.mathnet.ru/php/archive.phtml?wshow=paper&jrnid=rm&paperid=5823&option_lang=rus}{О способах вычисления значений многочленов}>>. Там же можно найти метод позволяющий сэкономить ещё половину операций, если разрешены предвычисления.




\section{Неприводимые многочлены над $\R$ и $\C$}

Многочлен с коэффициентами в поле однозначно раскладывается на неприводимые множители. Множителям первой степени соответствуют корни. Однако бывают и множители большей степени. Работать с ними часто не удобно. Гораздо приятнее считать, что они раскладываются на линейные множители, но над большим полем. 

\rm Многочлен степени 2 и 3 с коэффициентами в поле $K$ неприводим в $K[x]$ тогда и только тогда, когда он не имеет корней в $K$.
\erm

\exm\\
1) Многочлен $x^2-2$ неприводим, как многочлен в $\mb Q[x]$, но приводим как многочлен с вещественными коэффициентами.\\
2) Многочлен $x^3-x+1$ неприводим, как многочлен с рациональными коэффициентами.\\
3) Многочлен степени 3 из $\mb R[x]$ не может быть неприводимым.\\
4) Многочлен $x^2+1$ неприводим в $\mb R[x]$.\\


Посмотрим в этой связи на следствия основной теоремы алгебры.

\crl Пусть $0\neq f(x) \in \mb C[x]$ -- многочлен. Тогда $f(x)$ раскладывается на линейные множители. В частности,  у любого многочлена $f$ количество комплексных корней с учётом кратности равно его степени.
\ecrl
\proof Индукция по степени $f(x)$. Пусть $\lambda$ -- корень $f(x)$. Тогда $f(x)=(x-\lambda)g(x)$. Но тогда $g(x)$ раскладывается на линейные множители по индукционному предположению, а значит и $f(x)$.
\endproof

Посмотрим, что же получается для вещественных чисел.

\lm Пусть $\lambda \in \mb C$ корень $f(x)\in \mb R[x]$. Тогда $\ovl{\lambda}$ -- тоже корень $f(x)$.
\elm 
\proof Достаточно воспользоваться леммой про гомоморфизм и корень.
\endproof

\lm Пусть $f(x)\in \mb R[x]$ имеет комплексный корень $\lambda \notin \mb R$, тогда $f(x)\di(x-\lambda)(x-\ovl{\lambda})$ в $\mb R[x]$.
\proof Если $\lambda \notin \mb R$, то $\ovl{\lambda}\neq \lambda$ тоже корень $f$. Тогда $f(x)\di(x-\lambda)(x-\ovl{\lambda})$ в $\mb C[x]$. Заметим, что последний многочлен -- вещественный и неприводимый над $\mb R$, так как не имеет вещественных корней. Обозначим его $r(x)=(x-\lambda)(x-\ovl{\lambda})$. Предположим, что $f(x)\ndi r(x)$ в $\mb R[x]$. По неприводимости $r(x)$ получаем, что $(f(x),r(x))=1$. Рассмотрим линейное разложение НОД-а: $u(x)f(x)+g(x)r(x)=1$. Подставим $x=\lambda$. Правая часть равна 0, а левая 1. Противоречие. Значит $f(x)\di r(x)$, что и требовалось. 
\endproof
\elm

\thrm Любой неприводимый многочлен над $\mb R$ либо линеен, либо является многочленом второй степени с отрицательным дискриминантом.
\ethrm
\proof Рассмотрим неприводимый над $\mb R$ многочлен $p(x)$. У него есть комплексный корень $\lambda$. Если $\lambda \in \mb R$, то $p(x)\di (x-\lambda)$ и по неприводимости $p(x)=x-\lambda$.  Если $\lambda \notin \mb R$, то $p(x)\di (x-\lambda)(x-\ovl{\lambda})$ в $\mb R[x]$. Этот многочлен не имеет вещественных корней и, следовательно, имеет отрицательный дискриминант. Обратно, любой линейный многочлен и квадратичный многочлен с отрицательным дискриминантом неприводимы над $\mb R$.
\endproof

Доказательство даёт пример того, как получить разложение вещественного многочлена на вещественные же неприводимые множители -- для этого достаточно найти все комплексные корни, разбить их на пары сопряжённых друг другу и сгруппировать комплексные множители по этим парам.

Посмотрим пример: разложим на неприводимые вещественные множители многочлен $x^4+1$. Его комплексные корни -- это числа $\frac{\pm 1\pm i}{\sqrt{2}}$. Посмотрим на первую пару корней  -- это $x_1=\frac{1+i}{\sqrt{2}}$ и $x_2=\frac{1-i}{\sqrt{2}}$. Перемножив $(x-x_1)(x-x_2)$ получаем $x^2-\sqrt{2}x+1$. Для оставшейся пары получаем $x^2+\sqrt{2}x+1$. Итого
$$x^4+1=(x^2-\sqrt{2}x+1)(x^2+\sqrt{2}x+1).$$

Заметим так же, что этот многочлен неприводим над $\Q$. Действительно, любой неприводимый делитель над $\Q$ должен быть произведением какого-то набора неприводимых над $\R$, возможно, домноженный на константу. Ни один из неприводимых множителей выше нельзя сделать множителем с рациональными коэффициентами домножением на константу, поэтому необходимо, чтобы неприводимый множитель $x^4+1$ над $\Q$ делился и на $x^2-\sqrt{2}x+1$ и на $x^2+\sqrt{2}x+1$, а значит на их произведение, то есть на $x^4+1$. Этого мы и хотели.




\section{Производная}

Нам понадобится понятие производной многочлена. Оказывается, что это определение можно дать над любым кольцом. 

\dfn Пусть $R$ -- кольцо, а $f\in R[x] $ имеет вид $f(x)=a_0+\dots+a_nx^n$. Тогда определим производную как $f'(x)=a_1+2a_2x+\dots+na_nx^{n-1}$.
\edfn

Проверим, что все основные свойства производной верны в этом контексте.

\thrm[Свойства] Пусть $f(x),g(x) \in R[x]$. Тогда:
\begin{itemize}
\item $(f(x)+g(x))'= f'(x)+g'(x)$
\item $(\lambda f(x))'=\lambda f'(x)$ для всех $\lambda \in R$.
\item  $(f(x)g(x))'=f'(x)g(x)+f(x)g'(x)$
\item $(f^n(x))'=nf'(x)f^{n-1}(x)$.
\item $(f(g(x)))'=g'(x)f'(g(x))$.
\end{itemize}
\ethrm
\proof Первое и второе свойства понятны. Перейдём к третьему свойству. Докажем его сначала для мономов:
$$(x^{n+m})'=(n+m)x^{n+m-1}=nx^{n-1}x^{m}+mx^{m-1}x^n=(x^n)'x^m+(x^{m})'x^n.$$
Теперь пусть $f=\sum a_i x^i$, а $g(x)=\sum b_j x^j$ -- произвольные. Тогда 
$$(fg)'= 
\sum_{i,j} a_ib_j (x^{i+j})'= \sum a_ib_j (x^i)'x^j + \sum a_ib_j x^i(x^j)'=f'g+g'f$$ 
Покажем четвёртое свойство индукцией по $n$. База при $n=1$ тривиальна. Дальше имеем 
$$(f^n)'=(f\cdot f^{n-1})'=f'f^{n-1}+f(n-1)f'f^{n-2}=nf'f^{n-1}.$$
Теперь покажем последнее свойство. Распишем $f(x)=\sum a_i x^i$. Тогда $$(f(g(x)))'=\sum a_i (g^i(x))'= \sum i a_i g^{i-1}(x) g'(x)= g'(x) f'(g(x))$$


\endproof

\thrm Пусть $R$ -- кольцо. Если многочлен $f(x) \in R[x]$ делится на $g(x)^l$ то $f'(x) \di g(x)^{l-1}$. Более того, если $R=K$ -- поле, $g(x)$ неприводим, $\chr K > \deg f$ или $\chr K=0$, а $f(x) \ndi g(x)^{l+1}$, то $f'(x)\ndi g(x)^{l}$.
\ethrm
\proof Пусть $f(x)=g(x)^lh(x)$. Тогда $$f'(x)=lg(x)^{l-1}g'(x)h(x)+g(x)^lh'(x)=g(x)^{l-1}(lg'(x)h(x)+g(x)h'(x)) \di g(x)^{l-1}.$$
Пусть теперь $f(x) \ndi g(x)^{l+1}$, многочлен $g(x)$ неприводим и выполнено условие на характеристику. Наша задача доказать, что последний сомножитель в разложении $f'$ взаимнопрост с $g(x)$ при указанных условиях. Надо показать, что $lg'(x)h(x)\ndi g(x)$. Благодаря неприводимости $g(x)$  и тому что $f(x)\ndi g^{l+1}(x)$ получаем, что $h(x)$ и $g(x)$ взаимно просты.   Тогда вопрос сводится к взаимной простоте $lg'(x)$ и $g(x)$. Заметим, что если $lg'(x)$ не 0, то он действительно взаимнопрост с $g(x)$ так как $g(x)$ неприводим, а $lg'(x)$ имеет заведомо меньшую степень. 

Итого пусть $lg'(x)=0$. Понятно, что в условиях теоремы $l\neq 0$ в $K$. Следовательно, надо рассмотреть ситуацию, когда $g'(x)=0$.
Если $\chr K =0$, то и $g'(x)\neq 0$. Если $\chr K =p>\deg f$, то заметим, что $\deg f \geq \deg g=s$. В этом случае, старший член производной $g'(x)$ будет иметь вид $sa_s$, и, следовательно, не равен 0 так как $s\leq \deg f < \chr K$. 
\endproof


\crl Пусть $K$ --- поле, $f\in K[x]$ многочлен степени $n$ и $\chr K = 0$ или $\chr K>n$. Пусть $a$ корень $f$. Тогда кратность  $a$ как корня $f$ равна $l$ тогда и только тогда, когда кратность корня $a$ у $f'$ равна $l-1$.
\ecrl

\crl Пусть $K$ --- поле, $f\in K[x]$ многочлен степени $n$ и $\chr K = 0$ или $\chr K>n$. $a$ -- корень кратности $l$ многочлена $f(x)$ тогда и только тогда, когда $0=f(a)=f'(a)=\dots=f^{(l-1)}(a)$ и $f^{(l)}(a)\neq 0$.
\ecrl

\rm Это утверждение можно доказать когда $K$ -- область целостности, что мы и сделали на паре.
\erm

В условиях теоремы оказывается возможным избавиться от всех кратных корней (а на самом деле и от всех кратных множителей $f$). Точнее

\crl Пусть $K$ --- поле, $f(x)\in K[x]$ многочлен степени $n$ и $\chr K = 0$ или $\chr K>n$. Тогда многочлен $\frac{f(x)}{\Nod(f(x),f'(x))}$ имеет те же неприводимые множители, что и $f(x)$. При этом каждый  неприводимый множитель $f$ входит с кратностью $1$.
\ecrl

\noindent {\bf Пример:} Вот пример многочлена, у которого проблемы с кратностью корня у производной: $x^{p}$ в $\mb Z/p$. Его производная равна 0. И кратность корня -- бесконечность. Это несколько экзотичная ситуация. Для примера менее экзотичной ситуации посмотрим на многочлен $x^p(x-1) \in \mb Z/p[x]$. Его производная это $x^p$ имеет такую же кратность корня $x=0$, как и исходный многочлен.



Посмотрим, как связана производная и коэффициенты многочлена. Для этого посмотрим вот на какой вопрос. Рассмотрим простейший многочлен $x-a \in R[x]$. Можно ли разложить многочлен по степеням $x-a$? Ответ да, можно.

\utv Пусть $R$ -- кольцо, $a\in R$  и $f(x)\in R[x]$ степени $n$. Тогда существуют и единственные коэффициенты $a_0,\dots, a_n$, что $$f(x)=a_0+a_1(x-a)+\dots+a_n(x-a)^n.$$
\proof Рассмотрим отображение $R[x] \to R[y]$ переводящее $f(x)\to f(y+a)$. Пусть $f(y+a)=a_0+\dots+a_n y^n$. Подставим $y=x-a$. Тогда $f(x)=a_0+\dots+a_n(x-a)^n$. Таким образом, мы показали существование.
Для доказательства единственности заметим, что $f(x)=a_0+\dots+a_n(x-a)^n$, то необходимо при подстановке $x\to y+a$ этот многочлен перейдёт в $f(y+a)=a_0+\dots+a_ny^n$. Но коэффициенты $a_i$ в такой записи определены однозначно.
\endproof
\eutv



Вопрос состоит в том, как найти эти коэффициенты в разложении по степеням $x-a$?

\thrm[Формула Тейлора для многочленов]
Пусть $f(x)$ многочлен в $R[x]$, где $R$ -- область целостности и  $\chr R =0$, или $\chr R > \deg f=n$. Тогда имеет место формула
$$f(x)= f(a)+f'(a)(x-a)+\frac{f''(a)}{2}(x-a)^2+  \dots + \frac{f^{(n)}(a)}{n!}(x-a)^n.$$
\proof По предыдущей теореме у нас есть разложение
$$f(x)=a_0+a_1(x-a)+\dots+a_n(x-a)^n.$$
Возьмём $k$-ую производную от обеих частей равенства. Получим
$$ f^{(k)}(x)=k!a_k+(k+1)!a_{k+1}(x-a)+\dots+\frac{n!}{k!}a_n(x-a)^{n-k}.$$
Осталось подставить $x=a$.
\endproof
\ethrm







\subsection{Дополнительно: Метод Ньютона и лемма Гензеля} 

Условие, что у многочлена нет кратных корней, является важным для того, чтобы эффективно искать корни многочленов. В частности, для метода Ньютона приближённого поиска корней многочлена. Опишем этот метод.


Пусть $f$ -- многочлен без кратных корней (можно и с кратными корнями, но тогда метод может плохо работать). Рассмотрим некоторую точку $x_0$. Это нулевое приближение к корню. Построим следующее приближение. Можно посмотреть на $f(x)$ около точки $x_0$ 
$$f(x)=f(x_0)+f'(x_0)(x-x_0)+\dots.$$
и заменить $f(x)$ на свое <<линейное приближение>>.
Возьмём $x_1$ равным корню уравнения $0=f(x_0)+f'(x_0)(x-x_0)$. Его легко найти. Он равен $x_1=x_0-\frac{f(x_0)}{f'(x_0)}$. Поступая так и далее получим последовательность $x_n$ заданную правилом $$x_{i+1}=x_i-\frac{f(x_i)}{f'(x_i)}.$$

Таким образом, мы построили последовательность $x_n$, про которую мы надеемся, что она сходится к корню многочлена $f(x)$. Покажем, что так действительно бывает.

\thrm Пусть $f(x)\in K[x]$ (где $K=\mb R$ или $\mb C$). Пусть $\hat{x}\in K$ -- корень $f(x)$ кратности $1$. Тогда существует такая положительная $C>0$, что для любого $x_0 \in K$, такого что $|\hat{x}-x_0|<C$ последовательность точек метода Ньютона сходится к $\hat{x}$.
\ethrm
\proof Напишем оценку для $|\hat{x}-x_{i+1}|$ через $|\hat{x}-x_i|$. Имеем 
$$|\hat{x}-x_{i+1}|=\left|\hat{x}-x_i+\frac{f(x_i)}{f'(x_i)}\right|=\left|\frac{f'(x_i)(\hat{x}-x_i)+f(x_i)}{f'(x_i)}\right|$$
Распишем значение многочлена $f(x)$ в точке $\hat{x}$ используя разложение по степеням $x-x_i$. 
$$0=f(\hat{x})= f(x_i)+f'(x_i)(\hat{x}-x_i)+\frac{f''(x_i)}{2}(\hat{x}-x_i)^2 + (\hat{x}-x_i)^3 g(x_i)$$
Здесь хвост в разложении по Тейлору заменён на $(\hat{x}-x_i)^3 g(x_i)$ для некоторого многочлена $g(x)$. Начало этой суммы есть в точности числитель дроби. Тогда
$$|\hat{x}-x_{i+1}|=\left|\frac{\frac{f''(x_i)}{2}(\hat{x}-x_i)^2 + (\hat{x}-x_i)^3 g(x_i)}{f'(x_i)}\right|=|\hat{x}-x_i|^2\left|\frac{\frac{f''(x_i)}{2} + (\hat{x}-x_i) g(x_i)}{f'(x_i)}\right|$$

Заметим, что так как $\hat{x}$ не кратный корень, то $f'(\hat{x})\neq 0$. Значит существует константа $C_1>0$, что  $|f'(x)|>D_1>0$ для всех $x$, таких что $|\hat{x}-x|<C_1$ как и любая уважающая себя непрерывная функция. Вторая производная многочлена $f$ ограничена при $|\hat{x}-x|<C_1$, то есть $|f''(x)|<D_2$ для некоторого $D_2 \geq 0$ (так как многочлен -- непрерывная функция). Слагаемое же $|(\hat{x}-x) g(x)|<D_3$  ограничено при $|\hat{x}-x|<C_1$ по тем же причинам. 
Значит при $|\hat{x}-x_i|<C_1$
$$|\hat{x}-x_{i+1}|\leq |\hat{x}-x_i|^2 \frac{D_2+D_3}{D_1}= D |\hat{x}-x_i|^2.$$
Если, скажем, $|\hat{x}-x_i|<\frac{1}{2D}$, то $|\hat{x}-x_{i+1}|<\frac{1}{2}|\hat{x}-x_i|$. То есть расстояние уменьшилось по крайней мере вдвое. Отсюда следует, что выбрав $x_0$, такое что $|\hat{x}-x_0|<\min (C_1,\frac{1}{2D})$ расстояние до $\hat{x}$ на каждом шаге итерации будет уменьшаться вдвое, что и приведёт к сходимости последовательности $x_i$ к точке $\hat{x}$.
\endproof

На самом деле неравенство $|\hat{x}-x_{i+1}|<D|\hat{x}-x_i|^2$ означает, что для достаточно близких к $\hat{x}$ точек, число совпадающих знаков после запятой у $\hat{x}$ и $x_{i+1}$ примерно вдвое больше, чем у $\hat{x}$ и $x_i$. Это гораздо сильнее, чем уменьшение расстояния в два раза, что гарантирует на каждом шаге только один новый точный знак (в двоичной системе).

Так же видно, что если $\hat{x}$ кратный корень, то такая хорошая оценка невозможна.

К сожалению, достаточно близкая точка -- это далеко не любая точка. Мы  заранее не сможем предсказать для данной точки $x_0$ сойдётся ли последовательность из метода Ньютона, а если сойдётся, то к корню в каком интервале.

В качестве примера того, что точка может привести к несходящейся последовательности из метода Ньютона, легко привести многочлен и точку $x_0$, которая вызывает зацикливание. Например, рассмотрим такой многочлен $f(x)$, что $f(0)=f(1)=1$ и $f'(1)=1$, а $f'(0)=-1$. Таковым, например, является многочлен $(x-\frac{1}{2})^2+\frac{3}{4}$. Стартуя с точки $x_0=0$ мы приходим в точку $x_1=1$ и потом в $x_2=0$, то есть попадаем в цикл. Можно придраться и сказать, что у этого многочлена нет корней и потому всё так плохо. Однако, добавив слагаемое вида $c x^2(x-1)^2$ мы получим многочлен у которого есть корни (при подходящем $c$), но который удовлетворяет тем же условиям $f(0)=f(1)=1$ и $f'(1)=1$, а $f'(0)=-1$.

Несложно построить такой многочлен, для которого метод Ньютона будет приводить к циклу произвольной длины. Например, цикл длины три получится, если $f(-1)=f(0)=f(1)=1$ и $f'(0)=f'(1)=1$, но $f'(-1)=-\frac{1}{2}$.



Рассмотрим на первый взгляд другую задачу. Можно ли свести решение уравнения по модулю $p^n$ к решению уравнению по модулю $p$? Оказывается, что во многих случаях это так. И помогает в этом лемма Гензеля.

\lm Пусть $f(x)\in \mb Z[x]$ и дано целое число $a$, что $f(a)\equiv 0 (\mod p)$. Предположим так же, что $f'(a)\nequiv 0 ( \mod p)$. Тогда  для любого $k\in \mb N$ существует единственное $b$ по модулю $p^k$, что $f(b)\equiv 0(\mod p^k)$ и $b\equiv a (\mod p)$.   
\elm
\proof Будем доказывать утверждение индукцией по $k$. При $k=1$ надо взять $b=a$. Перейдём к шагу индукции. Заметим, что если мы нашли $b$ по модулю $p^k$ и показали его единственность, то это $b$ годится и для всех меньших степеней $p$, причём единственность так же выполнена. Таким образом, достаточно показать, что если нашлось единственное такое $b$ по модулю $p^k$, что $f(b)\equiv 0 mod p^k$  то существует единственное $b_{new}$ по модулю $p^{2k}$ удовлетворяющее аналогичному условию по модулю $p^{2k}$. То есть достаточно удваивать степень.

Перейдём к доказательству. Заметим, прежде всего, что $b_{new}$, если оно есть, должно давать решение исходной задачи по модулю $p^k$. Так как мы предположили, что $b$ есть единственное решение по модулю $p^k$, то $b_{new}\equiv b \mod p^k$. Таким образом, нам необходимо искать $b_{new}$ в виде $b_{new}=b+rp^k$. Нам надо найти подходящее $r$ и показать, что оно однозначно определено по модулю $p^k$ -- отсюда последует единственность $b_{new}$ по модулю $p^{2k}$.

Разложим $f(x)$ по степеням $(x-b)$. Получаем $f(x)=f(b)+f'(b)(x-b)+(x-b)^2g(x)$. Подставим $x=b+rp^k$ и посмотрим на получившееся по модулю $p^{2k}$. 
$$f(x)=f(b)+f'(b)rp^k+r^2p^{2k}g(x)\equiv f(b)+f'(b)rp^k \mod p^{2k}$$
Таким образом, необходимо найти $r$, что $f(b)+f'(b)p^kr\equiv 0 \mod p^{2k}$. Заметим, что $f(b)$, как целое число, делится на $p^k$. Разделив всю левую часть на $p^k$ придём к сравнению сравнение по модулю $p^k$
$$\frac{f(b)}{p^k}+rf'(b)\equiv 0\mod p^k.$$
Заметим, что $f'(b)\equiv f'(a) \mod p$ и потому взаимно просто с $p$. Значит $f'(b)$ обратимо по модулю $p^k$. Тогда 
$$r\equiv -\frac{f(b)}{p^k}f'(b)^{-1}\mod p^k.$$
Это показывает существование и единственность для $r$ и, следовательно, для $b_{new}$.  
\endproof
Указанный процесс похож на процесс уточнения вещественного решения уравнения. Действительно, из  соотношения на $r$ можно получить $b_{new}$ по модулю $p^{2k}$. Имеем $$b_{new}=b+rp^k=b-\frac{f(b)p^k}{p^k}f'(b)^{-1}=b-\frac{f(b)}{f'(b)} (\mod p^{2k})$$
То есть, даже формула для нового <<приближения>> в точности совпадает с формулой из метода Ньютона.

Лемма Гензеля может быть применена для нахождения целочисленных корней полиномиального уравнения $f(x)=0$, где $f(x)\in \mb Z[x]$. Для этого выберем простое число $p$ и решим сначала уравнение $f(x)=0$ в $\mb Z/p$. Если $p$ мало, то сделать это можно перебором всех остатков по модулю $p$. Найдём решения $a_0,\dots,a_k$. Далее, используя лемму Гензеля, поднимем эти решения по модулю степени $p^{\alpha}$ для достаточно большого $\alpha$. Здесь уместно воспользоваться следующим замечанием:

\rm Пусть $N$ -- нечётное натуральное число. Тогда множество чисел от $\frac{-N+1}{2}$ и до $\frac{N-1}{2}$ является полной системой вычетов по модулю $N$. Если $x_0$ -- целое число, что $|x_0| <\frac{N}{2}$  и $x$ -- это элемент из указанной системы вычетов, такой что $x\equiv x_0 \mod N$, то $x=x_0$.
В случае чётного $N$ нужно чуть поменять систему вычетов.
\erm

Это замечание означает, что $x_0$ -- целочисленный корень уравнения $f(x)=0$ должен быть равен своему каноническому  из указанной полной системы вычетов по модулю $p^{\alpha}$, если $\frac{p^{\alpha}}{2}> |x_0|$. Но $x_0$ так же должен являться решением $f(x)=0$ в $\mb Z/p^{\alpha}$, а все решения в $\mb Z/p^{\alpha}$ мы уже перечислили. Таким образом, для нахождения корня достаточно просто взять и подставить всех представителей корней по модулю $p^{\alpha}$ в $f(x)$ и проверить, действительно ли они дают целочисленные решения.  

Остался вопрос в выборе $p$ и выборе $\alpha$. Выбор $\alpha$ должен быть таким, чтобы $\frac{p^\alpha}{2}$ был заведомо больше по модулю, чем любой корень $f(x)$. Для этого необходимо иметь оценку сверху на корни многочлена.

\lm Пусть $f(x) \in \mb R[x]$ представлен в виде $f(x)=a_0+a_1x+\dots+a_n x^n$. Тогда, если $x_0$ корень $f(x)$, то $|x_0|\leq \max\{1,\frac{1}{a_n}(|a_0|+\dots+|a_{n-1}|)\}$. 
\elm
\proof  Без ограничения общности будем считать $a_n=1$. Предположим противное Пусть теперь $x_0$ -- решение, $|x_0|> 1$ и $|x_0|> (|a_0|+\dots+|a_{n-1}|)$. Тогда $-x_0^n=a_0+a_1x_0+\dots+a_{n-1} x_0^{n-1}$. Оценим модуль левой части 
$$|a_0+a_1x_0+\dots+a_{n-1} x_0^{n-1}|< |a_0|+\dots+|a_{n-1}| |x_0|^{n-1} \stackrel{|x_0|\geq 1}{<} |x_0|^{n-1}(|a_0|+\dots+|a_{n-1}|) < |x_0|^n$$
Но это противоречит тому, что $x_0$ решение.
\endproof

Попробуем немного разобраться с применением леммы Гензеля для  решения уравнения $x^k-a=0$, то есть для извлечения корней из $a \in \mb Z$. Какое  $p$ можно выбрать для данных $a$ и $k$?  
Возьмём производную $kx^{k-1}$. Посмотрим, когда у $x^k-a$ есть общий корень $kx^{k-1}$. Есть две возможности. Первая состоит в том, что $k=0$ по модулю $p$. Вторая состоит в том, $0$ -- единственный корень $x^{k-1}$, является и корнем $x^k-a$.  Для того, чтобы исключить эти возможности потребуем, чтобы $k\ndi p$ и $a\ndi p$. Для таких простых $p$ уже можно применять лемму Гензеля. Такие $p$ найдутся и, как мы обсудили, найдутся достаточно маленькие.  Однако, будет несколько нехорошо, если у уравнения по модулю $p$ будет много решений. В принципе и этого иногда можно избежать. Вспомнив про RSA  получаем, что если $(k,p-1)=1$, то тогда решение единственно. Если $k=2$, то решений у квадратного уравнения не более 2 и это не страшно. Если $k$ чётное, то можно сначала попытаться извлечь квадраты, а потом извлекать корень нечётной степени. Если же с самого начала $k$ нечётно, то такое $p$ найти можно.

\upr Оцените количество операций, которое необходимо затратить для вычисления корня из целого числа при помощи леммы Гензеля.
\eupr



\subsection{Дополнительно: Изоляция корней и правило знаков Декарта}

Мы обсудили, как приближённо найти корни многочлена при помощи метода Ньютона. Однако, как мы показали, метод Ньютона не всегда сходится к решению системы так как, например, может попасть в цикл. Такого не происходит, если метод Ньютона стартует из начальной точке, достаточно близкой к корню. Таким образом, встаёт задача нахождения таких промежутков, что в этих промежутках находится по одному вещественному корню многочлена и метод Ньютона сходится к этому корню для любой начальной точки из промежутка.

Рассмотрим первую часть проблемы -- нахождение промежутков, в которых вещественный многочлен содержит один вещественный корень. Это задача называется задачей изоляции корней. Большинство методов решения этой задачи позволяют по произвольному промежутку $(a,b)$ сказать, сколько корней $f(x)$ содержится в этом промежутке. Само по себе это знание позволяет найти приближённо все корни многочлена, ведь зная, что на промежутке $(a,b)$ содержится один корень мы просто можем поделить промежуток пополам и посмотреть, в какую из половин этот корень попал и тем самым ещё больше уточнить, куда попал корень. Стоит заметить, правда, что такой вариант бинарного поиска работает гораздо медленнее метода Ньютона -- за одну итерацию он делит промежуток пополам -- то есть уточняет на один двоичный знак корня больше в то время как метод Ньютона, фактически, удваивает число верных знаков.

Первым работающий метод предложил в 1829 году французский математик Жак Шарль Франсуа Штурм. Как и более ранние методы, дающие оценку на число корней на промежутке $a,b$ теорема Штурма формулируется используя понятие числа перемен знака.

\dfn Пусть $c_0,\dots,c_n$ -- последовательность вещественных чисел. Тогда число  перемен знака в этой последовательности вычисляется по следующему правилу: сначала выкидываются все 0, а потом в оставшейся последовательности считается число пар соседних чисел разного знака.
\edfn
\noindent Сформулируем теорему Штурма:

\begin{thmm}[Штурм] Пусть $f(x) \in \mb R[x]$ -- многочлен без кратных корней. $[a,b]$ -- промежуток на котором ищутся корни. При этом $f(a),f(b)\neq 0$. Рассмотрим последовательность многочленов $f_i$ определённых по правилу $f_0(x)=f(x)$, $f_1(x)=f'(x)$, а при $2\leq i\leq n$ имеем $f_{i-2}(x)=f_{i-1}(x)q(x)-f_i(x)$, причём $\deg f_i \leq \deg f_{i-1}$. Тогда число вещественных корней многочлена $f(x)$ равно $W(a)-W(b)$, где $W(a)$ равно числу перемен знака в последовательности $f_0(a),\dots,f_n(a)$. 
\end{thmm}

Доказательство см. в учебнике Кострикина -- Введение в алгебру. Часть 1. Основы алгебры, стр 245. или в книге Прасолова Многочлены стр. 42.

Однако большая часть современных методов нахождения корней основывается на другой теореме, позволяющей лишь дать оценку на число корней на промежутке. 

\thrm[Фурье-Бюдан] Пусть $f(x)\in \mb R[x]$ c $\deg f=n$, а промежуток $[a,b]$ таков, что $f(a),f(b)\neq 0$. Тогда число корней многочлена $f(x)$ на промежутке $[a,b]$ с учётом кратности меньше или равно $V(a)-V(b)$, где $V(a)$ есть число перемен знака в последовательности $f(a),f'(a),\dots,f^{(n)}(a)$. Кроме того, число корней с учётом кратности отличается от $V(a)-V(b)$ на чётное число.
\ethrm
\proof Построим доказательство следующим образом: точка  $x$  будет двигаться от $a$ к $b$ и мы будем смотреть, как меняется число $V(a)-V(x)$. Прежде всего заметим, что если между точками  $x$  и $y$ нет корней ни у $f(x)$, ни у его производных, то $V(x)=V(y)$, так как знаки $f^{(i)}(x)$ и $f^{(i)}(y)$ одинаковы.

Таким образом, $V(x)\neq V(y)$, возможно лишь если между $x$ и $y$ есть корень $f^{(j)}(x)$. Посмотрим как меняется $V(x)$, когда мы проходим  через $x_0$ -- корень некоторой производной $f(x)$. 

Если $x_0$ -- корень какой-то производной $f(x)$, то в последовательности $f(x_0),\dots,f^{(n)}(x_0)$ есть нули. Все нули в этой последовательности можно разбить на блоки нулей. Блок длины $r$ начиная с позиции $k$ означает, что у $f^{(k)}(x)$ точка $x_0$ есть корень кратности $r$. Блоки нулей разделены между собой какими-то ненулевыми значениями. Количество перемен знака в последовательности $f(x),f'(x),\dots, f^{(n)}(x)$ до точки $x_0$ и после точки $x_0$ может отличаться только потому, что поменяли знак производные, которые лежали в каком-то блоке нулей в последовательности $f(x_0),f'(x_0),\dots, f^{(n)}(x_0)$. 

Будем разбираться с каждым блоком нулей по отдельности. Рассмотрим сначала основной случай, когда $x_0$ -- это корень кратности $r$ самого многочлена $f(x)$. Это означает, что последовательность $f(x_0), \dots, f^{(n)}(x_0)$ начинается с блока из $r$ нулей. Разберёмся с переменами знаков, связанных с этим блоком.

Удобно будет обозначать многочлен, делящийся на $(x-x_0)^k$ как $O((x-x_0)^k)$. Это довольно неплохо согласовано с определениями из математического анализа. Если $x_0$ -- корень кратности $r$, то  $f(x)=c_r(x-x_0)^r + O((x-x_0)^{r+1})$, где $c_r\neq 0$.  Тогда первые $r$ производных $f(x)$ будут иметь вид $$f^{(k)}(x)= \frac{r!}{(r-k)!}c_r(x-x_0)^{r-k}+O((x-x_0)^{r-k+1}), \text{ где } 0\leq k\leq r.$$ 
Знак $k$-ой производной в окрестности точки $x_0$ совпадает со знаком $c_r(x-x_0)^{r-k}$. Без ограничения общности можно считать, что $c_r>0$, так как количество перемен знака не изменится, если мы домножим $f(x)$ на $-1$. Тогда получаем следующую расстановку знаков
$$\begin{array}{c|c|c|c}
 \substack{\text{номер}\\ \text{производной} } &\text{ до $x_0$ }& x=x_0 & \text{ после $x_0$ }\\
\hline
0 & (-1)^r & 0 & +\\
\hline
\vdots & \vdots & \vdots & \vdots \\
\hline
r-1 & - & 0 & +\\
r & + & + & +
\end{array}.$$
До точки $x_0$ было $r$ перемен знака в соответствующем блоке нулей, а после стало $0$. $V(x)$ уменьшилось на $r$ при проходе через корень $f(x)$, что и ожидалось.

Осталось разобраться с блоками, соответствующими $x_0$ -- корню производной  $f^{(k)}(x)$ кратности $r$, где $k\geq 1$. В этой ситуации $f^{(k-1)}(x_0)\neq 0$ и $f^{(k+r)}(x_0)\neq 0$, а все производные между ними равны 0 в точке $x_0$. Представим 
$$f^{(k-1)}= a_0+ a_r(x-x_0)^{r+1}+O((x-x_0)^{r+2}) \text{ и } f^{(k)}=(r+1)a_r(x-x_0)^r+O((x-x_0)^{r+1})$$
Здесь $a_0\neq 0$  и $a_r \neq 0$. Будем считать, что $a_r>0$. Тогда среди производных от $k$ до $k+r$ происходит ровно $r$ смен наков до  и ни одной смены знака после. Осталось разобраться, с тем, что происходит со сменой знака между $k-1$ и $k$-ой производными. Нарисуем таблицу   

$$\begin{array}{c|c|c|c}
 \substack{\text{номер}\\ \text{производной} } &\text{ до $x_0$ }& x=x_0 & \text{ после $x_0$ }\\
\hline
k-1& \sgn a_0 & \sgn a_0 & \sgn a_0\\
\hline
k & (-1)^r & 0 & +\\
\hline
\vdots & \vdots & \vdots & \vdots \\
\hline
k+r-1 & - & 0 & +\\
k+r & + & + & +
\end{array}.$$
Пусть $r$ чётно. Тогда перемена знака между первой и второй строками таблицы до $x_0$ и после $x_0$ одинаково зависит от знака $\sgn a_0$. Значит при проходе через $x_0$ $V(x)$ уменьшается на $r$, то есть на чётное число, что и требовалось.

Если же $r$ нечётно, то при $ a_0>0$ до точки $x_0$ есть перемена знака между первой и второй строкой, а после $x_0$ перемены нет. Итого $V(x)$ уменьшится на $r+1$ -- чётное число. Если же $a_0<0$, то до $x_0$ перемены не было, а после появилась, то есть $V(x)$ уменьшилось на $r-1$ -- неотрицательное чётное число.
\endproof


\crl[Правило знаков Декарта] Пусть $f(x)=a_0+\dots+a_nx^n$. Тогда число положительных корней с учётом кратности для многочлена $f(x)$ не превосходит числа количества перемен знака в последовательности $a_0,\dots,a_n$ и отличается от количества перемен знака на чётное число.
\proof Устремим точку $x$ к бесконечности. Тогда $V(x)$ будет равно нулю. То есть $V(0)-V(x)=V(0)$. Но $V(0)$ есть число перемен знака в последовательности $a_0,a_1,2a_2,\dots,n!a_n$, что совпадает с числом перемен знака в последовательности $a_0,a_1,\dots,a_n$. Осталось применить теорему Фурье-Бюдана.
\endproof
\ecrl

\crl Если количество перемен знака в последовательности $a_0,\dots,a_n$ равно единице, то у многочлена $f(x)=a_0+\dots+a_nx^n$ есть единственный положительный корень, а если перемен знака нет, то положительных корней нет.
\ecrl

На правиле знаков Декарта основаны несколько алгоритмов, позволяющие найти интервалы содержащие корни. Ключевым ингредиентом здесь является теорема Винсента.

\begin{thmm}[Винсент,1836] Пусть $f(x)\in \mb R[x]$ -- многочлен. Если задано целое число $a$, то условимся говорить, что многочлен $x^nf(a+\frac{1}{x})$ есть результат преобразования координат $x \to a+\frac{1}{x}$ в многочлене $f(x)$. Тогда для любой последовательности целых чисел $a_0,\dots,a_n,\dots$, что $a_0\geq 0$, $a_i>0$ при $i>0$ существует такое $n$, что после цепочки преобразований $x\to a_0 +\frac{1}{x},\dots, x\to a_n+\frac{1}{x}$  результирующий многочлен $g(x)$ будет иметь либо одну, либо ни одной вариаций знака в последовательности коэффициентов. Более того, если число перемен знака равно единице, то у многочлена $f(x)$ есть единственный корень в интервале между $$a_0+\cfrac{1}{a_1+\cfrac{1}{\ddots\,+\cfrac{1}{a_{n-1}+\cfrac{1}{a_n}}}} \text{ и } a_0+\cfrac{1}{a_1+\cfrac{1}{\ddots+\,\cfrac{1}{a_{n-1}}}}.$$
\end{thmm}

Выбор подходящей последовательности $a_i$ даёт быстрый ответ на вопрос про корни многочлена и даёт приближение к ним. Подробнее смотри \cite[стр 56-61]{McNamee}







\section{Интерполяция}

Довольно часто требуется решить следующую задачу: пусть $K$ --- некоторое поле. Пусть дан набор различных точек
$x_1,\dots, x_n \in K$ и дан набор значений $a_1,\dots,a_n\in K$. Требуется построить многочлен $f\in K[x]$, такой что $f(x_i)=a_i$.
Прежде всего заметим, что у нас есть некоторая свобода выбора. А именно, рассмотрим многочлен $\ffi(x)=(x-x_1)\dots(x-x_n)$. Тогда можно к любому решению интерполяционной задачи прибавить кратное многочлена $\ffi(x)$ и снова получить решение интерполяционной задачи. Таким образом, можно любое решение заменить на остаток от деления на многочлен $\ffi(x)$. В частности, если есть какое-то решение, то есть решение степени строго меньше $n$.

\dfn[Задача интерполяции] Пусть дан набор различных точек $x_1,\dots,x_n\in K$ и дан набор значений
$a_1,\dots, a_n\in K$. Требуется построить многочлен $f\in K[x]$, такой что $f(x_i)=a_i$ и $\deg f < n$.
\edfn

\thrm Пусть $K$ -- поле. $x_1,\dots,x_n \in K$, $a_1,\dots,a_n \in K$ и $x_i\neq x_j$ при $i\neq j$. Тогда задача интерполяции разрешима и притом единственным образом. Более того, её решение может быть найдено по формуле
$$f(x)=\sum_{i=1}^n a_i\frac{\prod_{j\neq i}(x-x_j)}{\prod_{j\neq i } (x_i-x_j)}=\sum_{i=1}^n a_i\frac{\ffi(x)}{\ffi'(x_i)(x-x_i)},$$
где $\ffi(x)=(x-x_1)\dots(x-x_n)$.
\ethrm

\proof Заметим, что $\ffi'(x_i)=\prod_{j\neq i}(x_i-x_j)$. Теперь очевидно, что указанная формула даёт решение нужной степени. Единственность очевидна из леммы о многочленах, совпадающих в достаточном числе точек.
\endproof

Последняя формула называется интерполяционной формулой Лагранжа. На интерполяционную задачу можно посмотреть немного по-другому. А именно, условие, что $f(x_i)=a_i$ можно переписать как $f(x)\equiv a_i \mod (x-x_i)$. Таким образом, интерполяционная задача это частный случай китайской теоремы об остатках для многочленов. Для того, чтобы продвинуться дальше сформулируем Китайскую теорему об остатках в достаточно общей ситуации. 


\subsection{Дополнительно: факторизация колец}


В предыдущем разделе мы заметили, что разрешимость произвольной системы уравнений в целых числах может быть проверена переходом от $\mb Z$ к меньшему кольцу $\mb Z/n$. Нам хочется иметь подобный инструмент в произвольной ситуации.

\dfn Пусть $I$ -- идеал в кольце $R$. Определим отношение сравнимости на кольце $R$ по модулю $I$ как $a\equiv b \mod I$, если $a-b \in I$.
\edfn

\utv Это отношение эквивалентности. Класс эквивалентности элемента $a$ будем обозначать как $a+I$ (или по старому: $\ovl{a}$).
\proof Действительно, если $a\equiv a$, потому что $a-a =0 \in I$. Если $a\equiv b \mod I$, то $a-b \in I$. Тогда $b-a \in I$, то есть $b\equiv a \mod I$. Аналогично $a-b \in I$ и $b-c \in I$, то значит их сумма $a-b+b-c=a-c$ лежит в $I$. То есть $a\equiv c$.
\endproof
\eutv

\dfn Пусть $R$ кольцо, $I$ --- идеал. Рассмотрим фактормножество $R/\equiv_I$. Будем обозначать его просто как $R/I$. Определим на нём структуру кольца задав следующие операции:\\
$$(a+I)+ (b+I) = (a+b)+I \text{ и } (a+I)\cdot (b+I)=ab+I. $$
\edfn

\lm[Конструкция работает!] Пусть $R$ --- кольцо, $I$ --- идеал. Тогда $R/I$ --- кольцо.
\elm
\proof
Прежде всего необходимо проверить корректность заданных операций. Рассмотрим классы $a+I$ и $b+I$ и два других представителя $a+i_1$ и $b+i_2$. Тогда $$(a+i_1)(b+i_2)=ab +ai_2+i_1b+ i_1i_2 \in ab+I,$$
то есть результат произведения не зависит от выбора представителя. Аналогично для суммы.

Далее, необходимо проверить все аксиомы: аксиомы абелевой группы для сложения, дистрибутивность, ассоциативность  и коммутативность для умножения и существование единицы.

Докажем одно из этих свойств, оставив остальные на проверку читателю. Покажем ассоциативность умножения: пусть есть три класса $\ovl{a},\ovl{b},\ovl{c}$. Тогда
$$(\ovl{a}\ovl{b})\ovl{c}=(\ovl{ab})\ovl{c}=\ovl{(ab)c}=\ovl{a(bc)}=\ovl{a}(\ovl{b}\ovl{c})$$
Таким образом, видно, что все свойства $R/I$ наследуются им от кольца $R$. В частности, $0$ это класс $\ovl{0}$, а $1$-ца в $R/I$ это класс $\ovl{1}$.
\endproof

Если идеал $I$, по которому мы факторизуем порождён элементами $a_1,\dots,a_n$, то вместо $R/(a_1,\dots,a_n)$ мы будем писать $R/a_1,\dots,a_n$. В частности, в случае главного идеала $(a)$ будем писать $R/a$.

\crl[Китайская теорема об остатках на языке колец] Пусть $R$ -- область главных идеалов. Рассмотрим попарно взаимно простые элементы $r_1,\dots,r_n$. Тогда кольца
$$R/(r_1 \cdots r_n) \cong R/(r_1) \times\dots \times R/(r_n)$$
изоморфны посредством естественного отображения
$$ x +(r_1\cdots r_n) \to \left(x+(r_1),\dots,x+(r_n)\right).$$
\ecrl 
\proof Биективность указанного отображения равносильна предыдущей формулировке китайской теоремы об остатках. Таким образом, осталось обратить внимание на корректность данного отображения и то, что указанное отображение является гомоморфизмом колец. 
\endproof



Теорема о делении с остатком в кольце многочленов  пригождается нам для описания колец вида $R[x]/g(x)$. Работать с элементами фактора, как с классами эквивалентности сложно. Для того, чтобы побороть эту сложность, надо научиться выбирать из каждого класса эквивалентности по каноническому представителю и работать только с этими представителями. Например, хорошее описание фактора есть в случае  целых чисел. Там ключевую роль играла теорема о делении с остатком. В случае многочленов аналогичную функцию выполняет степень.


\thrm[Описание фактора с помощью остатков] Пусть $K$ -- поле. Рассмотрим многочлен $g \in K[x]$, $g\neq 0$. Тогда для любого многочлена $f(x)$ существует единственный многочлен $r(x)$, такой, что $\ovl{f(x)}=\ovl{r(x)} \,(\mod g(x))$ и $\deg r(x) < \deg g(x)$.
Этот канонический представитель класса $f(x)$ можно найти как остаток от деления $f(x)$ на  $g(x)$. Если $r_1(x)$ -- канонический представитель класса $f_1(x)$, а $r_2(x)$ -- канонический представитель класса $f_2(x)$, то 
$$r_1(x)+r_2(x) \text{ представитель  $f_1(x)+f_2(x)$ и } r_1(x)r_2(x) \mod g(x) \text{ -- представитель } f_1(x)f_2(x).$$
Формула для представителя суммы -- это ключевое отличие теории для многочленов от теории для $\mb Z$, упрощающее работу с многочленами.
\ethrm
\proof
Первая часть --- это просто переформулировка теоремы о делении с остатком. Вторая часть --- заметим, что $r_1+r_2$ сравним с $f_1+f_2$ и степень $\deg(r_1+r_2)\leq \max(\deg r_1, \deg r_2) < \deg g$.
\endproof

\rm Вообще в этом описании можно поле $K$ заменить на область целостности, если потребовать, чтобы старший коэффициент $g(x)$ был обратим.
\erm


\rm Заметим, что базовое поле $K$ лежит внутри фактора $K[x]/f(x)$  в качестве классов постоянных многочленов (если $\deg f\geq 1$, конечно).
\erm




Вот например многочлен $x^3-10x-7$. У него три вещественных корня, то есть в кольце $\mb R[x]$ он раскладывается в произведение $x^3-10x-7=(x-\alpha_1)(x-\alpha_2)(x-\alpha_3)$. По китайской теореме об остатках получаем, что $$\mb R[x]/(x^3-10x-7) \cong \mb R[x]/(x-\alpha_1)\times \mb R[x]/(x-\alpha_2)\times \mb R[x]/(x-\alpha_3)\cong \mb R\times \mb R\times \mb R.$$
Последний изоморфизм появился благодаря тому, что для любого поля $K$ факторкольцо $K[x]/(x-\lambda)$ изоморфно $K$.






Сформулируем, когда фактор $R/p$ обладает хорошими свойствами.



\lm[Критерий целостности для фактора] Пусть $p\neq 0$ -- некоторый элемент в  области целостности $R$. В этом случае $p$ -- простой тогда и только тогда, когда $R/pR$ -- область целостности.
\proof $R/pR$ -- область целостности тогда и только тогда, когда $\ovl{ab}\neq 0$, если $\ovl{a}\neq 0$ и $\ovl{b} \neq 0$, где $\ovl{a}$ и $\ovl{b}$ классы элементов $a,b \in R$. Это происходит тогда и только тогда, когда $ab\notin I$, если $a\notin I$ и $b\notin I$. Что и есть определение простого идеала. Таким образом, понятие простоты -- это практически дословная переформулировка того, что фактор --- область целостности.
\endproof
\elm



Теперь скажем несколько слов про специфику ситуацию с факторами для области главных идеалов.

\lm Пусть $R$ --- область главных идеалов. Тогда элемент $p\neq 0$ простой в $R$ тогда и только тогда, когда $R/p$ - поле.
\proof Пусть $pR$ --- простой идеал в $R$. Покажем, что $R/p$ поле. Рассмотрим элемент $a$, который даёт ненулевой класс в $R/p$. Тогда $a \ndi p$ и, следовательно, $a$ и $p$ взаимно просты. Тогда единица представима в виде $1=ax+py$. Тогда элемент $x$ обратен к $a$ в $R/p$.
Обратно, если $R/p$ -- поле, то $R/p$ -- область целостности. Значит $p$ -- простой.
\endproof
\elm

\rm Для произвольного кольца это не так. Например в кольце $\mb Q[x,y]$ есть идеал $I=(y)$. Это простой идеал так как $\mb Q[x,y]/y\cong \mb Q[x]$, то есть область целостности. С другой стороны $\mb Q[x]$ --- не поле. 
\erm

\subsection{Теорема об изоморфизме и её роль в описании различных колец}

На самом деле, конструкция факторизации даёт отличное описание для различных колец. Возьмём рациональные числа и рассмотрим наименьшее подкольцо в $\mb R$, содержащее $\sqrt[3]{2}$. Кроме собственно $\sqrt[3]{2}$ в этом кольце так же должен лежать $\sqrt[3]{4}=(\sqrt[3]{2})^2$ и все возможные их суммы, то есть элементы вида $a+b\sqrt[3]{2}+c\sqrt[3]{4}$, где $a,b,c \in \mb Q$. Множество таких чисел действительно подкольцо в $\mb R$ и обозначается как $\mb Q[\sqrt[3]{2}]$. 

Априори неясно, обязательно ли  брать $\sqrt[3]{4}$, ведь он может быть элементом вида $a+b\sqrt[3]{2}$. Оказывается, что брать его обязательно. Кроме того, я утверждаю, что  это кольцо --  поле. Почему так? Как, например, обратить элемент $1+3\sqrt[3]{2}+\sqrt[3]{4}$? Или может это 0?

Для этого посмотрим на $\mb Q[x]/x^3-2$. Многочлен $x^3-2$ неприводим над $\mb Q$ так как у него нет корней в $\mb Q$. Значит  $\mb Q[x]/x^3-2$ поле. Как оно связано с $\mb Q[\sqrt[3]{2}]$? Я утверждаю, что эти кольца изоморфны.

Вместо того, чтобы строить соответствие руками я приведу общую машинку, которая даёт это соответствие за "так". 

\dfn Пусть $f\colon X \to Y$ -- отображение множеств. Тогда образом $f$ называется подмножество $Y$ вида
$$\Im f= f(X)=\{y \in Y\, |\, \exists x \in X, \text{ что } f(x)=y\}$$
\edfn

\rm Образ гомоморфизма колец -- всегда подкольцо. 
\erm

Ещё одно определение я дам в контексте групп (потому что его можно там сформулировать).

\dfn Пусть $f\colon G \to H$. Тогда ядром $f$ называют $\Ker f=\{g\in G\,|\, f(g)=1\}$.
\edfn

\lm $\Ker f$ -- это подгруппа в $G$. Гомоморфизм $f$ является мономорфизмом тогда и только тогда, когда $\Ker f=\{1\}$. В этом случае мы будем говорить, что  ядро тривиально (тривиальная подгруппа).
\elm
\proof По свойствам гомоморфизма $1\in \Ker f$. Аналогично, если $g \in \Ker f$, то $f(g^{-1})=(f(g))^{-1}=1^{-1}=1.$ Если же $a,b\in \Ker f$, то $f(ab)=f(a)f(b)=1\cdot 1=1$. Таким образом, $\Ker f $ -- подгруппа в $G$. 

Покажем, что инъективность для гомоморфизма равносильна тому, что $\Ker f=\{1\}$. Действительно, если $f$ -- инъективно, то $f(x)\neq f(y)$, если $x\neq y$. В частности, если взять $x=1$, то получаем, что $f(y)\neq f(1)=1$ для всякого $y\neq 1$. Но это и означает, что  в ядре лежит только единица.  
Таким образом, условие, что $\Ker f=\{1\}$ это просто часть условия инъективности.

Покажем, что этого условия достаточно для инъективности. Действительно, пусть $f(x)=f(y)$. Тогда $$f(xy^{-1})=f(x)f(y)^{-1}=f(x)f(x)^{-1}=1.$$
Значит элемент $xy^{-1}$ лежит в ядре. Но тогда $xy^{-1}=1$, то есть $x=y$, что и требовалось.
\endproof

\rm Не забывайте, что в случае аддитивных обозначений тривиальность ядра означает $\Ker f=\{0\}$.
\erm

\rm Ядро гомоморфизма колец -- это ядро $f$ как гомоморфизмов аддитивных групп.
\erm

\rm Отметим ещё раз, что $\Ker f$ -- идеал в $R$. Проверим самое интригующее: если $r\in R$, а $a\in \Ker f$, то $ra \in \Ker f$. Действительно $f(ra)=f(r)f(a)=f(r)\cdot 0=0$.
\erm 



\thrm[Теорема об изоморфизме] $f\colon R \to S$. Тогда есть изоморфизм $\psi \colon R/\Ker f \cong \Im f$. Причём $\psi$ задаётся как $\psi(a+\Ker f)=f(a)$. 
\ethrm
\proof Правило для $\psi$ задано с одним только, <<но>>, что необходима проверка корректности. Обозначим $\Ker f=I$. Пусть $a=b+k$, где $k\in I$. Тогда $f(a)=f(b+k)=f(b)+0=f(b)$.

Теперь надо показать, что это гомоморфизм. Покажем, только что произведение переходит в произведение (а остальное оставим в качестве упражнения). Действительно
$$\psi((a+I)(b+I))=\psi(ab+I)= f(ab)=f(a)f(b)=\psi(a+I)\psi(b+I).$$

Почему это биекция? Заметим, что отображение $\psi$ сюръективно, ведь элемент вида $f(a)$ получается как образ $\psi(a+I)$. Проверим инъективность. Покажем, что $\Ker \psi =\{0\}$. 
Пусть $a+I\in \Ker \psi$. Это значит, что $\psi(a+I)=f(a)=0$. Но тогда $a\in \Ker f$ и класс $a$ равен $0$ в $R/\Ker f$. 
\endproof

Эту теоремы можно воспринимать так -- если <<обрезать>> всё лишнее от $R$ и $S$, то останутся одинаковые куски.  

Воспользуемся этой теоремой. Рассмотрим отображение $\psi \colon \mb Q[x] \to R$, переводящее $f(x) \to f(\sqrt[3]{2})$. Это гомоморфизм колец. Его образ -- это $\mb Q[\sqrt[3]{2}]$. Найдём его ядро. Очевидно, в ядре лежат многочлены кратные $x^3-2$. Но почему только они? Пусть $r(x)\in \Ker \psi$. Тогда либо $r(x)\di x^3-2$ и мы всё доказали, либо $r(x)$ взаимно прост с $x^3-2$. Третьего не дано, потому что $x^3-2$ неприводим. Итак, пусть $(r(x),x^3-2)=1$. Рассмотрим линейное разложение НОД-а $r(x)g(x)+(x^3-2)f(x)=1$. Подставим $x=\sqrt[3]{2}$. Левая часть обнулится, а в правой останется 1. Противоречие. Значит $\Ker \psi = (x^3-2)\mb Q[x]$. Ясно что это довольно общий аргумент. 

Применим теорему об изоморфизме. Тогда $$\mb Q[x]/x^3-2= \mb Q[x]/\Ker \psi \equiv \mb Q[\sqrt[3]{2}].$$

Как теперь обратить элемент $2+\sqrt[3]{2} + \sqrt[3]{4}$? В поле  $\mb Q[x]/x^3-2$ ему соответствует класс многочлена $x^2+x+2$. Найдём линейное разложение НОД-а для этого многочлена и $x^3-2$ 
$$(x^2+x+2)(-x^2+2)+(x-1)(x^3-2)=2.$$
Отсюда следует, что класс $\frac{1}{2}(-x^2+2)$ обратен к $x^2+x+2$. Переходя обратно в $\mb Q[\sqrt[3]{2}]$ получаем, что элемент $\frac{1}{2}(-\sqrt[3]{4}+2)$ обратен к $2+\sqrt[3]{2} + \sqrt[3]{4}$.

Заметим, что в $\mb Q[\sqrt[3]{2}]$ лежит корень уравнения $x^3-2$. Значит корень этого уравнения лежит и в $\mb Q[x]/x^3-2$. Заметим, что это просто класс $\ovl{x}$. Это более менее общий факт.



\utv[У неприводимого многочлена где-то есть корень] Пусть $f(x)\in K[x]$ -- неприводимый многочлен. Тогда у $f(x)$ есть корень в поле $L=K[x]/f(x)$.
\eutv
\proof Понятно, что $L$ -- поле. Вспомним, что элементы из $K$ представляются классами постоянных многочленов. 
Утверждение теперь состоит в том, что класс элемента $x$ и есть корень $f(x)$ в $L$.

Действительно, если $f(x)=a_nx^n+\dots+a_0$, то $$f(\ovl{x})=\ovl{a}_n\ovl{x}^n+\dots+\ovl{a}_0=\ovl{a_nx^n+\dots+a_0}=\ovl{f(x)}=\ovl{0}$$.
\endproof

\rm Конечно, можно сформулировать аналогичное утверждение и для приводимых многочленов.
\erm






\subsection{Дополнительно: Интерполяция по Эрмиту}

Рассмотрим более общий вариант интерполяционной задачи. А именно, попробуем решить задачу следующего вида.
Пусть задан набор точек $x_1,\dots, x_n$ и для каждой точки $x_i$ задан набор чисел $a_{i,0}, a_{i,1},\dots , a_{i,k_i-1}$. Интерполяционная задача Эрмита состоит в следующем: найти $f$ такой, что $j$-тая производная $f^{(j)}(x_i)=a_{i,j}$. Так же подобную задачу называют интерполяционной задачей с кратными узлами. Покажем, что она имеет решение.



\thrm Пусть $K$ -- поле характеристики 0 (или достаточно большой положительной характеристики). Решение задачи интерполяции по Эрмиту существует и единственно среди многочленов степени меньше $\sum_{i=1}^n k_i$.
\ethrm
\proof Сведём задачу к китайской теореме об остатках. А именно пусть $f(x)$ многочлен. Тогда значения его производных в точке $x_i$ равны $a_{i,j}$ $j\in \ovl{0,k_i-1}$ тогда и только тогда, когда
$$f(x)\equiv a_{i,0}+a_{i,1}(x-x_i)+a_{i,2}\tfrac{(x-x_i)^2}{2!}+\dots+ a_{i,k_i-1}\tfrac{(x-x_i)^{k_i-1}}{(k_i-1)!}\,\, (\mod (x-x_i)^{k_i}).$$
Рассмотрев условия во всех точках $x_i$ получаем систему сравнений. Элементы $(x-x_i)^{k_i}$ взаимно простые. Применяя китайскую теорему об остатках получаем, что у данной системы сравнений есть единственное решение по модулю $\prod_{i}(x-x_i)^{k_i}$. Но тогда среди решений есть единственное, меньшее по степени чем $\prod_{i}(x-x_i)^{k_i}$. Итого у интерполяционной задачи по Эрмиту есть и единственное решение степени меньшей, чем $\sum k_i$.
\endproof

\rm Вообще для  задачи интерполяции по Эрмиту  есть формула, аналогичная формуле Лагранжа, но она не сильно хороша (см. Сборник задач по алгебре под редакцией Кострикина, стр. 93, задача 30.14 ).\erm

\subsection{Метод Ньютона решения интерполяционной задачи}

Как решить интерполяционную задачу Эрмита? Довольно простым способом решения будет метод Ньютона. Разумеется он годится и для решения обычной интерполяционной задачи. Суть метода Ньютона состоит в том, что мы на каждом шаге меняем многочлен $f(x)$ так, чтобы он удовлетворял  ещё одному условию. 

Пусть задан набор точек $x_1,\dots, x_n$ и для каждой точки $x_i$ задан набор чисел $a_{i,0}, a_{i,1},\dots , a_{i,k_i}$. Пусть так случилось, что многочлен $f(x)$ и его производные принимают в точках $x_1,\dots,x_{i-1}$  значения $a_{s,j}$, где $s\in \ovl{1,i-1}$, а $0\leq j< k_s$. Пусть так же в точке $x_i$ выполнено соотношение, что $f^{(j)}(x_i)=a_{i,j}$ при всех $0\leq j<k$, где $k<k_i-1$. Построим такой новый многочлен $f_{new}(x)$, который удовлетворяет описанным соотношениям и новому соотношению $f^{(k)}_{new}(x_i)=a_{i,k}$.

Будем искать многочлен $f_{new}$ в виде $$f_{new}(x)= f(x)+c (x-x_i)^k\prod_{s=1}^{i-1} (x-x_s)^{k_s}.$$
Заметим, прежде всего, что добавка не портит условия интерполяционной задачи, выполнения которых мы уже добились. Осталось подобрать константу $c$ так, чтобы $f^{(k)}_{new}(x_i)=a_{i,k}$. Для этого необходимо посчитать $k$-ую производную многочлена $(x-x_i)^k\prod_{s=1}^{i-1} (x-x_s)^{k_i}$  в точке $x=x_i$. Обозначим за $\ffi(x)=\prod_{s=1}^{i-1} (x-x_s)^{k_i}$. Я утверждаю, что $k$-ая производная $(x-x_i)^k\prod_{s=1}^{i-1} (x-x_s)^{k_i}$ в $x=x_i$ равна $k!\ffi(x_i)$. Это можно получить, например, следующим образом: разложим $\ffi(x)$ по степеням $(x-x_i)$. Имеем $\ffi(x)=\ffi(x_i)+c_1(x-x_i)+\dots$. Домножая на $(x-x_i)^k$ получаем разложение по степеням $(x-x_i)$ интересующего нас многочлена. Но коэффициент при $(x-x_i)^k$ это как раз $\ffi(x_i)$. 

В частности, мы видим, что $\ffi(x_i)\neq 0$ и значит уравнение на $c$ разрешимо.

Осталось заметить, что на каждом шаге мы добавляем многочлен степени $k+\sum_{s=0}^{i-1} k_s$, что меньше или равно, чем требуемая степень.





\subsection{Интерполяция и остаток}

Интерполяционная задача пригождается при поиске остатка от деления одного многочлена на другой. А именно, представим себе, что мы хотим найти остаток от деления $r(x)$ многочлена $f(x)$ на $\ffi(x)=(x-x_1)\dots (x-x_n)$, где $x_i\neq x_j$ при $i\neq j$. 
Заметим, что и $r(x)$ и $f(x)$ принимают в указанных точках $x_i$ одинаковые значения. Так же, степень $r(x)< n=\deg \ffi(x)$. Но тогда $r(x)$ восстанавливается при помощи, например, формулы Лагранжа по значениям $r(x_i)=f(x_i)$.

Аналогично, если $\ffi(x)=(x-x_1)^{k_1}\dots (x-x_n)^{k_n}$, то $r(x)$ восстанавливается по $r^{(j)}(x_i)=f^{(j)}(x_i)$ для $i\in \ovl{1,n}$ и $0\leq j < k_i$.

\subsection{Разделение секрета по Шамиру}
Одним из применений понятие интерполяции находит в задаче разделения секрета. Задача состоит в следующем: пусть есть некий секрет $S$. В качестве $S$ можно взять число определённого размера. Есть $n$ участников, которые хотят получить некоторую информацию (для $i$-го участника некоторое число  $t_i$), так, что если соберутся любые $k$ из них, то по своим числам $t_i$ они смогут восстановить секрет $S$, но если соберутся $k-1$ из них, то они не смогут восстановить секрет.

Разделение секрета поручено некому доверенному лицу, которое не есть какой либо из участников. Как реализовать такое разделение доверенному лицу? Так как на число $S$ есть ограничение по размеру, то его можно считать элементом поля $\mb Z/p$ для достаточно большого простого $p$.

Для этого доверенное лицо сгенерирует случайным образом элементы $a_1,\dots,a_{k-1}$ и составит из них и секрета $S$ многочлен $f(x)=S+a_1x+
\dots+a_{k-1}x^{k-1}$. Затем, вычислим $t_i=f(i)$ при $i$ от $1$ до $n$. Для того, чтобы эта схема работала необходимо, чтобы $n<p$.

Осталось заметить, что собравшись вместе любые $k$ участников могут восстановить  $f(x)$
и, следовательно, секрет $S$ решив интерполяционную задачу. С другой стороны, никакие $k-1$ из них не смогут достоверно восстановить свободный коэффициент $f(x)$. Более того они не смогут получить вообще никакой информации про этот коэффициент, то есть про число $S$. Здесь безусловно важно, что в качестве узла интерполяции не берётся 0.


\section{Дискретное преобразование Фурье}

При произвольном выборе точек $x_i$ сложность задач интерполяции и подстановки $n$ при наших текущих знаниях есть $O(n^2)$. Однако, оказывается, что в определённых случаях можно подобрать такие $x_i$, что и задача интерполяции и задача о подстановке точек будут решаться заведомо быстрее.

Пусть есть некоторое поле $K$ и элемент $\omega \in K$. Рассмотрим упорядоченную $n$-ку $x=(a_0,\dots,a_{n-1})\in K^n$. Построим по ней многочлен $g(x)=a_0+\dots+a_{n-1}x^{n-1}$. Тогда определим $$F_{\omega}(x)=(g(1), g(\omega)\dots,g(\omega^{n-1}))\in K^n$$


Отображение $F_{\omega}\colon K^n \to K^n$ называется дискретным преобразованием Фурье. Если $\omega$ -- первообразный корень, то отображение $F_{\omega}$ обратимо, ведь нахождение прообраза равносильно решению задачи интерполяции для точек $x_i=\omega^i$, где $i\in \ovl{0,n-1}$. 

Пусть дан многочлен $g(x) \in K[x]$ степени меньше, чем $n$. Попробуем восстановить его свободный член $a_0$ по значениям $g(1),\dots,g(\omega^{n-1})$. Несколько экспериментов показывают, что 
$$a_0=\frac{1}{n}\left(g(1)+\dots+g(\omega^{n-1})\right).$$
Эта формула работает, если $n \in K^*$. Давайте её докажем. Для этого распишем правую часть
$$\frac{1}{n}\left(g(1)+\dots+g(\omega^{n-1})\right)=\frac{1}{n}\sum_{i=0}^{n-1} \sum_{k=0}^{n-1} a_k \omega^{ik}=\frac{1}{n}\sum_{k=0}^{n-1} a_k\sum_{i=0}^{n-1} \omega^{ik}$$

Коэффициент при $a_k$ равен $\frac{1}{n} \sum_{i=0}^{n-1}\omega^{ik}$. Таким образом, для  достаточно показать, что
\lm Пусть $\omega \in K$ -- первообразный корень степени $n$, то $$\sum_{i=0}^{n-1}\omega^{ik}=\begin{cases} n, k=0\\
0, k\neq 0
\end{cases}.$$
\elm
\proof Случай $k=0$ тривиален. Пусть теперь $k\neq 0$. Заметим, что в этом случае $1-\omega^{k}$ не $0$ и, следовательно, обратим в $K$. Так же получаем
$$\sum_{i=0}^{n-1}\omega^{ik}=\omega^{k}\sum_{i=0}^{n-1} \omega^{(i-1)k}=\omega^{k}\sum_{s=-1}^{n-2} \omega^{sk}=\omega^{k}\sum_{i=0}^{n-1} \omega^{ik}.$$
Для последнего перехода нужно заметить, что $\omega^{-1}=\omega^{n-1}$. Отсюда получаем, что 
$$0=(1-\omega^k)\sum_{i=0}^{n-1} \omega^{ik}.$$
Так как $1-\omega^k$ обратим, то  $$\sum_{i=0}^{n-1}\omega^{ki}=0.$$
\endproof

\upr На самом деле, если в поле $K$ есть первообразный корень степени $n$ из единицы, то $n \in K^*$ автоматически.
\eupr

Отвлечёмся немного и посмотрим, что нам даёт вычисление для $a_0$. Немного расширим его применимость. А именно, пусть $g(x)=a_0+\dots+ a_m x^m$. Чему тогда равно выражение $\frac{1}{n}\left(g(1)+\dots+g(\omega^{n-1})\right)$? Заметим, что $\omega^i$ -- это корни $x^n-1$. Следовательно, если многочлен $r(x)$ это остаток от деления $g(x)$ на $x^n-1$, то как обычно $g(\omega^i)=r(\omega^i)$ откуда мы сразу  получаем, что $\frac{1}{n}\left(g(1)+\dots+g(\omega^{n-1})\right)$ есть свободный член у $r(x)$. Но свободный член у $r(x)$ -- это $a_0+a_n+a_{2n}+\dots + a_{m-(n\mod m)}$. Для этого достаточно заметить, что при вычислении остатка от деления $g(x)$ на $x^n-1$ надо заменить все вхождения $x^n$ на $1$.

Как это может пригодиться? Рассмотрим, например, следующую комбинаторную задачу. Пусть дано множество $X=\{1,\dots,100\}$. Необходимо посчитать количество таких подмножеств $A\subseteq X$, что $\sum_{i\in A} i$ делится на, скажем, $5$. Почему эта задача вообще связана с многочленами? Для этого рассмотрим многочлен $$g(x)=(1+x)(1+x^2)\cdots(1+x^{100}).$$
коэффициент при $x^m$ в этом многочлене есть количество разбиений числа $m$ на слагаемые от $1$ до $100$, что тоже самое, что и число подмножеств $A \subseteq X$, что сумма элементов из $A$ в точности равна $m$. 

Таким образом, наша задача равносильна подсчёту суммы коэффициентов при $x^m$ у многочлена $g(x)$ по всем $m$, делящимся на 5.

Но мы уже знаем как искать такую сумму. Пусть $\omega=e^{\frac{2\pi i}{5}}$ -- первообразный корень степени $5$ из $1$ в $\mb C$. Тогда указанная сумма равна 
$$\frac{1}{5}\left(g(1)+\dots+g(\omega^4)\right).$$

Прежде всего заметим, что $g(1)=2^{100}$. Посчитаем $g(\omega)$. Заметим, что $$(1+1)(1+\omega)\dots(1+\omega^4)=(1+\omega)\dots(1+\omega^4)(1+\omega^5)=(1+\omega^l)\dots(1+\omega^{4+l})(1+\omega^{5+l}).$$
Отсюда $g(\omega)= ((1+1)(1+\omega)\dots(1+\omega^4))^{20}$. Заметим, что $x^5-1=(x-1)\dots(x-\omega^4)$. Подставляя $x=-1$ получаем, что 
$$-2=(-1)^5(1+1)(1+\omega)\dots(1+\omega^4).$$
Откуда $g(\omega)=2^{20}$. От элемента $\omega$ мы использовали только то, что $\omega^i$ при $0\leq i <5$ пробегает все корни $x^5-1$. Но таким же свойством обладают $\omega^2, \omega^3,\omega^4$. То есть $$g(\omega)=g(\omega^2)=g(\omega^3)=g(\omega^4)=2^{20}.$$
Получаем ответ 
$$\frac{1}{5}\left(g(1)+\dots+g(\omega^4)\right)=\frac{2^{100}+4\cdot 2^{20}}{5}.$$

Вернёмся назад к вычислению обратного отображения для преобразования Фурье.

\thrm[Вычисление обратного к преобразованию Фурье] Пусть $n\in \mb N$ некоторое натуральное число, а $\omega$ -- первообразный корень степени $n$ в поле $K$. Пусть так же $n \in K^*$. Тогда дискретное преобразование Фурье  $F_{\omega}$ обратимо и обратное к нему задаётся формулой $$(F_{\omega}^{-1})(b)_i=\frac{1}{n}\sum_{j=0}^{n-1} b_j \omega^{-ij}=\frac{1}{n} F_{\omega^{-1}}(b)_i.$$
\ethrm
\proof Достаточно доказать, что $F_{\omega^{-1}}(F_{\omega}(a))=a$. Для нулевой компоненты мы это знаем


\endproof

\subsection{Быстрое преобразование Фурье}

Перейдём теперь к алгоритму быстрого вычисления значений в указанных корнях из $1$. Этот алгоритм называется быстрым преобразованием Фурье.

\thrm[Быстрое преобразование Фурье] Пусть $n=2^k$ и $\omega \in K$ первообразный корень степени $n$ из 1-цы. Тогда дискретное преобразование Фурье можно провести за $O(n\log n)$ операций.
\ethrm
\proof  Будем считать, что вычисление $\omega^i$, по всем $0\leq i<n$ проделано заранее. Оно требует не более $n-2$ операций. Докажем индукцией по $n$, что для вычисления дискретного преобразования Фурье необходимо $\frac{3}{2} n\log n$ операций сложения и умножения без учёта операции домножения числа на $(-1)$, то есть операции взятия противоположенного. База при $n=1$ очевидна. Пусть дан многочлен $f(x)=a_0+a_1x+\dots+a_{n-1}x^{n-1}$. Сгруппируем все слагаемые с чётными степенями $x$  и отдельно с нечётными. Получим представление многочлена $f(x)$ в виде 
$$f(x)=r(x^2)+xs(x^2)$$
для некоторых многочленов $r(x), s(x)$, чья степень не превосходит $\frac{n}{2}$. Тогда, для того, чтобы посчитать $f(\omega^i)$ нужно посчитать $r(\omega^{2i})$ и $s(\omega^{2i})$. Это можно сделать используя преобразование Фурье относительно $\omega^2$. В свою очередь $\omega^2$ есть первообразный корень степени $\frac{n}{2}$ и для вычисления $F_{\omega^2}(r)$ и $F_{\omega^2}(s)$ необходимо $2\frac{3n}{4}(\log n -1)=\frac{3n}{2}(\log n -1)$ операций по индукционному предположению.

Чтобы вычислить $f(\omega^i)$  если $i<n/2$, то нужно сложить   $$F_{\omega^2}(r)_i+\omega^{i}F_{\omega^2}(s)_i,$$ либо, если $i\geq n/2$,  вычесть 
$$F_{\omega^2}(r)_{(i-n/2)}-\omega^{i-n/2}F_{\omega^2}(s)_{(i-n/2)}.$$
Здесь мы воспользовались тем, что $\omega^{n/2}=-1$ заменив $\omega^i$ на $-\omega^{i-n/2}$. 
Получаем $\frac{n}{2}$ умножений и $2\frac{n}{2}$ сложений не считая $\frac{n}{2}$ смен знака. Итого в сумме 
$$\frac{3n}{2}(\log n -1) +\frac{3}{2}n=\frac{3}{2}n\log n,$$
что и требовалось.
\endproof


Указанный в теореме алгоритм вычисления обладает одним недостатком: для вычисления ответа необходимо хранить все промежуточные вызовы $F_{\omega^{2^s}}$. Это неудобно. Можно было бы проанализировать указанный алгоритм и избавится от этой проблемы, однако проще (и полезнее) поменять точку зрения.



Вспомним, что если дан многочлен $f(x)$, то посчитать его значение в точке $a$ это тоже самое, что посчитать остаток от деления $f$ на $x-a$. Таким образом, нам нужно посчитать остатки от деления на $x-\omega^i$ по всем $0\leq i\leq n-1$. 
Далее заметим, что если мы хотим посчитать остаток $f \mod u(x)$ и $f \mod v(x)$, то можно сначала посчитать $r(x)=f\mod u(x)v(x)$, а потом уже посчитать $r(x) \mod u(x)$ и $r(x) \mod v(x)$.

Какое отношение это имеет к нашей ситуации? Многочлен $f(x)=a_0+\dots a_{n-1}x^{n-1}$ имеет степень не более $n-1$ и совпадает со своим остатком от деления на $x^n-1$. Многочлен $x^n-1=x^n-\omega^n=(x-1)(x-\omega)\dots(x-\omega^{n-1})$ раскладывается в виде произведения $x^{n/2}-\omega^{n/2}$ и $x^{n/2}+\omega^{n/2}=x^{n/2}-1=x^{n/2}-\omega^0$. Половина корней $x^n-1$ является корнями первого множителя, половина -- корнями второго. Оба множителя можно разложить и дальше.
Точнее $$x^{2^{k-s}}-\omega^{j2^{k-s}}=(x^{2^{k-(s+1)}}-\omega^{j2^{k-(s+1)}})(x^{2^{k-(s+1)}}-\omega^{j2^{k-(s+1)}+\frac{n}{2}})  \text{ для всех } 0\leq j< 2^s.$$ 

Мы хотим вычислить остатки от деления на $x-\omega^j=x^{2^{k-s}}-\omega^{j2^{k-s}}$ при  $s=k$.

На шаге $0$ мы знаем остаток от деления $f(x)$ на $x^n-1=x^{2^k}-\omega^{2^k}$. Пусть на шаге $s$ мы знаем остаток от деления $f(x)$  на $x^{2^{k-s}}-\omega^{j2^{k-s}}$ для всех $0\leq j< 2^s$. Если на шаге $s$ мы сможем найти все остатки от деления $f(x)$ на  $x^{2^{k-(s+1)}}-\omega^{j2^{k-(s+1)}}$ по всем $0\leq j< 2^{s+1}$, то на шаге $s=k-1$ мы вычислим $f(\omega^j)$ по всем $0\leq j <2^k$, что, собственно, и нужно.

Посмотрим, что происходит на шаге $s$. Чтобы найти остаток от деления $f(x)$ на $x^{2^{k-(s+1)}}-\omega^{j2^{k-(s+1)}}$ надо взять остаток от деления  $f(x)$ на $x^{2^{k-s}}-\omega^{j2^{k-s}}$ и поделить его на $x^{2^{k-(s+1)}}-\omega^{j2^{k-(s+1)}}$. Таким образом, если на шаге $s$ необходимо будет поделить $2^s$ многочленов степени меньше $2^{k-s}$ на $2^{s+1}$ многочленов степени $2^{k-(s+1)}$ специального вида. Чтобы понять, что это можно легко сделать сформулируем лемму.

\lm Пусть $n$ -- чётное натуральное число, а $f(x)=\sum_{i=0}^{n-1} a_ix^i$ многочлен из $K[x]$. Тогда остаток от деления многочлена $f(x)$ на $x^{n/2}-c$ находится по формуле
$$r(x)=\sum_{i=0}^{n/2-1}(a_i+ca_{i+n/2})x^{i}. $$
\elm
\proof При вычислении остатка по модулю $x^{n/2}-c$ достаточно заменить все вхождения $x^{n/2}$ в многочлен $f(x)$ на $c$. Откуда и получаем эту формулу.
\endproof

Отсюда видно, что для вычисления указанного остатка необходимо $\frac{n}{2}$ умножений и $\frac{n}{2}$ сложений. Причём, если параллельно считать остаток от деления на $x^{n/2}+c$, то можно сэкономить $\frac{n}{2}$ умножений, заменив их на домножение на $-1$ (то есть на взятие противоположенного). Таким образом,  для вычисления дискретного преобразования Фурье указанным способом необходимо как и раньше
$$\frac{3}{2}\left(n+2\frac{n}{2}+4\frac{n}{4}+\dots+2^k\frac{n}{2^k}\right)=\frac{3}{2}nk=\frac{3}{2}n\log n$$
умножений и сложений  в $K$ не считая домножений на $-1$.

Для чего применяется быстрое преобразование Фурье? Самое базовое применение -- это быстрое произведение многочленов. А именно, пусть в поле $K$ есть $\omega$ -- первообразный корень степени $2n=2^{k+1}$ из единицы и $n \in K^*$. Пусть даны два многочлена $f,g$, что $\deg f, \deg g <n$. Тогда и $f$ и $g$  и их произведение $f\cdot g$ восстанавливаются по их значениям в точках $\omega^i$. Но если мы знаем $f(\omega^i)$ и $g(\omega^i)$, то мы знаем $fg(\omega^i)=f(\omega^i)g(\omega^i)$.

То есть посчитать произведение $fg$ можно следующим образом $$fg= \frac{1}{2n}F_{\omega^{-1}}\left(F_{\omega}(f)\cdot F_{\omega}(g)\right).$$
Здесь точкой обозначено поточечное произведение в $K^n$. Это выражение можно вычислить за $O(n\log n)$ операций в $K$, что заметно меньше наивных $O(n^2)$.

Осталось ещё несколько вопросов, касательно преобразования Фурье. 

\enm 
\item Что происходит, когда мы считаем произведение многочленов по указанной формуле, но их степени могут быть больше $n$?
\item А что если характеристика поля равна 2?
\item Как обстоят дела с преобразованием Фурье в других кольцах?
\item Для чего ещё можно использовать быстрое преобразование Фурье?
\eenm

Ответ на первый вопрос мы уже знаем -- отображение $F_{\omega}^{-1}$ восстанавливает многочлен по его значениям в корнях из единицы, то есть решает задачу интерполяции. Если степень исходного многочлена больше  или равна числа точек, то восстанавливается лишь его остаток при делении на $(x-x_1)\dots(x-x_n)$. В нашем конкретном случае получаем, что если $\deg f+\deg g \geq n$, то $\frac{1}{n}F_{\omega^{-1}}\left(F_{\omega}(f)\cdot F_{\omega}(g)\right)$ есть остаток от деления $fg$ на $x^n-1$.  


Если характеристика поля равна $2$, то можно использовать корни степени $3^k$ из единицы, если они есть. Существуют, впрочем, и другие приёмы по этому поводу.


Поговорим немного про теорию для колец. Начнём с того, что определение первообразного корня степени $n$ в этом контексте придётся поменять.



\dfn Элемент  $\omega \in R$ называется первообразным корнем  степени $n$ из единицы, если $\omega$ -- корень степени $n$ из $1$-цы и $1-\omega^i$ не делитель нуля при $1\leq i< n$.
\edfn

\rm Если $\omega \in R$ -- первообразный корень степени $n$ из единицы  и $0\leq k < n$, то 
$$\sum_{i=0}^{n-1}\omega^{ik}=\begin{cases} n, k=0\\
0, k\neq 0
\end{cases}.$$
В большинстве источников именно это условие на суммы служит определением для первообразного корня. Однако, легко показать, что эти определения, фактически, совпадают.
\erm

\upr Покажите, что если $n \in R^*$, то если для любого  $0\leq k < n$ выполнено
$$\sum_{i=0}^{n-1}\omega^{ik}=\begin{cases} n, k=0\\
0, k\neq 0
\end{cases},$$
то $\omega$ -- первообразный корень степени $n$ из единицы в $R$.
\eupr

\rm Пусть $\omega \in R$ -- первообразный корень степени $n$. Тогда\\
1) $\omega^{-1}$ тоже первообразный корень степени $n$ из $1$.\\
2) если $n=pq$, то $\omega^q$ -- это первообразный корень степени $p$ из единицы в $R$.\\
3) В частности, для чётного $n$, $\omega^{\frac{n}{2}}=-1$. Действительно $0=\omega^n-1=(\omega^{\frac{n}{2}}-1)(\omega^{\frac{n}{2}}+1)$. Осталось заметить, что по условию $(\omega^{\frac{n}{2}}-1)$ не делитель нуля.
\erm

Понятно, что бывают кольца, например $\mb Z$, в которых нет первообразных корней большой степени. Однако в случае $\mb Z$ быстрое умножение многочленов всё равно возможно. Основным инструментом для этого служит переход к достаточно большому модулю $m$ для которого есть первообразные корни степени $2^l$ для большого $l$.

Точнее, если мы хотим умножить два многочлена $f,g\in \mb Z[x]$ степени $n$, и коэффициенты $f$ и $g$ оцениваются по модулю числом $N$, то коэффициенты произведения оцениваются как $nN^2$. Если мы выберем теперь модуль $m >2nN^2$, то зная произведение $fg \mod m$ мы восстановим само произведение $fg \in \mb Z[x]$. 

Осталось только понять, как найти модуль $m$, что в кольце $\mb Z/m$ есть первообразные корни степени $2^l$.


\utv Пусть $m=2^{2^s}+1$. Тогда $2$ является первообразным корнем степени $2^{s+1}$ из единицы в кольце $\mb Z/m$. 
\eutv
\proof Предположим противное. Рассмотрим наименьшее $k<2^{s+1}$, что $2^k-1$ делитель нуля в $\mb Z/m$. Это значит, что $(2^k-1,m)\neq 1$. В частности, у $2^k-1$ и $m$ есть общий простой делитель $p$. Тогда $2^k\equiv 1 \mod p$. С другой стороны, по модулю $m$ выполнено сравнение $2^{2^s}\equiv -1 \mod m$. Значит, оно же верно по модулю $p$. Из этого следует, что $2^{2^{s+1}}\equiv 1 \mod p$.

Воспользуемся теоретико-групповой леммой. Получим, что $2^d\equiv 1$, где $d=(2^{s+1},k)$. Отсюда из минимальности $k$ получаем, что $k=2^l$ для некоторого $l\leq s$. Но если $2^{2^l} \equiv 1 \mod p$, то возведя несколько раз в квадрат получим $2^{2^s}\equiv 1 \mod p$, что противоречит сравнению $2^{2^s}\equiv -1\mod p$.   
\endproof

Что же можно сказать про другие применения быстрого преобразования Фурье? Одним из наиболее интересных сюжетов здесь является быстрое умножение целых чисел. Идея такова: представим целые  числа  $a,b$ в записи по основанию $t$, то есть $a=a_0+a_1t+\dots+a_lt^l$ и аналогично $b$. Это означает, что $a$ и $b$ есть значения некоторых многочленов $f,g$ в точке $t$. Мы хотим посчитать значение  произведения $fg$ этих многочленов в точке $t$. Посчитаем сначала произведение. Это мы умеем делать быстро при помощи быстрого преобразования Фурье вычисленного по модулю $m=2^{2^s}+1$. 

К сожалению, в таком наивном виде алгоритм не работает. Нужно сильно конкретизировать как выбирать $t$ и как считать значение $fg(t)$. Для этого $t$ обычно тоже берут степенью двойки.

Так или иначе, но Шёнхаге и Штрассену в 1971 году удалось построить на этой основе практически применимый алгоритм умножения чисел со сложностью $O(n\log n \log\log n)$. Доказательства смотри \cite[стр. 270]{AHU}.


Недавно в марте 2019 года был анонсирован, а в 2021 -- опубликован в Annals of Mathematics алгоритм умножения, работающий за $O(n\log n)$ \href{https://hal.archives-ouvertes.fr/hal-02070778/document}{David Harvey, Joris Van Der Hoeven. Integer multiplication in time $O(n \log n)$.}




\section{Поле частных}

Мы уже замечали с вами, что некоторые утверждения про многочлены с целыми коэффициентами удобно получать, рассматривая их как многочлены с рациональными коэффициентами и пользоваться тем, что $\mb Q$ -- поле. Наша задача смоделировать аналогичную ситуацию для любой области целостности.

\dfn[Поле частных] Пусть  $R$ -- область целостности. Определим кольцо $Q(R)$ как
фактор множества пар
$$ Q(R)=\{ (a,u)\,|\, a\in R, \, u\in R\setminus\{0\} \,\}/\sim$$
по отношению эквивалентности $\sim$, заданного правилом
$$ (a,u)\sim (b,v), \text{ если } av=bu.$$
Класс элемента $(a,u)$ будем обозначать  $\frac{a}{u}$ и называть дробью.
Операции сложения и умножения введём подобно рациональным числам:
$$ \tfrac{a}{u}+\tfrac{b}{v}=\tfrac{av+bu}{uv} \text{ и } \tfrac{a}{u}\cdot\tfrac{b}{v}=\tfrac{ab}{uv}.$$
\edfn




\thrm[Конструкция работает] Пусть  $R$ -- область целостности. Тогда  кольцо $Q(R)$ корректно определено и является полем.
\ethrm
\proof
Прежде всего составим план того, что необходимо проверить:
\enm
\item Отношение $\sim$ действительно отношение эквивалентности
\item Операции сложения и умножения определены корректно
\item Выполнены все свойства сложения
\item Выполнена дистрибутивность
\item Выполнены все свойства умножения
\eenm
Обсудим подробно только некоторые из этих пунктов. Например, проверим транзитивность указанного отношения. Пусть $av=bu$ и $bw=cv$. Тогда $avbw=cvbu$. Сократим на $vb$. Это возможно так как $vb \neq 0$ в $R$ и $R$ -- область целостности.

Заметим, что дроби $\frac{a}{u}$ и $\frac{sa}{su}$ равны (при $s\neq 0$).
Теперь перейдём к корректности операций. Рассмотрим сумму. Пусть $\tfrac{a}{u}\sim \tfrac{a'}{u'}$, а  $\tfrac{b}{v}=\tfrac{b'}{v'}$. Тогда сумма
$$\tfrac{a'v'+b'u'}{u'v'}\sim \tfrac{uva'v'+uvb'u'}{uvu'v'}= \tfrac{au'vv'+bv'u'u}{uvu'v'}\sim \tfrac{av+bu}{uv}.$$

Из оставшихся свойств отметим лишь, что нулевой элемент -- это дробь $\frac{0}{1}$, противоположенная дробь к дроби $\frac{a}{u}$ это $\frac{-a}{u}=\frac{a}{-u}$, единица -- это $\frac{1}{1}$, а $\left(\frac{a}{u}\right)^{-1}=\frac{u}{a}$. Разумеется, если $a\neq 0$.
\endproof

\thrm[Область целостности вкладывается в своё поле частных] Пусть  $R$ -- область целостности. Отображение $i\colon R\to Q(R)$ заданное по правилу $a\to \tfrac{a}{1}$ является инъективным гомоморфизмом колец.
\ethrm
\proof Проверим инъективность. Покажем, что ядро нулевое. Пусть $\tfrac{a}{1}= \tfrac{0}{1}$. Тогда $1\cdot a=0\cdot 1$. Но это значит, что $a=0$. 
Тот факт, что указанное отображение -- гомоморфизм колец, оставляется в качестве легкого упражнения. 

\thrm[Универсальное свойство] Пусть $R$ -- область целостности и $f\colon R \to S$ -- гомоморфизм колец, такой, что для любого $a\in R$, $a\neq 0$, то $f(a)\in S^*$. Тогда Существует и единственный гомоморфизм колец $\hat{f} \colon Q(R)\to S$, такой что $f=\hat{f}\circ i_R$. Здесь $i_R$ это описанное вложение $R$ в $Q(R)$. Фактически мы требуем, чтобы $f(a)=\hat{f}(a)$ для всех $a\in R$. 
\ethrm
\proof Как всегда начнём с единственности. Вместо дроби $\tfrac{a}{1}$ буду писать просто $a$. Рассмотрим дробь $\tfrac{a}{u}=au^{-1}$. Тогда $\hat{f}(au^{-1})=\hat{f}(a)\hat{f}(u)^{-1}=f(a)f(u)^{-1}$. Значит вариантов нет.

Теперь надо показать, что отображение, заданное правилом
$$\hat{f}(\tfrac{a}{u})=f(a)f(u)^{-1}$$
корректно задано и является гомоморфизмом. Проверка прямолинейна.
\endproof


\endproof

Таким образом, можно считать, что любая область целостности лежит в некотором поле. Это позволяет сводить некоторые утверждения про области целостности к аналогичным утверждениям про поля.


\crl У многочлена $f$ в области целостности не более чем $\deg f$ различных корней с учётом кратности.
\ecrl
\proof Пусть корни $f$ в $R$ это $x_0,\dots,x_k$ и их кратности это $\alpha_0,\dots,\alpha_k$.  Очевидно, что если $f\di (x-x_i)^{\alpha_i}$ в $R[x]$, то $f\di (x-x_i)^{\alpha_i}$ в $Q(R)[x]$. Но тогда сумма кратностей корней $f$ в $R$ не превосходит суммы кратностей этих корней в $Q(R)$, которая, в свою  очередь, меньше или равна $\deg f $.
\endproof

Посмотрим на эту конструкцию в некоторых конкретных ситуациях.
\enm
\item Поле частных $Q(\mb Z)$ это $\mb Q$. 
\item Поле частных $Q(K[[x]])$, где $K$ -- поле, обозначается как $K((x))$ и называется полем рядов Лорана с коэффициентами из $K$.
\item Поле частных $Q(K[x_1,\dots,x_n])$, где $K$ -- поле, обозначается как $K(x_1,\dots,x_n)$ и называется полем дробно-рациональных функций от $n$ переменных над полем $K$.  
\eenm

Поговорим подробнее про $K((x))$. Имеет место следующее описание:
\utv Пусть $K$ -- поле и дан элемент $f(x)\in K((x))$. Тогда существует единственное представление $f(x)$ в виде $f(x)=c_{-k}x^{-k}+\dots+ c_{-1}x^{-1}+c_0+c_1x+\dots$. Здесь первые $k$ слагаемых это дроби вида $\frac{c}{x^i}$, а оставшееся, начиная с $c_0$, задают ряд из $K[[x]]$. 
\eutv 
\proof Пусть $f(x)=\frac{h(x)}{g(x)}$, где $g(x)$ делится на наименьшую возможную степень $x$. Представим  $g(x)$ в виде $x^k u(x)$, где $u(x)$ обратим. Тогда имеет место равенство 
$$\frac{h(x)}{g(x)}=\frac{h(x)u^{-1}(x)}{x^k}.$$
Представим числитель в виде ряда, начав нумерацию слагаемых с $-k$. Получаем 
$h(x)u^{-1}(x)=c_{-k}+c_{-k+1}+\dots + c_0 +\dots $. В таких обозначениях дробь $\frac{h}{g}$ как раз имеет нужный вид.

Покажем единственность такого представления. Пусть есть два представления для одной и той же дроби. Прежде всего будем считать, что отрицательные индексы и в том и в другом начинаются с номера $-k$. Имеем $$a_{-k}x^{-k}+\dots+a_0+\dots=b_{-k}x^{-k}+\dots +b_0 +\dots.$$
Домножим на $x^k$. Получим равенство рядов. Но ряды равны тогда и только тогда, когда их коэффициенты равны. Единственность доказана. 
\endproof

\rm Собственно рядом Лорана обычно называют выражение вида $$a_{-k}x^{-k}+\dots+a_0+a_1x+a_2x^2+\dots+a_n x^n +\dots$$
то есть сумму степеней $x$, где количество слагаемых с отрицательными степенями конечно.
\erm

Благодаря универсальному свойству имеем, что имеет место вложение $K(x) \hookrightarrow K((x))$. А именно имеет место вложение $K[x]\to K[[x]]\to K((x))$. Но при таком вложении любой многочлен $f(x)\neq 0$ обратим, как элемент $K((x))$. Это и даёт возможность воспользоваться универсальным свойством.




\section{Дробно-рациональные функции}


Поговорим о специальных свойствах поля $K(x)$. Это поле в целом напоминает поле рациональных чисел, так как является полем частных евклидового кольца.

\lm Пусть $\frac{f}{g} \in K[x]$. Тогда существуют  единственные многочлены  $u,v$, где старший коэффициент $v$ равен единице, что $\Nod(u,v)=1$ и $\frac{f}{g}=\frac{u}{v}$. 
\elm
\proof Возьмём какие-то $f,g$ и рассмотрим $d=\Nod(f,g)$. Тогда $u=c^{-1}\frac{f}{d}$, а $v=c^{-1}\frac{g}{d}$ подходят, где $c$ -- это старший коэффициент $\frac{g}{d}$. Пусть есть две пары $u,v$ и $u_1,v_1$ подходящие по условию. Тогда $uv_1=vu_1$. Так как $u$ и $v$ взаимно просты выполнено $v\di v_1$. Симметрично $v_1\di v$. Тогда $v=cv_1$. Но их старшие коэффициенты равны 1. Отсюда $c=1$ и $u=u_1$.
\endproof

\dfn Если многочлены $u,v$ таковы, что $(u,v)=1$, то запись $\frac{u}{v}$ согласимся называть несократимой дробью.
\edfn

\dfn Дробь $\frac{f}{g} \in K(x)$ называется правильной, если $\deg f< \deg g$.
\edfn

\rm Это определение не зависит от представления дроби в виде отношения двух многочленов.
\erm

\lm Любая дробь $\frac{f}{g}\neq 0$ единственным образом представляется в виде суммы многочлена $h(x)\in K[x]$ и правильной дроби $\frac{r}{g_1}$. Если обе дроби  $\frac{f}{g}$ и $\frac{r}{g_1}$ несократимы и старший коэффициент $g$ и $g_1$ равен 1, то $g_1=g$.
\proof Покажем существование. Можем считать дробь $\frac{f}{g}$ несократимой и старший коэффициент $g$ равным 1. Поделим с остатком $f(x)=h(x)g(x)+r(x)$, где $\deg r(x)<\deg g(x)$. Тогда
$$\frac{f(x)}{g(x)} =\frac{h(x)g(x)+r(x)}{g(x)} =h(x)+\frac{r(x)}{g(x)}.$$
Кроме того, заметим, что дробь $\frac{r(x)}{g(x)}$ так же несократимая.
Покажем единственность. Пусть
$$h_1(x)+\frac{r_1}{g_1}=h_2(x)+\frac{r_2}{g_2}.$$
Имеем равенство многочленов.
$$(h_1(x)-h_2(x))g_1(x)g_2(x)=g_1(x)r_2(x)-r_1(x)g_2(x).$$
Если $h_1\neq h_2$, то степень многочленов справа строго меньше степени многочлена слева. Таким образом, $h_1=h_2$, а значит $\frac{r_1}{g_1}=\frac{r_2}{g_2}$. Возьмём теперь в качестве $h_2=h$, $r_2=r$ и $g_2=g$ из доказательства существования. Предположим так же, что $\frac{r_1}{g_1}$ несократима и старший коэффициент $g_1$ равен 1. Тогда по единственности $\frac{r}{g}=\frac{r_1}{g_1}$. Осталось  применить единственность представления в виде несократимой записи и получить, что $g=g_1$.
\endproof
\elm

\rm Сумма двух правильных дробей -- снова правильная дробь. Произведение двух правильных дробей -- тоже правильная дробь. Таким образом, правильные дроби образуют подкольцо (без единицы!) в $K(x)$. Впрочем, единицу можно добавить, разрешив константы.
\erm

\dfn[Простейшие дроби] Пусть $K$ --- поле, $p\in K[x]$ --- неприводимый многочлен со страшим коэффициентом единица. Тогда дробь
$$\frac{f(x)}{p(x)^{k}} \text{ называется простейшей, если $f \neq 0$ и $\deg f < \deg p$}. $$
\edfn

\lm[О разложении по основанию] Пусть даны два многочлена $f(x)\in K[x]$ и $p(x)\in K[x]$, причём $\deg p(x)\geq 1$. Рассмотрим такое $s$, что $s\deg p < \deg f < (s+1)\deg p$. Тогда существуют единственные $a_i(x)\in K[x]$ $0\leq i\leq s$, что 
$$\deg a_i(x) < \deg p(x) \text{ и } f(x)=\sum_{i=0}^sa_i p^i(x).$$
\elm
\proof Докажем существование и единственность индукцией по степени $f(x)$. При $\deg f < \deg p$ возьмём $a_0(x)=f(x)$. Пусть теперь степень $f(x)$ произвольная.  Поделим $f(x)$ на $p(x)$ с остатком $$f(x)=p(x)q(x)+a_0(x).$$
Заметим, что  $\deg q(x) = \deg f(x)-\deg p(x) <  \deg f(x)$. Применим индукционное предположение для $q(x)$. $$q(x)=a_1+a_2p+\dots+a_s p^{s-1}.$$
Подставляя, получим представление для $f(x)$. 
Так же по индукции доказывается, что такое представление единственно: $a_0$ восстанавливается как остаток $f(x) \mod p(x)$, $a_1$ -- как остаток $\frac{f(x)-a_0}{p(x)} \mod p$ и так далее.
\endproof

\crl Несократимая дробь вида $\frac{r(x)}{p(x)^{\alpha}}$ единственным образом может быть представлена в виде суммы простейших
$$\frac{r(x)}{p(x)^{\alpha}}= \sum_{j=1}^{\alpha} \frac{r_j(x)}{p^j(x)},$$
где $r_s \neq 0$.
\proof Для выполнения указанных условий необходимо  и достаточно, чтобы $r(x)=\sum_{j=1}^{\alpha} r_j p(x)^{\alpha-j} $, и $\deg r_i < \deg p(x)$. 
\endproof
\ecrl


\lm[О разложении в сумму правильных дробей со взаимно простыми знаменателями] Пусть $\frac{f}{g} \in K(x)$ -- правильная дробь и многочлен $g(x)\in K[x]$ раскладывается на взаимно простые множители $g=g_1g_2$, где $(g_1,g_2)=1$. Тогда существуют единственные $h_1,h_2 \in K[x]$, что $$\frac{f}{g}=\frac{h_1}{g_1}+\frac{h_2}{g_2},$$
что дроби $\frac{h_1}{g_1}$ и $\frac{h_2}{g_2}$ -- правильные.
\elm
\proof Равенство
$ \frac{f}{g}=\frac{h_1}{g_1}+\frac{h_2}{g_2}$
имеет место тогда и только тогда, когда $h_1$ и $h_2$ являются решениями линейного уравнения $$h_2g_1+h_1g_2=f.$$
Так как $(g_1,g_2)=1$, то решение такого уравнения существует и, более того, если есть второе решение $\hat{h_1}, \hat{h_2}$, то $\hat{h_1}\equiv h_1\mod g_1$ и $\hat{h_2}\equiv h_2 \mod g_2$. В частности, существует и единственно решение $h_1, h_2$, где $\deg h_1 < \deg g_1$. Рассмотрим такое $h_1$. Ему однозначно соответствует $h_2$, такое что $g_1h_2= f- g_2h_1$. Заметим, что степень правой части строго меньше  $\deg g_1+ \deg g_2$. Отсюда следует, что степень $h_2$ меньше $\deg g_2$. Существование и единственность доказаны.
\endproof


\thrm[О разложении на простейшие] Пусть $K$ ---  поле. Тогда для любой несократимой дроби $0
\neq \frac{f}{g} \in K(x)$ существуют единственные многочлен $h\in K[x]$, неприводимые многочлены $p_1, \dots, p_n$ со старшим коэффициентом 1, натуральные числа $\alpha_1,\dots, \alpha_n$ и многочлены $r_{ij}$, где $i\in \ovl{1,n}$, и $j\in \ovl{0,\alpha_i}$, что дроби
$$ \frac{r_{ij}}{p_i^{j}} \text{ --- простейшие и } \frac{f}{g}=h+\sum_{i,j} \frac{r_{ij}}{p_i^{j}}.$$
При этом, если  $r_{i\alpha_i}$ не ноль и старший коэффициент $g$  равен 1, то $g=\prod p_i^{\alpha_i}$.
\ethrm

\proof Покажем существование разложения. Будем предполагать, что дробь $\frac{f}{g}$ несократима и старший коэффициент $g$ равен 1. По лемме о разложении дроби в виде суммы многочлена и правильной дроби представим $$\frac{f(x)}{g(x)}= h(x)+\frac{r(x)}{g(x)}$$
Переходя от $\frac{f}{g}$ к $\frac{r}{g}$, можно считать, что изначально дана правильная дробь.
В таком предположении будем доказывать существование разложения по индукции. Если $g=p^{\alpha}$, то разложение правильной дроби $\frac{f}{g}$ получается благодаря следствию из леммы о разложении по основанию.


Это отличная база для индукции по степени многочлена $g(x)$  (или по числу его различных неприводимых делителей). Для того чтобы показать шаг индукции докажем лемму



Перейдём к доказательству теоремы. Разложим $g(x)$ в виде $g(x)=p_1^{\alpha_1}\dots p_k^{\alpha_k}$. Множители $p_1^{\alpha_1}$ и $\prod_{i\geq 2}p_i^{\alpha_i}$ взаимно простые. Тогда по лемме существует единственное разложение в сумму правильных дробей $$\frac{f}{g}=  \frac{h_1}{p_1^{\alpha_1}}+\frac{h_2}{\prod_{i\geq 2}p_i^{\alpha_i}}.$$

Каждое из слагаемых раскладывается на простейшие благодаря индукционному предположению.\\

\proof[Единственность] Пусть $\frac{f}{g}$ -- несократимая дробь и старший коэффициент $g$ равен 1. Такое представление единственно для любой дроби. Пусть
$$\frac{f}{g}=h+\sum_{i,j} \frac{r_{ij}}{p_i^{j}},$$
где $r_{i\alpha_i}$ не ноль. Прежде всего заметим, что $$\sum_{i,j} \frac{r_{ij}}{p_i^{j}}$$
правильная дробь. Тогда $h$ определяется однозначно из единственности представления дроби в виде суммы многочлена и правильной дроби. Заменяя $\frac{f}{g}$ на $\frac{f}{g}-h$ можем считать, что дробь $\frac{f}{g}$ правильная. Теперь  покажем, что  $g=\prod p_i^{\alpha_i}$. Введём обозначение $$r_i= \sum_{j=1}^{\alpha_i} r_{ij} p_i^{\alpha_i-j}.$$
Приведя разложение на простейшие для $\frac{f}{g}$ к общему знаменателю  получим дробь 
$$\sum_{i,j} \frac{r_{ij}}{p_i^{j}}= \frac{\sum_{i} r_{i}\prod_{k\neq i} p_k^{\alpha_{k}}}{\prod p_i^{\alpha_{i}}}.$$
Покажем, что эта дробь несократима. Выберем некоторый неприводимый множитель знаменателя $p_l$ и покажем, что числитель не делится на $p_l$. Слагаемые вида $$r_i \prod_{k\neq i} p_k^{\alpha_{k}}$$ делятся на $p_l$, если $l \neq i$. С другой стороны, $r_l$ не делится на $p_l$, так как $r_{l\alpha_l}$ не делится (потому что он не ноль и степени меньше $\deg p_l$). Тогда и вся сумма не делится на $p_l$.
Но это значит, что $\prod p_i^{\alpha_i}=g$ из единственности несократимой записи для дроби. Таким образом,мы показали единственность $p_i$  и $\alpha_i$. Покажем единственность $r_i$. Имеем представление $$\frac{f}{g}=\frac{r_1}{p_1^{\alpha_1}}+\sum_{i\geq 2} \frac{r_i}{p_i^{\alpha_i}}$$
Первое слагаемое есть правильная дробь со знаменателем $p_1^{\alpha_1}$. Второе слагаемое есть правильная дробь со знаменателем $\prod_{i\geq 2}p_i^{\alpha_i}$. По единственности из леммы о разложении в сумму двух дробей со взаимно простыми знаменателями получаем единственность $r_1$. Переставляя слагаемые получаем единственность для всех $r_i$. Но по лемме о разложении по основанию $r_{ij}$ однозначно восстанавливаются по $r_i$, что и завершает доказательство.
\endproof

\zd Какой аналог у последней теоремы в рациональных числах?
\ezd

Рассмотрим теперь конкретные поля. Так как поле $\mb C$ алгебраически замкнуто, то все неприводимые многочлены над $\mb C$ имеют степень 1. Это заметно упрощает жизнь, так как в числителе простейшей дроби могут стоять только константы.

\crl Для любой дроби $\frac{f}{g}\in \mb C(x)$ существует представление в виде $h(x)+\sum_{i=1}^k\sum_{j=1}^{\alpha_i}\frac{A_{ij}}{(x-x_i)^j}$, где $h(x)\in \mb C[x]$, $A_{ij}\in \mb C$, а $x_i$ -- корни $g(x)$ кратности $\alpha_i$.
\ecrl 

\upr Сформулируйте аналогичное следствие для $\mb R$.
\eupr

Самый стандартный, но далеко не самый эффективный способ нахождения разложения на простейшие -- метод неопределённых коэффициентов. Приведём пример нахождения некоторого разложения, которое использует конструкцию интерполяции. Рассмотрим рациональную функцию $$\frac{1}{x^n-1}.$$
Хочется найти её разложение на простейшие в $\mb C$. Корни  многочлена $x^n-1$ нам известны. Это $$\eps_l=e^{\tfrac{2i \pi l}{n}},\,\,\,l\in \ovl{0,n-1}.$$ Многочлен $g(x)=1$ восстанавливается по своим значениям в точках  $\eps_l$ по формуле Лагранжа
$$1=\sum_{l=0}^{n-1} \frac{ x^n-1}{n\eps_l^{n-1}(x-\eps_l)}.$$
Роль функции $\ffi(x)$ здесь играет $x^n-1$. Тогда
$$\frac{1}{x^n-1}=\frac{\sum_{l=0}^{n-1} \frac{ x^n-1}{n\eps_l^{n-1}(x-\eps_l)}}{x^n-1}= \sum_{l=0}^{n-1} \frac{\eps_l}{n(x-\eps_l)}.$$



\section{Дополнительно. Степенные ряды как производящие функции}


\dfn[Линейное рекуррентное соотношение] Будем говорить, что последовательность $x_n$ удовлетворяет линейному рекуррентному соотношению $k$-го порядка, если существуют числа $a_0,\dots,a_{k}$, что $a_k,a_0\neq 0$ и
$$a_k x_{n+k}+a_{k-1}x_{n+k-1}+\dots+a_0x_n=0$$
\edfn


\rm Вообще говоря, ничто не мешает считать, что начальные коэффициенты $a_0,\dots,a_s=0$. Просто это означает, что до номера $k+s$ последовательность может быть любой, а после $k+s$ начинает удовлетворять соотношению с коэффициентами $a_{s+1},\dots,a_k$.
\erm

\dfn[Производящая функция] Пусть дана последовательность $a_n$, $n\geq 0$. Производящей функцией для последовательности $a_n$ назовём формальный степенной ряд $f(x)=\sum_{i=0}^{\infty} a_ix^i$.
\edfn



\thrm Ряд из $K[[x]]$ является рядом некоторой правильной дроби $\frac{f(x)}{g(x)}$, тогда и только тогда, когда его коэффициенты  удовлетворяют линейному рекуррентному соотношению. Более того, порядок наименьшего линейного рекуррентного соотношения, которому удовлетворяют коэффициенты, равен степени знаменателя в несократимой дроби.
\ethrm

\proof
Заметим, что, ряд Лорана  несократимой дроби $\frac{f}{g}$ лежит в $K[[x]]$ тогда и только тогда, когда $g(x)\ndi x$. Если $g(x)\ndi x$, то $g(x)$ обратима в $K[[x]]$, откуда и вся дробь лежит в $K[[x]]$. Обратно, если $g \di x$, и $\frac{f}{g}$ лежит в $K[[x]]$, то $f\ndi x$ и тогда $f$   обратимо в $K[[x]]$ откуда $g(x)^{-1} \in K[[x]]$, что не возможно, потому что свободный член $g$ равен 0.

Пусть $q(x)$ есть ряд правильной несократимой дроби $\frac{f(x)}{g(x)}$. Тогда $q(x)$ удовлетворяет соотношению $g(x)q(x)=f(x)$. Мы уже один раз выписывали соотношение на коэффициенты $g(x)$, когда $f(x)$ был равен 1. Поступим аналогично. Пусть $g(x)=b_nx^n+\dots +b_0$, $f(x)=a_mx^m+\dots +a_0$, а $q(x)=c_0+c_1x+\dots$. Тогда имеем уравнения на коэффициенты $q(x)$

$$ \sum_{j=0}^{n} b_j c_{i-j} =a_i .$$
Выражение справа равно 0 при $i>m$. Выражение слева при $i\geq n$ всегда имеет $n$ слагаемых. Функция $g(x)$ не может делиться на $x$ так как иначе мы не получили бы элемент из $K[[x]]$ или дробь была бы сократима. Тогда $b_0\neq 0$. Таким образом, при $i\geq n$ получаем рекуррентное соотношение на $c_j$

$$ b_0 c_{j+n}+b_1 c_{j+n-1}+\dots + b_n c_j=0.$$
Обратно, пусть $c_j$ удовлетворяют рекуррентному соотношению
$$ b_0 c_{j+n}+b_1 c_{j+n-1}+\dots + b_n c_j=0, \text{ где } b_0,b_n \neq 0.$$

Тогда возьмём в качестве $g(x)= b_n x^n+\dots+b_0$. Как теперь найти $f(x)$? Вспомним условие на коэффициенты и положим
$$a_i= \sum_{j=0}^{n} b_{j} c_{i-j}, \text{ где } i\in \ovl{0,n}.$$
Это и есть коэффициенты $f(x)$. Допустим дробь $\frac{f}{g}$ сократима. Тогда по уже доказанному она удовлетворяет соотношению меньшего $\deg g$ порядка.
\endproof

Рассмотрим простейший пример. Какая рациональная функция соответствует последовательности удовлетворяющей соотношению $z_{n+1}=\lambda z_n$, $z_0=1$? Эта последовательность имеет вид $z_n=\lambda^n$. Ей соответствует ряд $$1+ \lambda x+\dots + \lambda^nx^n+\dots .$$
Это ряд для функции
$$\frac{1}{1-\lambda x}.$$
Значит функции
$$\frac{1}{x-\lambda}=\frac{-1}{\lambda}\frac{1}{1-\frac{x}{\lambda}}$$
соответствует последовательность $z_n=-{\frac{1}{\lambda}^{n+1}}$, то есть некоторая геометрическая прогрессия.

А что соответствует ${\frac{1}{(1-\lambda x)^k}}$, где $k\geq 2$? Вспомним про производную. Заметим, что $$\frac{d^{k-1}}{dx^{k-1}}\frac{1}{1-\lambda x}=\frac{\lambda^{k-1} (k-1)!}{(1-\lambda x)^k}.$$
Переписывая получаем
$$\frac{1}{(1-\lambda x)^k}= \frac{1}{\lambda^{k-1} (k-1)!}\frac{d^{k-1}}{dx^{k-1}}\frac{1}{1-\lambda x}=  \sum_{n=0}^{\infty} C_{n+k-1}^{k-1} \lambda^{n}x^{n}.$$

\crl Пусть последовательность комплексных чисел $z_n$ удовлетворяет соотношению $a_k z_{n+k}+a_{k-1}z_{n+k-1}+\dots+a_0z_n=0$. Пусть многочлен $p(x)=a_k x^k+\dots +a_0$ имеет корни $\lambda_1$ кратности $k_1$, $\ldots$, $\lambda_l$ кратности $k_l$. Тогда последовательность $z_n$ имеет вид
$$ p_1(n)\lambda_1^n+\dots+p_l(n)\lambda_l^n,$$
где $p_i$ многочлен степени не выше $k_i$.
\proof
Рассмотрим многочлен $g(x)=a_0x^k+\dots+a_k$. Заметим, что $$g(x)=x^k p\left(\frac{1}{x}\right)= x^k\prod\left(\frac{1}{x}-\lambda_i\right)^{k_i}= \prod (1-\lambda_ix)^{k_i}.$$
Последовательность $z_n$ имеет производящую функцию вида
$$\frac{h(x)}{g(x)}.$$
Разложим её на простейшие над $\mb C$. Получим
$$\frac{h(x)}{g(x)}=\sum_{i=1}^l \sum_{0\leq j < k_i} \frac{b_{ij}}{(1-\lambda_ix)^j}.$$
Каждое слагаемое является производящей функцией для последовательности вида $p_{ij}(n)\lambda_i^n$, $\deg p_i < k_i$. Осталось просуммировать при одинаковом $i$.
\endproof
\ecrl

\dfn Многочлен $a_kx^k+\dots +a_0$ называется характеристическим многочленом линейной рекуррентной последовательности.
\edfn

Рассмотрим пример: пусть $f_n$ --- последовательность чисел Фибоначчи. Она удовлетворяет рекуррентному соотношению $f_{n+2}-f_{n+1}-f_n=0.$ Такой последовательности соответствует многочлен $g(x)=-x^2-x+1$ и $f(x)=x$. Рассмотрим дробь $F(x)=\frac{x}{-x^2-x+1}$  и разложим её в сумму простейших. Корни знаменателя это $\lambda_1=\frac{-1+\sqrt{5}}{2}$ и $\lambda_2=\frac{-1-\sqrt{5}}{2}$. Получим
$$F(x)= -\left(\frac{\lambda_1}{\sqrt{5}(x-\lambda_1)}-\frac{\lambda_2}{\sqrt{5}(x-\lambda_2)}\right).$$
Представим каждое слагаемое в виде ряда и получим формулу
$$f_n= \frac{1}{\sqrt{5}}(\ffi^{n-1}-\ovl{\ffi}^{n-1}),$$
где $\ffi=\frac{1+\sqrt{5}}{2}$, а $\ovl{\ffi}=\frac{1-\sqrt{5}}{2}$

Пусть последовательность $a_{n+2}=4a_{n+1}-4a_n$ начинается с $a_1=2$, $a_0=0$. Найдём общую формулу. Рассмотрим дробь $$A(x)=\frac{2x}{4x^2-4x+1}=\frac{2x}{(2x-1)^2}.$$
Как найти разложение в ряд? Заметим, что $$\frac{2}{(2x-1)^2}= \frac{d}{dx}\frac{-1}{2x-1}.$$
Вспомним, как считается производная для рядов. Тогда
$$A(x)=\sum_{n=0} (n+1) 2^{n+1} x^{n+1}=\sum_{n=0} n2^nx^n.$$




Заметим, что если $z_n$ --- комплексная последовательность, удовлетворяющая линейному рекуррентному соотношению, то её производящая функция $f(x)=\frac{h(x)}{g(x)}$ имеет конечный набор комплексных точек, в которых она не определена. Более того, мы даже знаем эти комплексные точки --- это корни $g(x)$, то есть обратные к корням характеристического многочлена. Общая философия, которая за этим стоит такая --- поведение последовательности определяется  <<особыми точками>> её производящей функции, то есть точками на комплексной плоскости, куда эта  функция не может быть продолжена, например, её полюсами.




\chapter{Основы линейной алгебры}

Основными источниками к этой части являются \cite{Meyer}



\setcounter{zad}{0}
\setcounter{lem}{0}
\setcounter{thm}{0}
%\setcounter{defn}{0}
\setcounter{cor}{0}




\section{Системы линейных уравнений и метод Гаусса}

\dfn Пусть $R$ -- кольцо. Тогда системой $m$ линейных уравнений от $n$ неизвестных называется набор условий

$$\begin{cases}
a_{11}x_1+\dots + a_{1n}x_n=b_1\\
\vdots \\
a_{m1}x_1+\dots+a_{mn}x_n=b_m
\end{cases},$$
где $a_{ij}, b_i \in R$.
\edfn

Совершенно понятно, что система линейных уравнений определяется однозначно числами $a_{ij}$ и $b_i$. Эти числа удобно организовывать в матрицы.

\dfn Матрица размера $m\times n$ над кольцом $R$ -- это набор чисел проиндексированных двумя индексами $a_{ij}$ $i\in \ovl{1,m}$, $j\in \ovl{1,n}$. Множество всех матриц размера $m\times n$ над кольцом $R$ обозначается как $M_{m\times n}(R)$. Обычно матрицы  будут обозначаться заглавными буквами, например $A$. Тот факт, что матрица $A$ имеет размер $m\times n$ будем записывать как $A\in M_{m\times n}(R)$. Рисовать матрицы мы будем в виде таблиц.
\edfn

\dfn Матрица системы линейных уравнений называется матрица $A\in M_{m\times n}$, состоящая из коэффициентов $a_{ij}$ этой системы. Матрица размера $m\times (n+1)$ содержащая дополнительно столбец $b_1,\dots, b_m$ называется расширенной матрицей системы. Мы будем отчёркивать столбец $b$, чтобы выделить его особую роль и будем обозначать расширенную матрицу системы как $(A|b)$.
$$\begin{cases}
a_{11}x_1+\dots + a_{1n}x_n=b_1\\
\vdots \\
a_{m1}x_1+\dots+a_{mn}x_n=b_m
\end{cases} \to
\left( \bar{ccc|c}
a_{11}& \dots& a_{1n} &b_1\\
\vdots& \ddots & \vdots&  \vdots \\
a_{m1}&\dots&a_{mn}& b_m
\ear \right).
$$

\edfn


От каждой системы нас прежде всего интересует множество её решений. Поэтому логично ввести определение:

\dfn Две системы линейных уравнений от одного и того же набора переменных $x_1,\dots,x_n$ называются эквивалентными, если множества их решений совпадают.
\edfn

Как для данной системы линейных уравнений можно построить эквивалентную? Прежде всего заметим, что если есть два уравнения, то по ним можно построить много новых. Пусть есть два коэффициента -- $\lambda$ и $\mu$ из $R$. Тогда сложив два уравнения с коэффициентами $\lambda$ и $\mu$ получаем третье
$$\begin{cases}
a_1x_1+\dots+a_nx_n=c\\
b_1x_1+\dots+b_nx_n=d
\end{cases} \Rightarrow (\lambda a_1+\mu b_1)x_1+ \dots +(\lambda a_n+ \mu b_n)x_n= \lambda c+\mu d.$$
Понятно, что если набор $x_1,\dots,x_n$ -- решение первых двух, то и нового тоже.

Получать новые уравнения мы научились, но увеличивать число уравнений в системе  -- не то, к чему мы стремимся. Нам бы хотелось получать систему такого или меньшего размера. Введём определение элементарных преобразований.

\dfn Пусть дана система уравнений
 $$\begin{cases}
a_{11}x_1+\dots + a_{1n}x_n=b_1\\
\vdots \\
a_{m1}x_1+\dots+a_{mn}x_n=b_m
\end{cases},$$
Элементарным преобразованием первого типа над этой системой линейных уравнений называется следующая операция. Рассмотрим уравнения с номерами $i$ и $j$, где $i\neq j$ и элемент $\lambda \in K$. Тогда прибавим  $i$-ое уравнение к $j$-ому с коэффициентом $\lambda$ и поместим результат на место $j$-го уравнения.
\edfn

\rm Очевидно, что решение новой системы содержит решения старой. Однако верно и наоборот, так как старая система получается из новой аналогичным прибавлением $i$-ого уравнения к $j$-ому, но с коэффициентом $-\lambda$.
\erm

\dfn  Элементарным преобразованием второго типа называется преобразование, домножающее $i$-ое уравнение на коэффициент $\lambda \in R^*$.
Элементарным преобразованием третьего типа называется преобразование меняющее местами $i$-ое и $j$-ое уравнения местами.
\edfn

\rm Элементарное преобразование второго типа приводит к эквивалентной системе так как есть обратное преобразование -- домножение на $\lambda^{-1}$. Для преобразования третьего типа эквивалентность тривиальна.
\erm





Нам будет удобно вместо системы линейных уравнений работать с её упрощённой записью -- матрицей этой системы. Поэтому логично перевести понятия элементарных преобразований на язык матриц.

\dfn Элементарным преобразованием строк первого типа над матрицей $A$ называется прибавление к $j$-ой строчке матрицы $A$ её $i$ строки с некоторым коэффициентом $\lambda$. Преобразованием второго типа называется домножение $i$-ой строчки на обратимый элемент $\lambda \in R^*$. Элементарным преобразованием третьего типа называется перестановка $i$-ой и $j$-ой строк в матрице $A$. 
\edfn

Мы научились строить по системе уравнений новую равносильную ей систему. Прежде чем обсудить общую ситуацию, посмотрим на конкретный пример. Решим систему из трёх уравнений с тремя неизвестными:
$$\begin{cases}
x+3y+z=1\\
2x+5y+z=-1\\
x-y+2z=-1
\end{cases}.
$$
Для простоты перейдём к матричной форме. Вот расширенная матрица системы:


$$\left(
\bar{rrr|r}
1& 3 & 1 & 1\\
2& 5 & 1 & -1\\
1& -1 & 2 &-1
\ear\right).$$
Применим цепочку элементарных преобразований строк
$$\left(
\bar{rrr|r}
1& 3 & 1 &\tikznode{g1}{$1$}\\
2& 5 & 1 &\tikznode{g2}{$-1$}\\
1& -1 & 2 &\tikznode{g3}{$-1$}
\ear\!\!\right) \quad \quad \quad \quad\to 
\left(
\bar{rrr|r}
1& 3 & 1 &1\\
0& -1 & -1 &\tikznode{gg2}{$-3$}\\
0& -4 & 1 &\tikznode{gg3}{$-2$}
\ear\!\!\right)
\quad \quad \to 
\left(
\bar{rrr|r}
1& 3 & 1 &1\\
0& -1 & -1 &-3\\
0& 0 & 5 &\tikznode{ggg3}{$10$}
\ear\!\!\right)
$$
\begin{tikzpicture}[remember picture,overlay,cyan,rounded corners]
  \draw[<-,shorten <=12pt,shorten >=12pt]
  (g2) -- +(1.0,0)  |- (g1);
  \draw[<-,shorten <=12pt,shorten >=12pt]
  (g3) -- +(1.6,0) |- (g1);
  \node (b2) at ($1/2*(g1)+1/2*(g2)+(1.2,-0.1)$) {$\scriptstyle{-2}$};
  \node (b3) at ($1/2*(g1)+1/2*(g3)+(1.8,0)$) {$\scriptstyle{-1}$};
  
  \draw[<-,shorten <=12pt,shorten >=12pt]
  (gg3) -- +(1.0,0)  |- (gg2);
  \node (b4) at ($1/2*(gg2)+1/2*(gg3)+(1.3,-0.1)$) {$\scriptstyle{-4}$};
  \node (b5) at ($(ggg3)+(0.8,0)$) {$ \cdot \frac{1}{5}$};
\end{tikzpicture}


На последнем шаге нижняя строчка даёт уравнение $z=2$. Подставляя $z=2$ в уравнение второй строки мы получаем $-y-2=-3$, откуда $y=1$. Из первой строки находим $x=-4$.

Коротко указанную процедуру можно охарактеризовать так -- избавляемся при помощи одного уравнения от вхождения одной из переменных во все нижние уравнения. Какие вопросы могут нас ждать на этом пути?

\enm
\item Когда можно провернуть первый шаг этого алгоритма? Тогда, когда первый элемент $a_{11}$ делит первый элемент второй строки $a_{21}$. Если $R$ абы какое, то это бывает крайне редко. Поэтому мы ограничим себя случаем $R=K$ -- поле.
\item Даже если рассматривать системы линейных уравнений над полем получается, что для первого шага должно быть выполнено, что $a_{11}\neq 0$. 
\item А ещё в примере число уравнений $m$ и число неизвестных $n$ в системе было одинаковым. Что изменится, если $n \neq m$? Как написать общий ответ?
\eenm


Ответим на эти вопросы. Для этого со всеми деталями опишем метод исключения Гаусса. Продолжим работать в матричной записи. Для начала определимся, какого вида матрицу мы хотим получить после того, как закончим преобразования строк в случае системы произвольного размера.

\dfn Главным элементом строки матрицы $A$ будем называть первый ненулевой элемент в этой строке.
\edfn

\dfn Будем говорить, что матрица $A$ имеет ступенчатый вид, если каждая новая строчка начинается с большего количества нулей, чем предыдущая, либо целиком состоит из нулей. Говоря строго, для $i$-ой строки номер столбца в котором стоит главный элемент строки строго больше, чем аналогичный  номер у $i-1$ строки, если только строка не целиком состоит из нулей.
\edfn

Утверждение, которое стоит за методом Гаусса можно сформулировать следующим образом:

\thrm Любую матрицу над полем $K$ можно привести элементарными преобразованиями строк к ступенчатому виду. Более того, можно добиться того, чтобы для каждой строки её главный элемент был равен 1, а в столбце над ним стояли нули.
\ethrm
Предъявим индукционный алгоритм для получения ступенчатого вида:\\
{\bf Случай 1:} Элемент $a_{11}\neq 0$. Тогда прибавим к $i$-ой строке первую с коэффициентами $-\frac{a_{i1}}{a_{11}}$. Получится матрица у которой в первом столбце стоят нули, кроме первой позиции. Вычеркнем первый столбик и первую строчку и продолжим по индукции.\\
{\bf Случай 2:} Элемент $a_{11}=0$, но в первом столбце в $i$-ой строчке стоит ненулевой элемент. Поменяем строку с номером $i$ с первой строкой и продолжим, как в случае 1.\\
{\bf Случай 3:} Весь первый столбец нулевой. Тогда вычеркнем первый столбец и продолжим по индукции.


Указанные преобразования очевидно приводят матрицу к ступенчатому виду. 
Теперь заработаем единицы в главных элементах строк. Пусть  $a_i$ -- главный элемент строки $i$. Тогда умножим её на $a_i^{-1}$.

Способ добиться нулей над главными элементами называется обратным ходом метода Гаусса.

Будем идти вверх по строкам матрицы, начиная с первой ненулевой строки. Посмотрим на последнюю ненулевую строку -- скажем строку $k$, первый  столбец с ненулевым элементом в которой имеет номер $j_k$, и прибавим её ко всем строкам выше с коэффициентом $-a_{lj_k}$ для $l$-ой строки. После чего перейдём к следующей строке.\\



\noindent {\bf Как при помощи этого всего решить систему?}
Приведём расширенную матрицу системы к ступенчатому виду. Рассмотрим последнюю ненулевую строчку. Если её ненулевой элемент находится в самом последнем отчёркнутом столбце, то решений нет, потому, что эта строчка соответствует уравнению $0x_1+\dots+0x_n=b_1\neq 0$, которое, как ни крути, решений не имеет.

Если же такого не происходит, то разделим переменные на два класса. Каждая переменная соответствует столбцу матрицы. Если в  столбце $1\leq i\leq n$ стоит главный элемент какой-то строки, то $x_i$ будем называть зависимой переменной. Если же в $i$-ом столбце нет главного элемента никакой строки, то $x_i$ будем называть независимой.

Выпишем все независимые переменные $x_{i_1},\dots,x_{i_r}$. Осталось заметить, что, выбрав любые значения для $x_{i_1},\dots,x_{i_r}$,  мы однозначно восстановим значения всех остальных переменных из уравнений.

Более того, значения остальных переменных представляются в виде значений многочленов первой степени от  $x_{i_1},\dots,x_{i_n}$. Так выглядит стандартное описание всех решений линейного уравнения, которое выдаёт метод Гаусса.

\rm Описанный метод подразумевает работу со строчками в определённом порядке. В частности, перестановка строк делается только в экстренных случаях. Но, в принципе, никто не запрещает для удобства переставлять строчки и прибавлять их друг к другу в произвольном порядке -- лишь бы вид системы в конце позволял проанализировать множество решений.
\erm

Давайте разберёмся, где же может пригодиться наш метод решения систем линейных уравнений?

\exm\\
Допустим мы хотим наладить некоторую поисковую систему. Что это значит? Поисковая система индексирует страницы в сети и то, какая страница на какую ссылается. Иными словами, поисковая система видит ориентированный граф $G$, вершины которого -- это страницы в сети, а рёбра проводятся, если один сайт ссылается на другой.

Что же должна сделать поисковая система? Ей неплохо было бы назначить каждому сайту его важность. То есть необходима функция из множества вершин графа в вещественные числа  $W\colon G \to \mb R$. Важность сайта зависит от того, насколько много на него ссылаются. Это приводит  к следующей системе уравнений:
$$w_i=\sum_{j\to i} \frac{1}{d_j^{out}}w_j,$$
где $d_j^{out}$ исходящая степень вершины $j$. 



Приведём пример, в котором возникает линейная система над $\mb Z/2$. Это будет описания довольно эффективного эвристического алгоритма для разложения числа $n$ на множители. 

Заметим, что для того, чтобы разложить нечётное число $n$ на множители достаточно (и необходимо) найти нетривиальное решение сравнения $$x^2=y^2(\mod n),$$
то есть такое решение, где $x\neq \pm y (\mod n)$. В этом случае число $n$ имеет нетривиальный множитель $(n,x-y)$.

Для получения такого разложения можно взять набор всех простых $p_1,\dots,p_h$ меньших некоторой константы $M$. Далее будем случайно брать элементы $x_i$ ( удобно брать их около $\sqrt{n}$) и считать  $x_i^2 \mod n$. Если $h$ большое, то с высокой вероятностью $x_i^2\mod  n$ есть произведение $p_1^{\alpha_{1i}}\dots p_h^{\alpha_{hi}}$. Оставим только такие $x_i$, что для $x_i^2$ есть указанное разложение. Найдём $h+1$ такое $x_i$. Построим теперь решение сравнения. Будем искать $x$ в виде $x=\prod x_i^{\eps_i}$, где $\eps_i \in \{0,1\}$. Посчитаем $x^2 \mod n$. Это число сравнимо с 
$$x^2 =x_1^{\eps_1}\dots x_{h+1}^{\eps_{h+1}} \equiv p_1^{\alpha_{11}\eps_1 +\dots+\alpha_{1h+1}\eps_{h+1}} \dots p_h^{\alpha_{1h}\eps_1 +\dots+\alpha_{h h+1}\eps_{h+1}} \mod n.$$
Если искать $y$ в виде $y=\prod p_i^{\gamma_i}$, то такой точно найдётся, если разрешима система
$$\begin{cases}
\alpha_{11} \eps_1+\dots+\alpha_{1h+1}\eps_{h+1}=0 \mod 2 \\
\vdots\\
\alpha_{h1} \eps_1+\dots+\alpha_{hh+1}\eps_{h+1}=0 \mod 2
\end{cases}$$
Это однородная система из $h+1$ уравнения и $h$ неизвестных над полем $\mb Z/2$. У неё скорее всего есть нетривиальное решение. Это позволяет найти нам $y$. К сожалению, никто не гарантировал, что такой $y$ даёт нетривиальное решение. Но если даёт, то разложение найдено. В указанном алгоритме часто берут $M$ порядка $e^{\sqrt{\ln n \ln\ln n}}$. Это приводит к субэкспоненциальному алгоритму для разложения числа на множители -- алгоритму Диксона.

Казалось бы, мы научились решать произвольную систему линейных уравнений -- что же ещё можно спросить? Поставим несколько вопросов, на которые ответим в дальнейшем:
\enm
\item Предположим, что две системы эквивалентны, например, потому что получились одна из другой перестановкой строк. Верно ли, что ответ для общего решения в методе Гаусса будет содержать одинаковое число независимых параметров? А что будет, если одна система из другой получается заменой переменных?
\item В методе Гаусса видно, что решающую роль играет матрица системы. Вопрос: как по матрице системы определить, для каких $b$ система будет разрешима?
\item Мы интуитивно догадываемся, что обычно решение системы из $n$ уравнений и $m$ неизвестных описывается $m-n$ параметрами (если это число не отрицательно, конечно). Однако это не всегда так. Вопрос -- найти критерии, когда это выполнено, а когда нет. Это очень полезно, например, в задаче про поисковик. Ведь в этой задаче $n$ уравнений на $n$ неизвестных, но она, очевидно, имеет нулевое решение. Хочется доказать, что нулевое решение  не единственное.
\item Часто решение системы нужно найти не обязательно точно. Например в задаче про поисковик. Никто не умрёт, если ранжирование чуть-чуть поедет. Разрешив неточное решение хочется выиграть на времени его нахождения. Это актуально для больших матриц. Что как раз  и имеет место в задаче о поисковой системе. Размер матрицы там равен числу вершин графа, то есть числу страниц в интернете. Сейчас в интернете более миллиарда страниц.

\item В задаче о разложении числа на множители нам попалась матрица над $\mb Z/2$. Заметим, что каждая строка этой матрицы соответствует разложению $x_i^2 \mod n < n $ на простые. но число не может раскладываться более чем на $\log$ от своего размера различных простых множителей. Поэтому в каждой строке всего $O(\log n)$ ненулевых чисел.  Всего $O(h \log n )$ ненулевых элементов. При выборе $h=e^{\sqrt{\ln n \ln\ln n}}$ получаем, что $(\log h)^2 = \ln n \ln\ln n$. Итого, получаем, что в матрице  $O(h \log^2 h)$ ненулевых элементов, что заметно меньше, чем возможные $h(h+1)$. Матрицы, в которых мало ненулевых элементов называются разреженными. Хочется иметь алгоритмы, быстро решающие системы с разреженными матрицами.
\eenm


\section{Операции с матрицами}

Отвлечёмся на время от ситуации в случае полей и посмотрим ещё на общие конструкции связанные с системой линейных уравнений. Пусть нам дано одно линейное уравнение $a_1x_1+\dots+ a_n x_n =b$. Матрица этой системы это строка $(a_1,\dots,a_n)$. Набор переменных мы будем считать столбцом высоты $n$. Мы хотим ввести операцию, которая восстанавливала бы выражение $a_1x_1+\dots+ a_n x_n$ по строке $a$ и столбцу $x$. До поры будем работать в контексте произвольного кольца.

\dfn Пусть $R$ -- кольцо. Определим произведение строки $a\in M_{1\times n}(R)$ на столбец $x\in M_{n\times 1}(R)$ в виде
$$ax= a_1x_1+\dots+a_nx_n.$$
\edfn 

Условимся обозначать множество столбцов $M_{n\times 1}(R)$ просто как $R^n$. Определение произведения мгновенно переносится на ситуацию, когда $A$ матрица. 

\dfn Пусть $R$ -- кольцо, $A\in M_{m\times n}(R)$, $x\in R^n$. Определим произведение $Ax$ как столбец из $R^m$, каждый элемент которого есть произведение строки из $A$ на столбец $x$,
$$Ax= \pmat a_{11} & \dots & a_{1n}\\
\vdots & \ddots & \vdots \\
a_{m1}&\dots& a_{mn} \epmat \pmat x_1\\ \vdots \\ x_n \epmat = \pmat a_{11}x_1+\dots+a_{1n}x_n\\ \vdots \\ a_{m1}x_1+\dots+a_{mn}x_n \epmat .$$
\edfn


Это определение позволяет нам записать систему линейных уравнений в компактном виде
$$Ax=b.$$

\rm Заметим, что задав операцию произведения, мы для каждой матрицы $A$ задали отображение $R^n \to R^m$, переводящее столбец $x\to Ax$.
\erm

Допустим мы хотим вычислить значение этого отображения одновременно на $k$ столбцах $e_i \in \mb R^n$. Организуем эти столбцы в матрицу $B=\pmat e_1 & \dots & e_k \epmat \in M_{n\times k}(R)$. Определим произведение матрицы $A\in M_{m\times n}(R)$ на матрицу $B$ как матрицу $C \in M_{m\times k}(R)$, чья $j$-ый столбец имеет вид $Ae_j$. Распишем это

\dfn Пусть $A\in M_{m\times n}(R)$ $B \in M_{n\times k}(R)$. Тогда произведение $AB$ это такая матрица $C \in M_{m\times k }(R)$, что 
$$C_{ij} = \sum_{k=1}^n A_{ik}B_{kj}$$
при $1\leq i\leq m$ и $1\leq j \leq k$.
\edfn

Основным свойством этой операции является ассоциативность

\utv Пусть $A\in M_{m\times n}(R), B \in M_{n\times l}(R), C\in M_{l\times s}(R)$. Тогда
$$(AB)C= A(BC).$$
\eutv





\noindent В некоторых задачах особенно важно научиться возводить матрицу в степень.\\
\exm\\
1) Вспомним про задачу с популяцией. Пусть дано $n$ городов и в начальный момент времени. Количество жителей, которые находятся в городе $i$ обозначим за $x_i$. Пусть известно, что ежегодно доля жителей переезжающих из города $j$ в город $i$ -- это $a_{ij}$. Составив из $a_{ij}$ матрицу $A\in M_{n\times n}(\mb R)$ получаем, что для того, чтобы узнать число жителей в городах через год нам надо найти столбец $Ax$. Если же мы хотим понять, сколько, при фиксированных тенденциях будет жителей в городах через $k$ лет, то необходимо понять, как ведёт себя выражение 
$$A^k x \text{ -- популяция через $k$ лет}.$$
2) Пусть $A$ -- матрица смежности графа. Тогда $(A^k)_{ij}$ -- это количество путей длины $k$ из вершины $j$ в вершину $i$. В частности, $(A^3)_{ii}/2$ -- это количество треугольников  содержащих вершину $i$. Всего же, число треугольников в графе есть 
$$\frac{1}{6}\sum_{i=1}^n (A^3)_{ii}.$$
Если научиться быстро считать умножение матриц, то можно быстро посчитать число треугольников (или других циклов).\\

Здесь важно отметить ещё одно свойство умножения матриц -- его блочную структуру. Точнее, если есть две матрицы
$$A=\pmat A_{11} & A_{12}\\
A_{21}& A_{22}
\epmat \text{ и } B=\pmat B_{11} & B_{12}\\
B_{21}& B_{22}
\epmat $$
которые перемножаемы, плюс ко всему размеры $A_{ik}$ и $B_{kj}$ согласованы, то тогда
$$AB= \pmat A_{11}B_{11}+ A_{12}B_{21} & A_{11}B_{12}+ A_{12}B_{22}\\
A_{21}B_{11}+ A_{22}B_{21}& A_{21}B_{12}+ A_{22}B_{22}\epmat. $$
То есть матрицы перемножаются по блокам.

Это важная составляющая алгоритма для быстрого умножения матриц опубликованного Фолькером Штрассеном в работе \cite{StrassenGauss}

Однако кроме операции произведения есть и другие, более привычные и простые.

\dfn Пусть $A,B\in M_{m\times n}(R)$. Тогда определим сумму матриц как 
$$(A+B)_{ij}=A_{ij}+B_{ij}.$$
\edfn

\dfn Пусть $r\in R$, $A\in M_{m\times n}(R)$. тогда определим $rA$ как 
$$(rA)_{ij}=rA_{ij}.$$
\edfn

\utv Пусть $R$ -- кольцо. Тогда\\
1) $M_{m\times n}(R)$ относительно сложения это абелева группа.\\
2) $(A+B)C=AC+BC$\\
3) $C(A+B)=CA+CB$.\\
4) $r(AB)=(rA)B=A(rB)$.\\
5) $(r_1+r_2)A=r_1A+r_2A$.\\
6) $r(A+B)=rA+rB$.
\eutv

\crl Если $x_0\in R^n$, решение системы линейных уравнений $Ax=b$, где $A\in M_{m\times n}(R)$, $b\in R^m$, то любое другое решение $x'$ этой системы имеет вид $x'=x_0+y$, где $Ay=0$, -- есть решение однородной системы. Обратно, если $Ay=0$, то любое $x'=x_0+y$ есть решение  $Ax=b$.
\proof Определим $y=x'-x_0$. Тогда $$Ay=A(x'-x_0)=Ax'-Ax_0=b-b=0.$$
Если теперь $Ay=0$, то 
$$A(x_0+y)=Ax_0+Ay=b.$$

\endproof
\ecrl

\crl Пусть $y_1,y_2$ решение однородного уравнения $Ay=0$. Тогда $y_1+y_2$  и $ry_1$ решение уравнения $Ay=0$.
\ecrl

\crl Если уравнение $Ax=b$ разрешимо, то мощность множества его решений такая же как и у уравнения $Ax=0$. 
\ecrl





\section{Векторные пространства}

Базовым объектом линейной алгебры является векторное пространство.

\dfn[Векторное пространство]
Векторным пространством над полем $K$ называется множество $V$ вместе с отображениями $+\colon V\times V \to V$ и $\cdot \colon K \times V \to V$, удовлетворяющее свойствам:\\
1) $V$ относительно сложения -- это абелева группа\\
2) $\forall v \in V$ верно, что $1\cdot v=v$\\
3) $\forall v \in V$, $\forall \lambda, \mu \in K$ верно, что $(\lambda+\mu)\cdot v= \lambda\cdot v + \mu \cdot v$.\\
4) $\forall u,v \in V$, $\forall \lambda \in K$ верно, что $\lambda\cdot(u+v)= \lambda\cdot u + \lambda \cdot v$.\\
5) $\forall v \in V$ $\forall \lambda, \mu \in K$ верно, что $(\lambda\mu)\cdot v= \lambda\cdot(\mu \cdot v)$.
\edfn





\exm\\
0) Само поле $K$ вместе со сложением и умножением.\\
1) Пространство столбцов $K^n$. Умножение и сложение покомпонентное.\\
2) Обобщая. Пространство матриц $M_{m\times n}(K)$.\\
3) Пусть $X$ -- множество. Рассмотрим множество всех функций  из $K$ в $X$ , то есть $K^X$. Это векторное пространство над полем $K$ с поточечным сложением и умножением.\\
4) Рассмотрим множество непрерывных вещественнозначных функций на отрезке $[0,1]$. Это векторное пространство над $\mb R$.\\
5) Рассмотрим множество последовательностей над полем $K$, удовлетворяющих заданному линейному рекуррентному соотношению $a_k x_{n+k}+\dots+a_0x_n=0$. Это векторное пространство над $K$.\\
6) Рассмотрим множества всех многочленов $K[x]$\\
7) $\mb C$ является векторным пространством над $\mb R$\\



Однако обычно векторные пространства возникают в следующей ситуации.





\dfn[Подпространство] Пусть $V$ -- векторное пространство над полем $K$. Подмножество $U\subseteq V$ называется подпространством $V$, если\\
1) $U$ -- подгруппа $V$.\\
2) $\forall \lambda \in K$, $\forall u \in U$ верно, что $\lambda u \in U$.\\
По другому говоря,  операции на $V$ можно сузить на $U$, с тем, чтобы $U$ стало векторным пространством относительно этих операций.
\edfn

\exm\\
1) Множество решений уравнения $Ax=0$, где матрица $A \in M_{m \times n}(K)$ образует подпространство в $K^n$. Это один из самых интересных для нас примеров.\\
2) Рассмотрим множество непрерывных на отрезке $[0,1]$ функций, принимающих значение $0$  в точках $0, \frac{1}{2}, 1$. Это подпространство в $C([0,1])$.\\
3) Рассмотрим множество многочленов степени не выше $n$ от одной переменной $$K[x]_{\leq n}=\{ f \in K[x]\,|\, \deg f\leq n\}.$$ Это подпространство в  $K[x]$.\\
4) Рассмотрим множество правильных дробей $\frac{f}{g}\in K(x)$. Это подпространство в $K(x)$.\\

\utv[Простейшие свойства] Пусть $V$ -- векторное простраснтво над полем $K$. Тогда  \\
1) $0\cdot v =0 \in V$ для всех $v\in V$\\
2) $(-1)\cdot v=-v$ для всех $v\in V$\\
3) $\lambda \cdot 0 = 0$ для всех $\lambda\in K$.
\eutv


\rm Подпространства наследует с объемлющего пространства структуру и потому сами являются примерами векторных пространств.
\erm


Если дан некоторый набор векторов из пространства, то любое подпространство, их содержащее, должно содержать их всевозможные суммы с любыми коэффициентами. Для этой ситуации в линейной алгебре есть специальный термин.

\dfn(Линейная комбинация) Линейной комбинацией векторов $v_1,\dots, v_n$ с коэффициентами $\lambda_1, \dots, \lambda_n$, называется выражение
$$\lambda_1 v_1 +\dots + \lambda_n v_n.$$
Будем говорить, что элемент $v\in V$ представим в виде линейной комбинации векторов $v_1,\dots,v_n$, если
$$v=\lambda_1 v_1 +\dots + \lambda_n v_n.$$
Если хотя бы один из элементов $\lambda_1,\dots, \lambda_n $ не равен 0, то говорят, что линейная комбинация нетривиальна.
\edfn



\dfn Пусть $X \subseteq V$. Тогда линейная оболочка $\lan X \ran$ называется множество всех линейных комбинаций.
$$\lan X \ran = \{ v\in V\,|\, \exists\, v_1,\dots,v_k\in X\,\,  \lambda_1,\dots,\lambda_k \in K, \text{ что } v=\lambda_1v_1+\dots+\lambda_kv_k\}$$
\edfn

\dfn Будем говорить, что набор $v_{\alpha} \in V$ $\alpha \in I$ является порождающим для $V$, если $\lan \{v_{\alpha}\}_{\alpha \in I}\ran= V$. Иными словами, для любого $v \in V$ существуют  $\lambda_1,\dots,\lambda_n$, что $v=\sum \lambda_i v_i $.
\edfn

\lm Рассмотрим набор $v_1,\dots,v_n \in V$. Пусть $w_1=\mu_{11}v_1+\dots+\mu_{1n}v_n$, $\dots$, $w_m= \mu_{m1}v_1+\dots+\mu_{mn}v_n$. Рассмотрим набор $\lambda_1,\dots, \lambda_m$. Тогда вектор $w=\sum \lambda_i w_i$ является линейной комбинацией набора $v_i$.
\elm

\crl $\lan X \ran$ является подпространством в $V$, наименьшим среди содержащих $X$.
\ecrl


\dfn[Линейная зависимость] Набор векторов $v_1,\dots,v_n$ называется линейно зависимым, если 0 является нетривиальной линейной комбинацией $v_1,\dots, v_n$, то есть существуют  $\lambda_1, \dots, \lambda_n \in K$ не все равные 0, что
$$0=\lambda_1v_1+\dots+\lambda_n v_n.$$
\edfn

\dfn[Линейная независимость] Набор векторов $v_1,\dots,v_n$ называется линейно независимым, если он не является линейно зависимым, то есть если $\lambda_1, \dots, \lambda_n \in K$ такие, что $$0=\lambda_1v_1+\dots+\lambda_n v_n, \text{ то $\lambda_1=\dots=\lambda_n=0$}.$$
\edfn


\exm \\
0) Набор из одного нуля линейно зависим.\\
1) Пусть $v_1$ и $v_2$ два вектора из $V$. Они линейно зависимы тогда и только тогда, когда они пропорциональны.\\
2) Рассмотрим пространство $K^n$ и набор столбцов
$$e_1=\pmat 1\\0\\ \vdots\\ 0\epmat,\, \dots, e_n=\pmat 0\\ 0 \\ \vdots \\ 1 \epmat.$$
Это линейно независимая система векторов. \\
3) Аналогично в пространстве матриц $M_{m \times n}(K)$ имеется набор матриц $e_{ij}$ вида
$$ e_{ij}=
\bordermatrix{
 & &j&& \cr
 &0&\cdots&\cdots&0\cr
 &\vdots&\ddots && \vdots\cr
i&\vdots& 1 & \ddots& \vdots\cr
 &0&\cdots& \cdots&0
}
$$\\
4) Любой поднабор линейно независимого набора линейно независим.\\


\thrm[О линейной зависимости линейных комбинаций.] Пусть $u_1,\dots,u_m$ и $v_1,\dots,v_n$ два набора векторов. При этом все вектора $u_i$ являются линейными комбинациями $v_j$, то есть $u_i=\sum_{j=1}^n \lambda_{ij}v_j$. Тогда, если $m>n$, то $u_i$ обязательно линейно зависимы.
\ethrm
\proof Индукция по $n$. $n=1$. Все вектора $u_i$ кратны $v_1$ и пропорциональны друг другу, то есть линейно зависимы.

Будем поступать как в методе Гаусса. Запишем $u_i$ в виде
$u_i=\sum_{j=1}^n \lambda_{ij}v_j$. Если для некоторого индекса $j$ все $\lambda_{ij}=0$, то можно воспользоваться предположением индукции.

Рассмотрим вектор $u_i$, что $\lambda_{in}\neq 0$. Тогда перейдём к набору $$u_s'=u_s - \frac{\lambda_{sn}}{\lambda_{in}}u_i= \sum_{j=1}^{n-1} \mu_{sj} v_j, \,\,\,\, s\neq i.$$
Это набор из $m-1$ элемента, которые суть линейные комбинации $v_1,\dots,v_{n-1}$. Этот набор линейно зависим по индукционному предположению, то есть существуют $\nu_{s}$ не все равные нулю, что
$$0=\sum \nu_s u_{s}'= -\left(\sum\nu_s\frac{\lambda_{sn}}{\lambda_{in}}\right)u_i +\sum \nu_s u_s.$$
Заметим, что не все коэффициенты при $u_s$ равны нулю. Таким образом, мы получили нетривиальную линейную зависимость.
\endproof






\dfn[Базис] Набор векторов $v_{\alpha}$, $\alpha \in I$ называется базисом пространства $V$, если он является порождающей и линейно независимой системой векторов в $V$. \edfn

\exm\\
1) Набор векторов $e_i \in K^n$ является базисом. Этот базис называют стандартным.\\
2) Набор $e_{ij}$ является базисом $M_{m\times n}(K)$.\\
3) Мономы $1,x, \dots, x^n$ являются базисом $K[x]_{\leq n}$.\\
4) $1,i$ -- базис $\mb C$ над $\mb R$.\\
5) Базис $\mb C(x)$ над $\mb C$ это $\frac{1}{(x-\lambda)^n}$, где $\lambda \in \mb C$, $n\in\mb N$ и мономы $1,x,\dots, x^n, \dots$. Мощность этого базиса континуальна.








\lm[Переформулировки] Пусть $e_1,\dots,e_n$ -- набор элементов пространства $V$.
Тогда следующие свойства эквивалентны: \\
1) $e_1,\dots,e_n$ -- базис $V$.\\
2) $e_1,\dots,e_n$ -- минимальный по включению среди порождающих $V$ наборов векторов.\\
3) Для любого $v\in V$ существуют единственные $\lambda_1,\dots,\lambda_n \in K$, что $v=\lambda_1e_1+\dots+\lambda_ne_n$. Такие элементы $\lambda_1,\dots,\lambda_n$ называются координатами вектора $v$ в базисе $e$.\\
4) $e_1,\dots,e_n$ -- максимальный по включению набор среди линейно независимых наборов векторов из $V$.
\proof 1)  в 2). Пусть набор не минимален. Тогда в нём есть лишний вектор. Например, $e_1$. Выкинем его. Но тогда $e_1=\sum_{i\geq 2}\lambda_i e_i$. Это даёт нетривиальную линейную зависимость.

2) в 3). Существование разложения следует из порождаемости. Пусть $\sum \lambda_i e_i =\sum \mu_i e_i$. Тогда либо все $\mu_i=\lambda_i$, либо, скажем, $\mu_1-\lambda_1 \neq 0$. Тогда  $e_1=\frac{1}{\mu_1-\lambda_1}\sum_{i\geq 2} (\mu_i-\lambda_i) e_i$. Тогда из системы можно выкинуть $e_1$ и всё равно будет порождающая система.

3) в 4). Единственность разложения для 0 означает линейную независимость. Покажем максимальность. Пусть система не максимальна. Тогда к ней можно добавить вектор $v\neq 0$ и она останется независимой. Но такого не может быть, так как $v=\sum \lambda_i e_i$, что очевидно даёт линейную зависимость.

4) в 1). Пусть система не порождает $V$. Тогда добавим к ней вектор $v \in V\setminus \lan e_1,\dots,e_m \ran$. Если система зависима, то есть $\lambda v+ \sum \lambda_i e_i=0$, то либо $\lambda=0$ и тогда получаем, что $e_i$ зависимы, что не так, либо $v=-\lambda^{-1} \sum \lambda_i e_i$, что противоречит определению $v$. Таким образом, система $v,e_1,\dots, e_n$ независима, что противоречит максимальности.
\endproof
\elm

\dfn Пространство $V$ называется конечномерным, если оно порождено конечной системой векторов $e_1,\dots,e_n$.
\edfn

\thrm[Теорема о дополнении до базиса] Пусть $V$ -- конечномерное пространство. Тогда любой набор линейно независимых векторов $e_1,\dots,e_m$ можно дополнить до базиса при помощи элементов заданного конечного порождающего множества $v_1,\dots,v_n$. Число $m$ может быть равно нулю.
\proof Будем добавлять элементы из порождающего множества к линейно независимой системе до тех пор, пока полученный набор будет оставаться линейно независимым. Пусть мы в какой-то момент остановились и не можем добавить элемента в нашу линейно независимую систему. Это значит, что любой из оставшихся в порождающей системе элементов выражается через вектора из уже набранных линейно независимых. Значит набранные вектора порождают $V$, а значит, они образуют базис. Что и требовалось доказать.
\endproof
\ethrm

\crl В любом конечномерном пространстве есть конечный базис.
\proof Пустое множество векторов линейно независимо. Дополним его до базиса при помощи конечной порождающей системы.
\endproof
\ecrl


\thrm[Теорема о равномощности базисов] Пусть $V$ -- конечномерное пространство. Тогда любые два базиса $V$  равномощны.
\proof Можно считать, что один базис $e_1,\dots,e_n$ конечен. Рассмотрим другой базис $X \subseteq V$. Если $X$ бесконечно, то есть различные $f_1,\dots,f_{n+1}\in X$. Заметим, что $f_i$ линейно независимы как элементы базиса $X$. Но это противоречит  теореме о линейной зависимости линейных комбинаций так как $f_i$  выражаются через $e_j$. Пусть теперь $X$ конечно. Тогда, применяя тот же аргумент получаем $|X|\leq n$. Заметим, что, наоборот,  $e_j$ выражаются через элементы $X$. Тогда $n\leq |X|$. То есть $|X|=n$.
\endproof
\ethrm

\rm В такой постановке эта теорема верна для любого векторного пространства. Однако общее доказательство требует некоторой специфической техники из теории множеств.
\erm



\dfn[Размерность] Пусть $V$ -- конечномерное векторное пространство. Размерностью $V$ называется количество элементов в каком-то базисе $V$.
\edfn

\rm В дальнейшем будем считать, что все пространства, кроме тех, что встречаются в примерах -- конечномерны.
\erm

\lm Число элементов в любой линейно независимой системе $v_1,\dots,v_k$ в $V$ меньше или равно размерности $V$. Более того, равенство $k=\dim V$ достигается тогда и только тогда, когда $v_1,\dots,v_k$ -- базис $V$.
\elm
\proof Если $v_1,\dots,v_k$ -- линейно независимы, то их можно дополнить до базиса $V$. Но тогда их количество меньше или равно числу элементов в базисе $V$, то есть размерности $V$.
Аналогично, если $k=\dim V$, то мы не можем дополнить эту систему ни одним вектором до линейно независимой, так как получится линейно независимая система слишком большого размера. Таким образом, мы имеем максимальную линейно независимую систему, то есть базис $V$. Обратное утверждение вытекает из определения размерности.
\endproof

Сформулируем аналогичную лемму для порождающих систем

\lm Число элементов в любой конечной порождающей системе $v_1,\dots,v_k$ в $V$ больше или равно размерности $V$. Более того, равенство $k=\dim V$ достигается тогда и только тогда, когда $v_1,\dots,v_k$ -- базис $V$.
\elm



\thrm Любое подпространство $U$ конечномерного пространства $V$ конечномерно и $\dim U \leq \dim V$. Равенство достигается только в случае $U=V$.
\ethrm
\proof Рассмотрим линейно независимую систему $u_1,\dots,u_m$ в $U$ самого большого размера. Такая есть, так как линейно независимая система в $U$ лежит в $V$ и, следовательно, ограничена размерностью $V$. Заметим, что к линейно независимой системе векторов $ u_1,\dots,u_m $, нельзя добавить элемент из $U$, так чтобы она осталась линейно независимой. Таким образом, это максимальная по включению линейно независимая система в $U$, то есть конечный базис $U$. Как мы уже заметили, число $m$ меньше или равно, чем размерность $V$ и, следовательно, $m=\dim U \leq \dim V$. Заметим теперь, что если $m=\dim V$, то $u_1,\dots,u_m$ -- базис $V$ и, следовательно, $U=V$.
\endproof



\exm\\
1) Размерность пространства $M_{m\times n}(K)$ равна $mn$. Базисом является $e_{ij}$. Такой базис называется стандартным\\
2) Размерность пространства $K[x]_{\leq n}=n+1$. Базис $1,x,\dots,x^n$.\\
3) Размерность $\mb C$ над $\mb R$ равна 2.\\

Понятие размерности можно использовать для того, чтобы находить уравнения которым удовлетворяют различные числа.

\dfn Число $\alpha \in \mb C$ называется алгебраическим, если существует такой многочлен $p(x)\in \mb Q[x]$, что $p(x)\neq 0$ и $p(\alpha)=0$.
\edfn

\utv Пусть $\alpha \in \mb C$ -- алгебраическое число, а $f(x)\in \mb Q[x]$ -- некоторый многочлен. Тогда $\beta=f(\alpha)$ -- тоже алгебраическое число.
\eutv
\proof Рассмотрим $\mb Q$-векторное подпространство в $\mb C$ вида $V=\lan 1,\alpha,\dots,\alpha^k,\dots\ran \leq \mb C$. Это подпространство конечно порождено. А именно, если взять многочлен $p(x)\in \mb Q[x]$ из определения алгебраичности для $\alpha$, то 
$$V=\lan 1,\alpha,\dots, \alpha^{n-1}\ran,$$
где $n=\deg p(x)$. Значит $\dim V\leq n$ (при некотором ограничении на $p(x)$ будет и равенство). Значит любой набор из $n+1$ вектора из $V$ линейно зависим. Заметим, что $1,\beta,\dots,\beta^n$ лежат в $V$. Значит они линейно зависимы. Но тогда  есть такие коэффициенты $a_0,\dots,a_n\in \mb Q$ не все равные нулю, что $$a_0+a_1\beta+\dots+a_n\beta^n=0.$$
Но это и значит, что $\beta$ -- алгебраическое число. 
\endproof

\section{Сумма подпространств}

Мы уже обсудили, что пересечение подпространств это подпространство. Есть и другая конструкция, которая является аналогом объединения подпространств.

\dfn[Сумма] Пусть $U_1$ и $U_2$ -- подпространства в пространстве $V$. Тогда определим сумму $U_1$ и $U_2$ как 
$$U_1+U_2=\{u_1+u_2\,|\, u_1\in U_1, \,u_2\in U_2\}.$$
\edfn

\rm Сумма $U_1+U_2$ -- подпространство в $V$. \erm

\rm Кроме суммы подпространств можно рассмотреть и их теоретико множественное пресечение $U_1\cap U_2$. Несложно заметить, что это тоже подпространство. 
\erm

\thrm[Формула Грассмана] Пусть $U_1,U_2$ подпространства конечномерного пространства  $V$. Тогда 
$$\dim (U_1+U_2) + \dim U_1\cap U_2 = \dim U_1 + \dim U_2.$$
\ethrm
\proof Доказательство будет основано на подходящем выборе базиса. Начнём с пересечения $U_1\cap U_2$. Выберем некоторый базис $e_1,\dots,e_k$ в пересечении. Дополним его элементами $f_1,\dots,f_l$ до базиса $U_1$ и элементами $g_1,\dots,g_m$ до базиса $U_2$. Покажем, что $e_1,\dots,e_k, f_1,\dots,f_l, g_1,\dots,g_m $ это базис $U_1+U_2$. 


Понятно, что это порождающая система. Покажем, что этот набор линейно независим. Рассмотрим линейную комбинацию
$$\lambda_1e_1+\dots+\lambda_ke_k +\mu_1 f_1+\dots+\mu_lf_l+ \nu_1g_1+\dots+\nu_m g_m=0.$$
Перепишем это как 
$$\lambda_1e_1+\dots+\lambda_ke_k +\mu_1 f_1+\dots+\mu_lf_l=-(\nu_1g_1+\dots+\nu_m g_m).$$
Левая часть лежит в $U_1$, а правая часть в $U_2$. Значит обе суммы лежат в пересечении. Посмотрим на сумму $\nu_1g_1+\dots+\nu_m g_m\in U_1\cap U_2$. Как вектор из пересечения она расписывается через $e_i$. Но такое может быть только если $\nu_i=0$ так как набор $e_1,\dots,e_k,g_1,\dots,g_m$ линейно независим.  Значит
$$\lambda_1e_1+\dots+\lambda_ke_k +\mu_1 f_1+\dots+\mu_lf_l=0.$$
Но набор $e_1,\dots,e_k,f_1,\dots,f_l$ тоже линейно независим. Откуда оставшиеся коэффициенты так же равны нулю.

Посчитаем теперь размерности $\dim U_1+\dim U_2= k+l+k+m=2k+l+m$. С другой стороны $\dim (U_1+U_2) + \dim U_1\cap U_2= k+l+m+k=2k+l+m$. Что и доказывает нужное равенство.
\endproof

Покажем некоторые эвристические следствия из формулы Грассмана. Представим себе, что мы случайно выбираем подпространства $U_1$ и $U_2$ фиксированной размерности $k$ и $m$. Какова ожидаемая размерность суммы $U_1+U_2$ и размерность пересечения $U_1\cap U_2$?  Для этого, конечно, неплохо бы сказать, что такое случайное подпространство. Посмотрим на вещественную картинку.  Будем просто случайно выбирать вектора (на единичной сфере) и смотреть, какое пространство они порождают. Если присмотреться, то становится понятно, что случайно выбранные $k$ векторов с вероятностью 1 порождают $k$-мерное пространство, если, конечно $k\leq \dim V=n$. 

Итак, что мы можем сказать про сумму случайно выбранных подпространств размерности $k$ и $m$? Исходя из нашего определения это просто будет подпространство порождённое $k+m$ случайно выбранными векторами. Соответственно, если $k+m\leq n$, то ожидаем, что $\dim (U_1+U_2)=k+m$, а если $k+m > n$, то $\dim (U_1+U_2)=n$. Заметим, что в любой ситуации есть неравенство
$$\dim (U_1+U_2)=\dim U_1+\dim U_2 - \dim U_1\cap U_2 \leq \max(k+m,n).$$

Посмотрим на пересечение. Тут удобно воспользоваться формулой Грассмана. Получаем, что ожидаемая размерность будет $\dim U_1 + \dim U_2 - \dim (U_1+U_2)$ то есть $0$ при $k+m \leq n$ и $k+m-n$ при $k+m>n$. Удобно ввести понятие коразмерности 

\dfn Пусть $U\leq V$, причём размерность $V$ равна $n$, а размерность $U$ равна $m$. Тогда коразмерностью $U$  в $V$ называется число  
$$\codim U =n-m.$$
\edfn

В этих терминах получаем, что ожидаемая коразмерность пересечения $\codim U_1\cap U_2$ есть $\codim U_1 + \codim U_2$, если $\codim U_1 + \codim U_2 \leq n$ и $n$ иначе. То есть мы ожидаем, что коразмерности складываются. Воспользовавшись формулой Грассмана в общем случае получаем неравенство
\begin{align*} \codim U_1 \cap U_2 = n -\dim U_1 \cap U_2=& n+\dim (U_1+U_2)-\dim U_1-\dim U_2=\\
=&\codim U_1+\codim U_2 - \codim (U_1 +U_2) \leq \codim U_1+\codim U_2.
\end{align*}

Попробуем посмотреть, можно ли обобщить формулу Грассмана. Сама формула появилась у нас как аналог формулы включения-исключения. Может быть она верна и для большего числа подпространств? 

Ответ: <<Нет>>. Дело в том, что для доказательства формулы включения-исключения используются правила де Моргана $U\cap (V \cup W)=(U\cup V)\cap (U\cup W)$. Оказывается, что аналоги этих формул не верны в общей ситуации. Точнее, возьмём в качестве объемлющего пространства  $\mb R^2$, а в качестве $U,V,W$ три различный прямые проходящие через 0. В этой ситуации $U + (V \cap W)=U+0=U$, а $(U+V)\cap(U+W)=\mb R^2 \cap \mb R^2= \mb R^2$. 


Часто бывает необходимо разделить информацию на важный кусок и неважный. Если информация -- это вектор в $n$ мерном пространстве, то это обычно означает, что мы представляем эту точку в виде суммы двух векторов, первый из которых лежит в одном подпространстве, а второй в другом. Такое разложение должно быть единственным. Эта ситуация формализуется при помощи понятия о прямой сумме.

\dfn Будем говорить, что $V$ раскладывается в прямую сумму своих подпространств $U_1$ и $U_2$ и записывать это как
$$V=U_1\oplus U_2,$$
если $\forall v\in V$ существуют единственные $u_1\in U_1$, $u_2\in U_2$, что $v=u_1+u_2$.
\edfn

Вектор $u_1$ будем называть проекцией $v$ на $U_1$ вдоль $U_2$ и обозначать $u_1=pr_{U_1}v$.

\thrm[Критерий разложения в прямую сумму] Пусть $U_1$ и $U_2$ -- подпространства в пространстве $V$. Тогда следующие условия эквивалентны\\
1) $V=U_1\oplus U_2$\\
2) $V=U_1+U_2$ и $U_1\cap U_2=\{0\}$.\\
3) $U_1\cap U_2=\{0\}$ и $\dim U_1+\dim U_2=\dim V$.\\
4) Для любых базисов $e_1,\dots,e_k$   и $f_1\dots,f_l$ пространств $U_1$ и $U_2$ соответственно, что  $e_1,\dots,e_k,f_1,\dots,f_l$ -- базис $V$\\
5) Существуют базисы $e_1,\dots,e_k$   и $f_1\dots,f_l$ пространств $U_1$ и $U_2$ соответственно, что $e_1,\dots,e_k,f_1,\dots,f_l$ -- базис $V$.
\ethrm
\proof Из 1) в 2). Условие про сумму очевидно. Покажем, что пересечение нулевое. Пусть вектор $u \in U_1\cap U_2$. Запишем равенства $u=u+0$ и $u=0+u$. Это два разложения для $u$ при помощи элементов $u_1$ и $u_2$. По условию прямой суммы такое разложение единственно. Значит $u=0$.


Покажем переход 2) в 3). Надо сравнить размерности. Однако это напрямую следует из формулы Грассмана. Действительно имеем $\dim U_1 + \dim U_2=\dim (U_1+U_2) + 0 = \dim V$.


Из 3) в 4). Пусть $e_1,\dots,e_k$ -- базис пространства $U_1$ и $f_1\dots,f_l$ -- базис пространства $U_2$. Заметим, что по условию $k+l=\dim V$. Значит достаточно показать, что объединённая система векторов  линейно независима. Пусть 
$$\lambda_1 e_1+\dots+\lambda_ke_k+\mu_1f_1+\dots+\mu_lf_l=0.$$
Перенесём 
$$\lambda_1 e_1+\dots+\lambda_ke_k=-(\mu_1f_1+\dots+\mu_lf_l).$$
Получаем, что обе части равенства одновременно лежат в пересечении. Но пересечение состоит только из нуля. Значит обе части равенства нулевые. Так как $e_i$ и $f_j$ базисы получаем, что $\lambda_i=0$ и $\mu_j=0$.\\


Из 4) в 5) переход очевиден. Из 5) в 1). Рассмотрим вектор $v\in V$. Тогда вектор $v$ раскладывается по базису
$$v=\sum \lambda_i e_i + \sum \mu_j f_j.$$
Первая сумма -- это вектор из $U_1$, а второй из $U_2$. Покажем единственность. Возьмём разложение, возможно отличное от того, которое получили: $v=u_1+u_2$. Разложим в свою очередь $u_1=\sum \lambda_i'e_i$, а $u_2=\sum \lambda_j' f_j$. Но тогда это даёт другое разложение $v$. Но разложение по базису единственно. Значит $\lambda_i=\lambda_i'$ и $\mu_j=\mu_j'$. Но тогда и разложения одинаковые.

\endproof



\section{Линейные отображения}

\dfn[Линейное отображение] Пусть $U,V$ -- два векторных пространства над полем $K$. Отображение $L\colon U \to V$ называется линейным, если\\
1) $\forall a,b \in U$ верно, что $L(a+b)=L(a)+L(b)$.\\
2) $\forall a \in U$, $\lambda \in K$ верно, что $L(\lambda a)=\lambda L(a)$.
\edfn



\exm\\
0) Пусть $U$ и $V$ два пространства. Тогда отображение $U \to V$ вида $x \to 0$ является линейным.\\
1) Пусть задана матрица $A \in M_{m\times n}(K)$. Тогда отображение $K^n \to K^m$, заданное как $x \to Ax$ линейно.\\
2) Пусть задан многочлен $p(x) \in K[x]$. Тогда отображение $K[x] \to K[x]$ $f(x)\to p(x)f(x)$ линейно.\\
3) Пусть $p(x) \in K[x]$ -- многочлен. Тогда отображение $K[x] \to K[x]$, заданное как  $f(x)\to f(p(x))$ линейно.\\
4) Предыдущая конструкция работает и в другом контексте. Пусть $g(x)\in C(\mb R)$. Тогда отображение $C(\mb R)\to C(\mb R)$ вида $f(x)\to f(g(x))$ является линейным.\\
5) Рассмотрим пространство непрерывных функций $C([0,1])$. Тогда отображение $f(x) \to \int_{0}^1 f(x)dx$ линейно  как отображение $C([0,1])\to \mb R$.\\
6) Пусть $V=U_1\oplus U_2$. Тогда отображение $pr_{U_1} \colon V \to U_1$ заданное правилом $v \to u_1$, где $v=u_1+u_2$ разложение в сумму элементов из  $U_1$ и $U_2$.\\


Линейное отображение -- частный случай гомоморфизма групп. Поэтому здесь возникают стандартные понятия:






\dfn[Ядро и образ] Пусть $L\colon U \to V$ -- линейное отображение. 
$$\Ker L=\{x\in U\,|\, Lx=0\}\subseteq U.$$
$$\Im L=\{y\in V\,|\, \exists x\in U\, Lx=y\}\subseteq V.$$
\edfn

\rm Линейное отображение, как частный случай гомоморфизма групп, инъективно тогда и только тогда, когда $\Ker L=\{0\}$.
\erm

Итак, благодаря примерам, мы поняли, что отображение $K^n \to K^m$, заданное с помощью матрицы $A$ это частный случай линейного отображения. Таким образом, решение системы линейных уравнений можно понимать как нахождение прообраза элемента при линейном отображении.

Сюръективность или инъективность такого линейного отображения имеет непосредственное отношение к вопросам о разрешимости системы линейных уравнений. А именно, система $Ax=y$ разрешима для любого $y$, тогда и только тогда, когда отображение $x\to Ax$ сюръективно. Так же, система $Ax=0$ имеет единственное решение в случае инъективности $x\to Ax$.

В дальнейшем мы увидим, что все вычисления с  линейными отображениями может быть сведено к матрицам. Тем самым, линейное отображение между пространствами столбцов есть  модель для всех задач про линейные отображения. Но прежде посмотрим, на общие качественные свойства линейных отображений.



\lm[Базовые свойства] Для линейных отображений имеют место следующие свойства:\\
0) Пусть $L$ -- линейное отображение. Тогда $L(0)=0$.\\
1) Пусть $L_1$ и $L_2$ -- два линейных отображения $U \to V$. Тогда $L_1+L_2$ -- их поточечная сумма -- тоже линейное отображение $U\to V$.\\
2) Пусть $\mu \in K$ и $L\colon U \to V$ -- линейное отображение. Тогда $\mu L$ -- тоже линейное отображение.\\
3) Пусть $L_1\colon V_1\to V_2$, а $L_2\colon V_2 \to V_3$. Тогда $L_1\circ L_2$ -- линейное отображение $V_1 \to V_3$.\\
4)  Выполнена дистрибутивность для композиции. А именно, если $L_1,L_2 \colon V \to W$, а $L_3 \colon W \to U$, то
$$ L_3 \circ (L_1+  L_2 ) =  (L_3 \circ L_1)+  (L_3 \circ L_2).$$
5) Так же, если $L_1 \colon V \to W$, а $L_2,L_3 \colon W \to U$,  то
$$( L_3+  L_2 ) \circ L_1 =  (L_3 \circ L_1)+ (L_2 \circ L_1).$$\\
6) Пусть $L\colon U \to V$. Тогда $\Ker L$ подпространство $U$, а $\Im L$ -- подпространство $V$.\\
7) Множество всех линейных отображений $\Hom(U,V)=\{ L\colon U \to V\,|\, L \text{ линейно}\}$ является векторным пространством.
\elm
\proof Упражнение. Отметим только, что доказательства пунктов 4) и 5) принципиально разные.
\endproof





Оказывается, что все линейные отображения устроены довольно просто.

\thrm
Пусть $V_1$, $V_2$ --- векторные пространства над полем $K$. Пусть $e_1,\dots,e_n$ - базис $V_1$, а $f_1,\dots,f_n$ --- набор каких-то векторов из $V_2$. Тогда существует единственное линейное отображение $L\colon V_1 \to V_2$, что $L(e_i)=f_i$. Более того, если вектор $v\in V_1$ раскладывается по базису $v=\sum \lambda_i e_i$, то $L(v)=\sum \lambda_i f_i$.
\ethrm
\proof Очевидно, что отображение должно быть задано  формулой $L(v)=\sum \lambda_i f_i$. и это показывает единственность.
Осталось показать, что указанная формула даёт линейное отображение. Действительно, если два вектора $u=\sum \lambda_i e_i$ и $v=\sum \mu_i e_i$, то $u+v= \sum (\lambda_i +\mu_i) e_i$ есть разложение для суммы. Осталось посчитать $L(u+v)$ и раскрыть скобки. Аналогично делается вычисление для $L(\lambda u)$.
\endproof


\crl
Все линейные отображения $L\colon K^n \to K^m$ имеют вид $L(x)=Ax$, где $A$ --- матрица $m\times n$
\proof Если задано линейное отображение $L$, то по нему определяется матрица $A$ составленная из столбцов $L(e_i)$, где $e_i$ -- это стандартный базис $K^n$. Тогда отображения $x \to L(x)$ и $x \to Ax$ оба переводят $e_i \to L(e_i)$, то есть совпадают на базисе и, значит, совпадают везде.
\endproof
\ecrl

\dfn Линейное отображение называется моно-, эпи- или изоморфизмом, если оно инъективно, сюръективно или биективно.
\edfn

\rm Если линейное отображение изоморфизм, то есть обратимо, то тогда обратное -- тоже изоморфизм.
\erm

\crl Если $L$ переводит некоторый базис $V$ в базис $W$, то $L$ обратимо. Обратно, если линейное отображение $L \colon V \to W$ является изоморфизмом, то $L$ переводит любой базис $V$ в базис $W$.
\proof
Пусть $e_1,\dots,e_n$ -- базис $V$ и $L(e_1),\dots,L(e_n)$ -- базис $W$. Тогда есть единственное линейное отображение $T \colon W \to V$, которое переводит $L(e_i)$ в $e_i$. Заметим, что композиция $T\circ L$ переводит $e_i \to e_i$. Тогда по единственности такая композиция тождественна. Аналогично композиция в другом порядке тождественна. Тогда $T$ -- обратное отображение к $L$.
 В другую сторону. Пусть $e_1,\dots,e_n$ -- базис $V$. Покажем, что $L(e_1),\dots,L(e_n)$ -- базис $W$.  Пусть есть линейная зависимость  $$0=\lambda_1 L(e_1)+\dots+\lambda_n L(e_n).$$
Тогда
$$0=L^{-1}(0)=L^{-1}(L(\lambda_1 e_1+\dots+\lambda_n e_n))=\lambda_1 e_1+\dots+\lambda_n e_n.$$
Тогда все $\lambda_i$ равны 0. Покажем, что $L(e_i)$ порождают $W$. Рассмотрим вектор $w\in W$. Тогда $$w=L(v)=L\left(\sum \lambda_i e_i\right)=\sum \lambda_i L(e_i).$$
\endproof
\ecrl

Это позволяет нам установить следующее

\crl Пусть $V$ -- конечномерное пространство размерности $n$. Пусть $f_1,\dots,f_n$ -- базис $V$. Тогда  отображение $V\to K^n$, сопоставляющее вектору его столбец координат в базисе $f$ линейно и обратимо. Более того, задание базиса равносильно заданию обратимого линейного отображения $V\to K^n$.
\proof
Рассмотрим пространство $K^n$ и его стандартный базис $e_1,\dots,e_n$. Тогда по теореме существует единственное  линейное отображение переводящее $f_i \to e_i$. Это отображение берёт вектор $v \in V$, раскладывает его как $v=\sum_{i=1}^n \lambda_i f_i$ и переводит его в столбец координат $\lambda_i$. То есть это и есть отображение из условия теоремы.

Обратно, если есть изоморфизм $L\colon V \to K^n$, то можно рассмотреть обратное отображение $L^{-1}$. Тогда $L^{-1}(e_i)$ -- это базис $V$.
\endproof
\ecrl




\dfn
Изоморфизм  $V \to K^n$ называется линейной системой координат на пространстве $V$. Мы знаем что любая линейная система координат происходит из некоторого базиса. Отображение, сопоставляющее вектору $v$ его $i$-ую координату, называется $i$-ой координатной функцией. 
\edfn



\exm(Дополнительно) \\
1) Линейное отображение $$\pmat x\\y\\z \epmat \to \pmat x+y+z\\ y+z\\z \epmat $$
является линейной системой координат на $\mb R^3$.  Какому базису эта система координат  соответствует?\\
2) А вот это -- система координат на $\mb R^2$, соответствующая  повёрнутому на угол $\ffi$ против часовой стрелки стандартному базису:
$$\pmat x\\ y \epmat \to \pmat \cos \ffi\, x + \sin \ffi\, y\\ -\sin\ffi\, x+ \cos \ffi\, y \epmat 
$$


Посмотрим на качественные характеристики линейных отображений. Самой важной такой характеристикой является ранг.





\dfn Рангом линейного отображения $L\colon V \to W$ называется размерность его образа $\rk L= \dim \im L$. Рангом матрицы $A\in M_{m\times n}(K)$ называется ранг соответствующего ей линейного отображения $K^n \to K^m$. Иными словами, ранг матрицы это размерность пространства, порождённого столбцами этой матрицы.
\edfn


\thrm[О подходящем выборе базиса]
Пусть $L\colon V \to W$ --- линейное отображение между конечномерными пространствами. Тогда существует $e_1,\dots,e_n$ -- базис $V$, такой что $e_1,\dots,e_k$ -- базис $\Ker L$, а $L(e_{k+1}),\dots,L(e_n)$ -- базис $\Im L$.
\ethrm
\proof Выберем $e_1,\dots, e_k$ -- базис $\Ker L$ и дополним его элементами $e_{k+1},\dots,e_n$ до базиса всего $V$. Я утверждаю, что $L(e_{k+1}),\dots,L(e_n))$ являются базисом образа. Действительно, образ $L$ порождён $L(e_1),\dots, L(e_n)$, но первые $k$ элементов этого набора нули. Поэтому их можно исключить, что означает, что $L(e_{k+1}), \dots, L(e_n)$ порождают образ $L$.

Пусть сумма $\sum_{i=k+1}^n \lambda_i L(e_i)=0$. Тогда элемент $\sum_{i=k+1}^n \lambda_i e_i $ лежит в ядре $L$. Отсюда получаем, что имеет место равенство $$\sum_{i=k+1}^n \lambda_ie_i = \sum_{i=1}^k \lambda_i e_i$$
которое приводит к нулевой линейной комбинации всех $e_i$. Но $e_i$ -- базис $V$ и поэтому все коэффициенты, в частности, $\lambda_i$ при $i\geq k+1$ равны нулю.
\endproof

\crl Пусть $L\colon V \to W$ --- линейное отображение между конечномерными пространствами. Тогда
$$\dim V= \dim \Ker L +  \dim \im L= \dim \Ker L +\rk L.$$
\ecrl
\proof В обозначениях предыдущей теоремы размерность ядра равна $k$, размерность образа равна $n-k$, что в сумме и даёт $n$.
\endproof



\crl[Принцип Дирихле для линейных отображений] Пусть $V$ и $W$ два пространства размерности $n$ и $L \colon V \to W$ -- линейное отображение между ними. Тогда $L$ -- сюръективно тогда и только тогда, когда $L$ -- инъективно.
\ecrl

\thrm Любое подпространство $U\leq K^n$ коразмерности $d$ задаётся $d$ уравнениями. При этом меньшим числом уравнений задать $U$ нельзя. 
\ethrm
\proof 
Пусть $e_1,\dots,e_k$ -- базис $U$. Здесь $k=n-d$. Дополним его до базиса всего пространства $K^n$ векторами $e_{k+1},\dots,e_n$. Рассмотрим такое отображение $L\colon K^n \to K^d$, что $L(e_i)=0$, если $i\leq k$ и $L(e_i)=f_{i-k} \in K^d$, где $f_j$ -- $j$-ый стандартный базисный вектор.

Тогда $U=\Ker L$. Но $L$ представляется в виде $L(x)=Ax$ для матрицы $A\in M_{d\times n}(K)$. Тогда вектора из $U$ есть в точности решения системы $Ax=0$. 
\endproof

\rm Меньшим числом уравнений задать подпространство нельзя. В самом деле, если $d<\codim U$, и $U=\{ x\in K^n\,|\, Ax=0\}$ где $A\in M_{d\times n}$, то $\dim \Ker A\geq n- d > \dim U$. Противоречие.
\erm


\subsection{Число параметров в методе Гаусса}

Как мы уже выяснили, множество решений системы $Ax=b$ либо пусто, либо имеет вид $x_0 + \Ker A$, где $x_0$ -- некоторое решение.

В свою очередь, множество всех решений описывается при помощи метода Гаусса. В качестве ответа даётся формула, которая по произвольному набору параметров -- независимых переменных -- восстанавливает значения остальных переменных линейным образом. Качественная характеристика такой системы -- это число параметров, при помощи которых описываются все её решения. Нам надо показать, что это число параметров не зависит от хода метода Гаусса и от возможной замены переменных. Сделаем это следующим образом:

\thrm Пусть дана система линейных уравнений $Ax=b$ с матрицей $A\in M_{m\times n}(K)$ и непустым множеством решений. Тогда число параметров, задающих общее решение системы после использования метода Гаусса, равно $\dim \Ker A$.
\ethrm
\proof Пусть независимые переменные в методе Гаусса это $x_{i_1}, \dots,x_{i_s}$.
Заметим, что номера независимых переменных при решении однородной системы $Ax=0$ такие же, как и для системы $Ax=b$. Поэтому можем смотреть на однородную систему.

В случае однородной системы зависимые переменные  выражаются линейно через независимые в виде
$$x_i= \sum c_{ij} x_{i_j}, \text{ при всех} i \notin \{i_1,\dots, i_k\}.$$
Сопоставление набору $(x_{i_1},\dots, x_{i_s})$, решения системы $Ax=0$, задаёт линейное отображение $K^s \to K^n$. Точнее, это отображение есть взаимооднозначное линейное отображение $K^s \to \Ker A$, то есть изоморфизм. Следовательно, $\dim \Ker A = s$, что и есть число параметров.
\endproof




Если мы хотим найти все решения системы $Ax=b$, то, прежде всего, для этого нужно найти частное решение $x_0$. Для этого надо решить систему методом Гаусса и подставить конкретные значения для свободных переменных. Проще всего подставить $x_{i_1}=\dots=x_{i_s}=0$. Любое решение имеет вид $x_0+\Ker A$.
Теперь надо описать ядро $A$. Конкретно, нас будет интересовать  базис $\Ker A$. Заметим, что рассмотренное в доказательстве отображение $K^s \to \Ker A$ есть изоморфизм. При изоморфизме базис переходит в базис, следовательно взяв стандартный базис $K^s$ в качестве его образов получим базис ядра.

\subsection{Дополнительно: пример}
Пусть $$A=\pmat
1 & 2 & -1 & 2\\
0& 1& 0 & 1\\
1& 0 & -1 & 0\epmat, \,\,b= \pmat -1\\ -1\\ 1 \epmat.$$
Решаем систему
$$\pmat
1 & 2 & -1 & 2 & -1\\
0& 1& 0 & 1 & -1\\
1& 0 & -1 & 0 & 1\epmat \sim
\pmat 1& 0 & -1 & 0 & 1 \\
0& 1& 0 & 1 & -1\\
0 & 2 & 0 & 2 & -2
\epmat \sim \pmat 1& 0 & -1 & 0 & 1 \\
0& 1& 0 & 1 & -1\\
0 & 0 & 0& 0 & 0
\epmat.$$
Параметра два -- это $x_3,x_4$. Берём $x_3=x_4=0$. Тогда $x_2=-1$, $x_1=1$. Итого получаем частное решение $$v_0=\pmat 1\\ -1\\0 \\ 0 \epmat.$$
Ищем базис ядра. Для этого переходим к однородной системе. 
$$\pmat
1& 0 & -1 & 0 & 0 \\
0& 1& 0 & 1 & 0\\
0 & 0 & 0& 0 & 0
\epmat.$$
Подставляем стандартные вектора из $K^2$. Берём $x_3=1$, $x_4=0$. Тогда $x_2=0,x_1=1$. Берём $x_3=0$, $x_4=1$. Тогда $x_1=0,x_2=-1$. Итого базис состоит из двух векторов
$$v_1=\pmat 1\\0\\1\\0 \epmat, \, v_2=\pmat 0 \\ -1 \\ 0 \\ 1 \epmat.$$
Общее решение описывается как
$$\pmat 1\\ -1\\0 \\ 0 \epmat+ \lan \pmat 1\\0\\1\\0 \epmat, \pmat 0 \\ -1 \\ 0 \\ 1 \epmat \ran.$$


При рассмотрениях выше мы столкнулись с двумя разными заданиями подпространств в пространстве столбцов -- параметрическим, $U=\lan u_1,\dots, u_k \ran$, где по набору параметров $\lambda_1,\dots,\lambda_k$ легко построить вектор из $U$ взяв $\lambda_1 u_1+\dots+\lambda_k u_k$.

Другой способ -- это задание подпространства уравнениями $U=\Ker A = \{ x\in K^n \,|\, Ax=0\}$. При таком подходе очень легко проверить, что данный вектор лежит или не лежит в подпространстве. Достаточно вычислить $
Ax$ и сравнить с нулём. Только что мы показали, как от задания подпространства уравнениями перейти к заданию этого подпространства параметрически. 

В свою очередь, мы знаем, что есть и обратный переход -- подпространство коразмерности $d$ задаётся $d$ уравнениями. 


\section{Матрица линейного отображения}


Итак, у нас есть модельная задача: пусть $A \colon K^n \to K^m$ линейное отображение и элемент $y \in K^m$. Если нужно описать все прообразы элемента $y$, то это равносильно решению системы линейных уравнений $Ax=y$. Про эту задачу мы много понимаем всё.
Наша текущая задача -- научиться сводить задачу про общее линейное отображение к этой модельной. Однако тут возникает нюанс -- это можно сделать разными способами. Точнее:

\dfn
Пусть $V_1$, $V_2$ - векторные пространства над полем $K$ с базисами $e_1,\dots, e_n$ и $f_1,\dots, f_m$ соответственно. Пусть $L\colon V_1\to V_2$ - линейное отображение. Составим матрицу $A$, такую, что её $i$-ый столбец состоит из координат $L(e_i)$ в базисе $f$. Такая матрица называется матрицей линейного отображения $L$ в базисах $e$ и $f$. Будем обозначать её как $[L]^e_f$.
\edfn




\thrm Пусть $L \colon V_1 \to V_2$ -- линейное отображение, а $e$ и $f$ -- базисы  $V_1$  и $V_2$. Тогда матрица отображения $L$ -- это единственная такая матрица $A$, что $Ax=y$, где $x$ -- координаты вектора $v\in V_1$, а $y$ -- координаты его образа в $V_2$.
\ethrm
\proof Пусть $A$ -- это матрица $L$ в соответствующих базисах. Пусть $u=x_1e_1+\dots+x_ne_n$. Тогда $L u =x_1Le_1+\dots+x_n Le_n$. Тогда координаты $[Lu]_f$  вычисляются как $x_1[Le_1]_f+\dots+x_n[Le_n]_f$. Но это и есть $Ax$.
Обратно, если взять $u=e_i$, то координатный столбец $u$ будет равен $i$-ому стандартному столбцу и $[Le_i]_f=Ax$ будет как раз $i$-ым столбцом $A$.
\endproof


\utv Пусть $L_1,L_2\colon U \to V$ и $e$ -- базис $U$, а $f$ -- базис $V$. Тогда матрица $L_1+L_2$ в базисах $e$ и $f$ есть сумма матриц $L_1$ и $L_2$. Аналогично про домножение на скаляр.
\eutv
\proof Пусть $L_1 e_j= \sum A_{ij}f_i$, а $L_2=\sum B_{ij}f_i$. Тогда $L_1(e_j)+L_2(e_j)=\sum (A_{ij}+B_{ij})f_i$, что и доказывает требуемое.
\endproof

\crl Пусть пространства $U$ и $V$ имеют размерности $n$ и $m$. Допустим выбраны базисы $e_1,\dots,e_n$ и $f_1,\dots,f_m$ пространств $U$ и $V$ соответственно. Тогда сопоставление линейному отображению $L \in \Hom(U,V)$ его матрицы в указанных базисах есть изоморфизм
$$\Hom(U,V) \stackrel{\sim}{\longrightarrow} M_{m\times n}(K).$$
\ecrl





Пусть есть две матрицы $A\in M_{n\times m}(K)$ и $B\in M_{m\times l}(K)$. Какая матрица соответствует композиции линейных отображений, построенных по $A$ и $B$?



\thrm Пусть $U$, $V$, $W$ пространства с базисами $e_1,\dots,e_n$, $f_1,\dots,f_m$, $g_1,\dots,g_l$. Пусть $L_1\colon U \to V$ и $L_2\colon V \to W$ два линейных отображения. Пусть $A$ и $B$ матрицы $L_1$ и $L_2$ в парах базисов $e$, $f$  и $f$, $g$. Тогда матрица $L_2 \circ L_1$ в базисах $e$, $g$ равна произведению $BA$.
\ethrm
\proof Пусть $u\in U$, а $x$ -- его столбец координат. Подействовав последовательно на $x$ сначала $A$ и затем $B$ получим столбец координат образа $u$ под действием $L_2\circ L_1$ с одной стороны, а с другой -- столбец $B(Ax)$.  По ассоциативности произведения матриц имеем $$B(Ax)=(BA)x$$
Таким образом, домножение на матрицу $BA$ переводит координаты вектора $u$ в координаты его образа относительно $L_2 \circ L_1$. Но это и значит, что $BA$ есть матрица композиции.
\endproof




Какая матрица соответствует обратимому линейному отображению? 



\dfn Матрица $A \in M_{m\times n}$ называется обратимой, если существует $B \in M_{n\times m}$, что $AB=E_m$, $BA=E_n$.  Матрица $B$ называется обратной к $A$ и обозначается $A^{-1}$.
\edfn

\crl Если матрица $A \in M_{n\times m}$ обратима, то $n=m$. Обратная матрица единственна.
\proof Обратимая матрица осуществляет изоморфизм пространства $K^n$ и $K^m$.  Но если пространства изоморфны, то их размерности равны, то есть $n=m$. Обратное к биективному отображению единственно и, следовательно, единственна матрица, его задающая.
\endproof
\ecrl


\crl Матрица $A \in M_n(K)$  обратима тогда и только тогда, когда $\rk A=n$. Ещё такие матрицы называют невырожденными.
\ecrl
\proof Следует из принципа Дирихле для линейных отображений.
\endproof

\rm Если матрицы $A,B\in M_n(K)$ обратимы, то $AB$ -- тоже обратима и $(AB)^{-1}=B^{-1}A^{-1}$.
\erm

Знание обратной матрицы может помочь при решении системы линейных уравнений. А именно, если $A$ -- обратима, то тогда решение системы $Ax=b$ может быть найдено по правилу $x=A^{-1}b$.

Как найти обратную матрицу? В принципе, можно написать условие $AB=E_n$ и найти матрицу $B$, удовлетворяющую этому условию. Это система линейных уравнений на коэффициенты матрицы $B$. Однако, решать систему  относительно $n^2$ переменных не греет нам душу. 

Чтобы упростить жизнь вспомним посмотрим как найти столбец матрицы $B=A^{-1}$. Если $e_1,\dots,e_n$ -- это стандартный  базис $K^n$, то $u_i=Be_i$ и есть $i$-ый столбец $B$. Но это же равенство можно переписать как $Au_i=e_i$. Таким образом, для того, чтобы найти $u_i$ нужно решить систему уравнений с матрицей $A$. 

При решении такой системы методом Гаусса последовательность преобразований зависит от матрицы $A$. Значит все эти системы можно решать одновременно. А именно, возьмём матрицу $n\times 2n$ вида $(A|E_n)$. Приведём её при помощи элементарных преобразований к виду $(E_n|B)$. Тогда $B=A^{-1}$. Этот метод принято называть методом Гаусса-Жордана.



\subsection{Замена координат}


В одном и том же пространстве $U$ можно выбрать разные базисы и, соответственно, получаются разные системы координат. Как пересчитать координаты вектора из одной системы координат в другую?  Как меняются координаты вектора при переходе из одного базиса в другой?

Пусть на пространстве $U$ заданы два базиса $e$  и $f$. Рассмотрим $\id_U \colon U \to U$. Что даёт его матрица в базисах $e$  и $f$? По характеристическому свойству это такая матрица $A$, что $Ax=y$, где $x$ -- это координаты вектора $u$ в базисе $e$, а $y$ -- это координаты того же вектора в базисе $f$.

\dfn Рассмотрим пространство $V$ размерности $n$ и два базиса $e_1,\dots,e_n$ -- старый и $f_1,\dots,f_n$ -- новый. Тогда матрицу 
$[\id_U]^e_f$ назовём матрицей замены координат из базиса $e$ в базис $f$. Она пересчитывает координаты вектора из старого базиса в новый.

В том же контексте есть другое, похожее определение. Матрица $C_{e\to f}=[\id_V]^f_e$  называется матрицей перехода из базиса $e$ в базис $f$.
\edfn

Стандартным определением является именно матрица перехода. В чём причина? Оказывается матрицу перехода часто проще искать. Действительно, как найти матрицу $C_{e\to f}$? Для этого нужно взять элементы $f_i$, расписать их $f_j = \sum_{i=1}^n c_{ij} e_i$ через базис $e$, взять их координатные столбцы в базисе $e$ и составить из них матрицу. Это иногда записывают как 
$$(f_1,\dots,f_n)=(e_1,\dots,e_n)C_{e\to f}.$$ 

В одной из самых распространённых ситуаций, когда $e_1,\dots, e_n$ -- это стандартный базис $K^n$, а $f_1,\dots, f_n$ -- какой-то другой базис матрица перехода $C_{e\to f}$ просто составлена из столбцов $f_1,\dots,f_n$.




\rm Для матриц перехода выполнены следующие свойства:\\
1) $C_{e\to e}=E_n$\\
2) $C_{e\to f}C_{f\to g} = C_{e \to g}$\\
3) $C_{f\to e}=C_{e\to f}^{-1}$.
\erm


Теперь можно разобраться с тем, как меняется матрица линейного отображения при замене базиса.  




\thrm Пусть даны пространства $U$, $V$ и линейное отображение $L\colon U\to V$. Рассмотрим в пространстве $U$ два базиса $e_1,\dots, e_n$ (старый) и $e_1',\dots, e_n'$ (новый). Аналогично в $V$ --- $f_1,\dots, f_m$ (старый) и $f_1',\dots, f_m'$ (новый).
Пусть  $A$ -- матрица $[L]^e_f$ и $A'=[L]^{e'}_{f'}$. Тогда 
$$A'=C^{-1}AD,$$
где $C$ -- матрица перехода $f\to f'$, а $D$ -- матрица перехода $e\to e'$
\ethrm
\proof Посмотрим на равенство $L=\id_V \circ L \circ \id_U$. Тогда вычисляя матрицу композиции получаем
$$A'=[L]^{e'}_{f'}=[\id_V]_{f'}^{f}\, [L]_{f}^{e}\,[\id_U]_e^{e'}=C^{-1}AD,$$
что и требовалось.
\endproof



\thrm[Канонический вид матрицы линейного отображения] Пусть $L\colon U \to V$. Тогда существуют такие базис $e_1,\dots,e_n$ в $U$ и  $f_1,\dots,f_m$ в $V$, что матрица линейного отображения $L$ в этих базисах имеет вид 
$$\pmat E_r& 0\\
0&0\\
\epmat .$$
\ethrm
\proof
По теореме о подходящем выборе базиса  существует $e$ -- такой базис $U$, что $f_1=L e_1,\dots,f_r=L e_r$ -- это базис $\Im L$ и $e_{r+1},\dots,e_n$ -- базис $\Ker L$. Дополним набор $f_1,\dots,f_r$ до базиса $V$ элементами $f_{r+1},\dots,f_m$.  Посмотрим на матрицу отображения $L$ в этих базисах. Это в точности матрица  
$$\pmat E_r& 0\\
0&0\\
\epmat.$$
\endproof




\crl Для любой матрицы $A \in M_{m \times n}$ ранга $r$ существуют обратимые матрицы $C\in M_m(K)$ и $D\in M_n(K)$, что 
$$A=C\pmat E_r& 0\\
0&0\\
\epmat D.$$
\proof 
По предыдущей теореме, применённой к отображению $Lx =Ax$ есть $e$ -- базис $K^n$ и $f$ -- базис $K^m$, что матрица $L$ имеет вид  $$\pmat E_r& 0\\
0&0\\
\epmat.$$
Тогда по теореме о замене координат получаем, что 
$$A=C \pmat E_r& 0\\
0&0\\
\epmat D$$
где $C$ -- матрица перехода из стандартного базиса в $f$, а $D$ -- матрица перехода из $e$ в стандартный базис.
\endproof
\ecrl

\crl[Ранговое разложение] Для любой матрицы $A\in M_{m\times n}(K)$ ранга $r$ существуют матрицы $T\in M_{m\times r}$ и $S\in M_{r\times n}(K)$, что $A=TS$.
\proof 
Представим $A$ в виде $$A=C \pmat E_r& 0\\
0&0\\
\epmat D$$
Заметим, что  $$\pmat E_r& 0\\
0&0\\
\epmat =\pmat E_r\\
0\\
\epmat \pmat E_r& 0\\
\epmat.$$
Тогда 
$$A=C 
\pmat E_r\\
0\\
\epmat 
\pmat E_r& 0
\epmat D= TS, \,\text{ где }\, T=C 
\pmat E_r\\
0 \epmat \text{ и }  S=\pmat E_r& 0\\
\epmat D.$$

\endproof
\ecrl















\section{Свойства ранга}
Ранг линейного отображения $L$ отвечает за его обратимость и за размерность множества решений уравнения $Lx=y$. Ранг линейного отображения совпадает с рангом его матрицы при любом выборе базисов. Ранг линейного отображения есть единственный инвариант линейного отображения с точностью до замены координат. Наша задача посмотреть на базовые свойства, которыми обладает ранг. Прежде всего разберёмся, как оценить ранг суммы линейных отображений.


\utv Пусть $L_1, L_2 \colon U \to V$. Тогда $\rk (L_1 + L_2) \leq \rk L_1 + \rk L_2.$
\eutv
\proof Заметим, что $\Im(L_1 + L_2) \subseteq \Im L_1 + \Im L_2$. Тогда 
$$\rk (L_1 + L_2) =\dim \Im(L_1 + L_2) \leq \dim(\Im L_1 + \Im L_2) \leq \dim\Im L_1 + \dim\Im L_2 = \rk L_1 + \rk L_2.$$
\endproof

Разберёмся с оценкой на ранг композиции линейных отображений.

\utv Пусть $S \colon V \to W$, $T \colon W \to U$ -- линейные отображения. Тогда
$$\rk (T \circ S) \leq \min(\rk T, \rk S).$$
\eutv 
Необходимо доказать два неравенства. Для начала покажем, что если есть $L\colon V_1 \to V_2$ и $V' \leq V_1$, то $\dim L(V') \leq \dim V'$. Действительно $$\dim V'= \dim \im L|_{V'} + \dim \Ker L|_{V'} \geq \dim L(V').$$
Теперь $\im T \circ S \subseteq  \im T$, поэтому $\rk T \circ S \leq \rk T$.
Наконец $$\rk T \circ S= \dim \im T \circ S = \dim T (S(V)) \leq \dim S(V)= \rk S.$$
\endproof


\crl Пусть даны линейные отображения $U \stackrel{T}{\to} V \stackrel{L}{\to} W \stackrel{S}{\to} U'$, причём отображения $S$ и $T$ -- обратимые. Тогда $\rk SLT=\rk L$.
\ecrl
\proof С одной стороны ясно, что $\rk SLT \leq \rk LT \leq \rk L.$ С другой стороны $$\rk L = \rk S^{-1}SLTT^{-1} \leq \rk SLT,$$ что и требовалось.
\endproof







Однако, в методе Гаусса удобнее смотреть на строчки, чем на столбцы. Это замечание приводит нас к определению строчного ранга.

\dfn Пусть $A\in M_{m\times n}(K)$. Определим $\rk_{row}$ -- строчный ранг матрицы $A$ как размерность пространства, порождённого её строками.
\edfn

\dfn Пусть  $A\in M_{m\times n}(K)$. Определим матрицу $A^{\top}\in M_{n\times m}(K)$ как $A^{\top}_{ij}=A_{ji}$.
\edfn

\rm Очевидно равенство $\rk_{row} A= \rk A^{\top}$.
\erm

Поэтому посмотрим на свойства операции транспонирования матрицы.

\lm Пусть $A,B$ -- матрицы. Тогда\\
0) ${A^{\top}}^{\top}=A$.\\
1) $(A+\lambda B)^{\top}= A^{\top}+\lambda B^{\top}$.\\
2) $(AB)^{\top}=B^{\top}A^{\top}$.\\
3) $(A^{\top})^{-1}= (A^{-1})^{\top}$.
\elm
\proof Покажем, например, второй пункт. Имеем
$$(AB)^{\top}_{ij}= (AB)_{ji}=\sum_k A_{jk}B_{ki}=\sum_k B^{\top}_{ik}A^{\top}_{kj}=(B^{\top}A^{\top})_{ij}.$$
Теперь покажем пункт 3. Пусть $AA^{-1}=E_n$. Тогда $E_n=E_n^{\top}=(AA^{-1})^{\top}= (A^{-1})^{\top}A^{\top}$. Аналогично из равенства $A^{-1}A=E_n$ следует $E_n=A^{\top}(A^{-1})^{\top}$, что завершает доказательство.
\endproof

\rm Заметим, что, вообще говоря, проверять второе условие не обязательно.
\erm

\thrm Пусть $A\in M_{m \times n}(K)$. Тогда ранг по строчкам и ранг по столбцам совпадают.
\ethrm
\proof Представим матрицу $A$ в виде произведения
$$A=C \pmat E_r & 0\\
0 & 0 \epmat D,$$
где $C \in M_m(K)$, а $D \in M_n(K)$ -- обратимы, а $r$ -- ранг матрицы. Тогда
$$A^{\top}=D^{\top} \pmat E_r & 0\\
0 & 0 \epmat C^{\top}.$$
Так как ранг не меняется при домножении на обратимые матрицы, то $\rk A^{\top} = \rk \pmat E_r & 0\\
0 & 0 \epmat = r = \rk A$.
\endproof


Приведём пример использования свойства ранга. Для этого посмотрим на пример с поисковой системой. Пусть $G$ граф на $n$ вершинах. Тогда рассмотрим квадратную матрицу $P(G)$ размера $n$
$$P(G)_{ij}= \begin{cases} \frac{1}{d_j^{out}}, \text{ если есть ребро $j \to i$} \\
1, \text{ если $i=j$ и из вершины $i$ нет исходящих рёбер}\\
0, \text{ иначе }
\end{cases}.$$
Эта матрицу еще называется матрицей случайного блуждания на графе $G$. Смысл состоит в том, что она моделирует следующую ситуацию -- если мы с вероятностями $w_1,\dots,w_n$ находимся в вершинах графа и на следующем шаге хотим из $j$-ой вершины перейти в $i$-ую по ребру графа, при этом проход по каждому ребру равновероятен, то после такого действия новый набор вероятностей будет иметь вид $P(G)w$. Матрица $P$ обладает тем свойством, что сумма элементов в каждом столбце равна 1.

Теперь систему для нахождения <<важностей>> вершин графа можно переписать в виде $E_n w= P(G)w$ или
$$(E_n - P(G))w=0.$$
Нам хочется показать, что у этой системы есть нетривиальное решение, то есть, что ранг матрицы $E_n- P(G)$ строго меньше $n$. Для этого можно показать, что ранг
$$E_n - P(G)^{\top}$$
меньше $n$, а это легко сделать -- достаточно заметить, что матрица $E_n - P(G)^{\top}$  имеет столбец $(1,1,\dots, 1)^{\top}$ в своём ядре. Заметьте -- это не помогает найти решение исходной системы, а лишь доказывает его существование.



\section{Матрицы специального вида и $LUP$ разложение}


При решении систем линейных уравнений методом Гаусса нам пригодились элементарные преобразования. Покажем, что они не влияют на ранг матрицы.

Для этого покажем, что элементарное преобразование можно реализовать домножив исходную матрицу на некоторую обратимую матрицу. Точнее, рассмотрим матрицу
$$ E_{ij}(\lambda)=E_n +\lambda e_{ij}=
\bordermatrix{
 & &j&& \cr
 &1&\cdots&\cdots&0\cr
 &\vdots&\ddots && \vdots\cr
i&\vdots& \lambda & \ddots& \vdots\cr
 &0&\cdots& \cdots&1
}.
$$\\
Домножение на матрицу $E_{ij}(\lambda)$ приводит к тому, что матрица
$$A'=E_{ij}(\lambda)A.$$
получается из матрицы $A$ прибавлением $j$-ой строки к $i$-ой с коэффициентом $\lambda$.
Действительно, домножение матрицы $A$ на матрицу $e_{ij}$ выделяет из матрицы $A$ $j$-ую строку и записывает её в строку с номером $i$.

\dfn Матрица $E_{ij}(\lambda)$ называется матрицей элементарного преобразований первого типа или просто элементарной матрицей.
\edfn

Что соответствует замене местами двух строк матрицы $A$? Для этого надо поставить $i$-ую строчку в позицию $j$ и наоборот, а остальные строки оставить на месте. Итого имеем матрицу
$$P_{(ij)}=\,\bordermatrix{
 & & &j& & i& \cr
 &1& & & & & &0\cr
 & &\ddots & & & & \cr
j\,& && 0 & & 1 & &\cr
\,& &&  & &  & &\cr
i\,& && 1 & &0 & &\cr
 & & & & & & \ddots& \cr
 &0& & & & & &1
}
$$


\dfn Матрица $P_{(ij)}$ называется матрицей элементарного преобразований второго типа или матрицей транспозиции.
\edfn

А что вообще происходит при перестановке строк? Каждой перестановке $\sigma \in S_n$ однозначно соответствует матрица $P_{\sigma}$ заданная правилом
$$(P_{\sigma})_{ij}= \begin{cases}
1, \text{ если $\sigma(j)=i$}\\
0, \text{ иначе }
\end{cases}.$$


\dfn Матрица $P_{\sigma}$ называется матрицей перестановки $\sigma$.
\edfn


\rm Заметим, что произведение $P_{\sigma} P_{\tau}=P_{\sigma\tau}$.  Любая матрица, у которой в каждом столбце ровно один единичный элемент, а все остальные 0 является матрицей перестановки.
\erm

Наконец, преобразованию третьего типа соответствует матрица
$$ D_{i}(\lambda)=
\bordermatrix{
 & &&i&& \cr
 &1&&&&0\cr
 &&\ddots &&& \cr
i&&  & \lambda && \cr
&&  &  &\ddots& \cr
 &0&& &&1
}.
$$

\dfn Матрица $D_{i}(\lambda)$, $\lambda \in K^*$ называется матрицей элементарного преобразований третьего типа.
\edfn

\rm Так выглядят обратные к этим матрицам\\
1) $E_{ij}^{-1}(\lambda)= E_{ij}(-\lambda)$,\\
2) $D_i^{-1}(\lambda)= D_i(\lambda^{-1})$,\\
3) $P_{\sigma}^{-1}=P_{\sigma^{-1}}$. В частности, $P_{(ij)}^{-1}=P_{(ij)}$.
\erm






Композиция элементарных преобразований, это конечно не элементарное преобразование, но можно кое-что заметить:

\dfn Пусть $A \in M_{n}(K)$. Тогда матрица $A$ называется нижнетреугольной, если $\forall  i<j$, то $A_{ij}=0$. Аналогично определяются верхнетреугольные матрицы. 
\edfn

\dfn Множество всех верхнетреугольных матриц размера $n$ обозначается как $UT_n(K)$, а нижнетреугольных $LT_n(K)$. 
\edfn

\rm Матрица $E_{ij}(\lambda)$ является верхнетреугольной, если $i<j$ и нижней унитреугольной если $i>j$. 
\erm

\lm  Пусть $A,B \in LT_n(K)$. Тогда\\
1) $A+B \in LT_n(K)$\\
2) $\lambda A \in LT_n(K)$ где $\lambda \in K$.\\
3) $AB \in LT_n(K)$.\\
4) $A^{-1} \in LT_n(K)$, если $A$ -- обратима.\\
Аналогично для верхнетреугольных матриц.
\proof[Первое доказательство] Свойства 1) и 2) легко проверяются. Свойство 3) проверяется непосредственно. Покажем свойство 4). Пусть $A$ -- обратимая нижнетреугольная матрица. Тогда на диагонали $A$ стоят ненулевые элементы $d_1,\dots,d_n$. Заметим теперь, что все преобразования в методе Гаусса будут иметь вид $E_{ij}(\lambda)$, где $i<j$. Это означает, что не будет использоваться перестановки  строк, элементы на диагонали не изменятся, а наддиагональные элементы останутся нулевыми. В свою очередь матрицы $E_{ij}(\lambda)$ будут нижнетреугольными. Метод Гаусса приведёт матрицу $A$ к виду $$D=\pmat d_1 &&\\
&\ddots & \\
&& d_n \epmat.$$ 
Это означает, что 
$$ L_1\dots L_k A =D,$$
где $L_i$ -- матрицы указанных элементарных преобразований. Но тогда 
$$A^{-1}=(L_k^{-1}\dots L_1^{-1}D)^{-1}=D^{-1}L_1\dots L_k.$$
Следовательно, $A^{-1}$ -- нижнетреугольная, как произведение нижнетреугольных матриц. 
\endproof
\proof[Второе доказательство] Как и раньше на диагонали $A$ стоят ненулевые элементы $d_1,\dots,d_n$. Рассмотрим диагональную матрицу $D$ с $d_1,\dots, d_n$ на диагонали. Определим $B=D^{-1}A$. Это нижнетреугольная матрица с единицами на диагонали. Тогда $B=E_n+N$, где 
$$ N=\pmat 
0&&&\\
*&0&&\\
\vdots&\ddots&\ddots&\\
*&\dots & *&0
\epmat.$$
Заметим, что $N^n=0$. Действительно, верно, что $Ne_n=0$ и $Ne_i \in \lan e_{i+1},\dots,e_n\ran$. Отсюда применяя $n-1$ раз матрицу $N$ к любому вектору мы скатываемся в $\lan e_n \ran$ откуда благополучно отправляемся в $0$. Тогда заметим, что
$${B}^{-1}=E_n-N+N^2-N^3+\dots+ (-1)^{n-1}N^{n-1}$$
является нижнетреугольной. Значит и обратная к $A$ является нижнетреугольной.
\endproof
\elm

Обращение верхнетреугольных и нижнетреугольных матриц проводится за $O(n^2)$ операций. Это обстоятельство означает, что решать систему линейных уравнений $Lx=b$ для, например, нижнетреугольной матрицы $L$ довольно легко. Это можно использовать и для решения произвольных систем при помощи следующей теоремы.


\thrm[$LUP$ разложение] Пусть $A \in M_{n}(K)$ -- обратимая матрица. Тогда существует  две обратимые матрицы $L \in LT_{n}(K)$ -- нижняя треугольная с единицами на диагонали, $U\in UT_n(K)$ и матрица перестановки $P$, что 
$$PA=LU.$$ 
\ethrm
\proof Предъявим алгоритм построения такого разложения. После шага $k$ будем предполагать, что построена матрица $L\in LT_n$ с единицами на диагонали и нулями под диагональю в столбцах с номерами начиная с $k+1$; матрица $U$ -- блочная верхнетреугольная, причём верхний блок $k\times k$ -- верхнетреугольный
$$L=\,\bordermatrix{
& & &k&k+1 & \cr
&1& & & & &\cr
&*&\ddots & & && \cr
k&\vdots &\ddots& 1 &  & &\cr
&\vdots && *      &1 & &\cr
&\vdots && \vdots & & \ddots& \cr
&*&\dots & *& & &1
} \text{ и }
U=\,\bordermatrix{
& & &k&k+1 & \cr
&*&\dots &\dots &\dots &\dots &*\cr
&0&\ddots & & &&\vdots \cr
&\vdots &\ddots& * &  & &\vdots\cr
&\vdots && 0 &* & &\vdots\cr
&\vdots && \vdots &\vdots & &\vdots \cr
&0& \dots&0 &* &\dots &*
};$$
и матрица перестановки $P$, такие что 
$$L^{-1}PA=U.$$
При таких условиях матрица $U$, необходимо, невырождена. Попробуем произвести шаг алгоритма. Если элемент $U_{k+1,k+1}\neq 0$, то $k+1$ строчку можно прибавить к нижним с тем, чтобы элементы $U_{i,k+1}$ занулились при $i>k+1$. Это элементарные преобразования строк и они эквивалентны домножению на элементарные матрицы. Назовём эти матрицы $L_i$. Посмотрим, что происходит при отдельном элементарном преобразовании. Домножим равенство $L^{-1}PA=U$ на $L_i$ 
$$L_iL^{-1}PA=L_i U.$$
В правой части появился дополнительный ноль в $i$-ой позиции $k+1$-го столбца. В то же время $L_iL^{-1}=(LL_i^{-1})^{-1}$. Откуда видим, что матрица $LL_i^{-1}$ играет роль $L$. Заметим, что $L_i^{-1}$ -- нижнетреугольная и, следовательно, произведение $LL_i^{-1}$ -- тоже. Осталось заметить, что у $LL_i^{-1}$ добавились нули лишь в $k+1$ столбце. Но домножение на матрицу  $L_i^{-1}=E_{j,k+1}(\lambda)$ справа прибавляет к столбцу $k+1$ столбец $i$ c коэффициентом $\lambda$. Так как $i$-ый столбец содержит единственный ненулевой элемент на позиции $i$,то такое преобразование запишет  $\lambda$ вместо нуля на позиции $i$ в столбце $k+1$.
Применив все преобразования $L_i$ получим новые подходящие матрицы $L,U$.

Осталось разобрать ситуацию, когда $U_{k+1,k+1}=0$. В этом случае, благодаря невырожденности матрицы $U$ найдётся такое $i$, что элемент $U_{i,k+1}\neq 0$. Переставим строчку $i$ и строчку $k+1$ местами. Это происходит при помощи домножения на матрицу перестановки $P_i$. Посмотрим, как поменяются матрицы $L,U,P$ при таком преобразовании. Домножим на $P_i$ основное соотношение. 
$$P_iU=P_iL^{-1}PA=P_iL^{-1}P_i(P_iP)A=(P_iLP_i)^{-1}(P_iP)A.$$
Новая матрица $P$ равна $P_iP$. Осталось проверить, что $P_iLP_i$ -- нижнетреугольная с единицами на диагонали и нулями под диагональю в столбцах с номерами начиная с $k+1$. Но в этом несложно убедиться ведь матрица $P_iLP_i$ получается из $L$ перестановкой строк и столбцов с номерами $i$ и $k+1$.
\endproof

\rm Как видно из доказательства, матрица $P$ далеко не единственна. Она определяется тем, какие строки мы переставляем в методе Гаусса. Для того, чтобы избежать сложностей связанных с ошибками округления, даже если возможно не переставлять строки, принято ставить на первое место строку с наибольшим по модулю числом.
Поэтому часто используется именно $LUP$ разложение.
\erm

\rm  Диагональные элементы матрицы $L$ всегда единицы и их можно отдельно не хранить. Элементы под диагональю определяют $L$. Их столько же, сколько заведомо нулевых элементов в $U$. Таким образом, матрицы $L$ и $U$ удобно хранить в виде одной матрицы $n\times n$ убрав всю избыточную информацию про них.
\erm


\rm Можно провести смешное доказательство этой теоремы. Применим метод Гаусса к столбцам $A$. Метод Гаусса равносилен домножению на матрицы $E_{ij}(\lambda)$. При этом, вначале, мы прибавляем $i$-ую строку к $j$-ой, где $i>j$. Такие элементарные матрицы являются верхнетреугольными. Таким образом,если мы всегда домножаем справа на верхнетреугольные матрицы и в итоге получили нижнетреугольную $L$, то мы победили. 

Но в процессе, на шаге $k$   может  получиться, что элемент $a_{kk}=0$. Но в этом случае, в столбце $k$ есть ненулевой элемент. Переставим его с помощью преобразования строк -- это приведёт к домножению матрицы слева на матрицу перестановки. Но это нам и нужно!
\erm



\include{Groups}

\include{Linear}

\include{Multilinear}


\include{Polynomials}





\bibliographystyle{alpha}
\bibliography{lectures}

\end{document}